{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d56e4-328d-4cc3-afba-55cfa147cd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf789420-c121-4f55-99bb-10bf1d6c25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starts from here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression  # LogisticRegression is not used for regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "def remove_low_variance_columns(df, threshold=0.005):\n",
    "    # df = df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "    variances = df.var()\n",
    "    \n",
    "    # Identify columns with variance below the threshold\n",
    "    low_variance_columns = variances[variances < threshold].index.tolist()\n",
    "    \n",
    "    df_cleaned = df.drop(columns=low_variance_columns)\n",
    "    \n",
    "    return df_cleaned, low_variance_columns\n",
    "\n",
    "def features(df, target_column='Permeability', threshold=0.9):\n",
    "    correlation_matrix = df.corr()\n",
    "    \n",
    "    features_to_drop = set()\n",
    "    \n",
    "    for feature in correlation_matrix.columns:\n",
    "        if feature == target_column:\n",
    "            continue \n",
    "        target_corr = correlation_matrix[target_column][feature]\n",
    "        \n",
    "        for other_feature in correlation_matrix.columns:\n",
    "            if other_feature == feature or other_feature == target_column:\n",
    "                continue\n",
    "            \n",
    "            if abs(correlation_matrix[feature][other_feature]) > threshold:\n",
    "                other_target_corr = correlation_matrix[target_column][other_feature]\n",
    "\n",
    "                if abs(other_target_corr) < abs(target_corr):\n",
    "                    features_to_drop.add(other_feature)\n",
    "                else:\n",
    "                    features_to_drop.add(feature)\n",
    "    selected_features = [col for col in df.columns if col not in features_to_drop and col != target_column]\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e5fbb-feab-4fc6-90b4-be2c25c6a46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9600942-4788-4f3d-8152-5d2257672a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3677930/1550735325.py:1: DtypeWarning: Columns (1275,1277,1280,1285,1298,1354,1356,1359,1364,1377,1579,1580,1581,1583,1584,1595,1596,1597) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_desc_train = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Descriptors/Train_2d_3d_all_descriptors_Caco2.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "Data Loading completed\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "(1008, 262)\n",
      "(252, 262)\n",
      "(1008, 916)\n",
      "(252, 916)\n",
      "(1008, 763)\n",
      "(252, 763)\n",
      "(1008, 12)\n",
      "(252, 12)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "df_desc_train = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Descriptors/Train_2d_3d_all_descriptors_Caco2.csv')\n",
    "df_train = df_desc_train.sort_values(by='ID')\n",
    "df_train =df_train.dropna()\n",
    "train = df_train.drop(['ID','SMILES'],axis=1)\n",
    "train = train.select_dtypes(include=['number'])\n",
    "train, _ = remove_low_variance_columns(train)\n",
    "selected_features = features(train, \"Permeability\")\n",
    "df_desc_train = pd.concat( [df_train[['ID','SMILES','Permeability']],df_train[selected_features] ], axis=1)\n",
    "df_desc_test = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Descriptors/Test_2d_3d_all_descriptors_Caco2.csv')\n",
    "df_desc_test = df_desc_test.sort_values(by='ID')\n",
    "df_desc_test =df_desc_test.dropna()\n",
    "df_desc_test =  df_desc_test[df_desc_train.columns]\n",
    "\n",
    "\n",
    "# Fingerprints\n",
    "df_fp_train = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Fingerprints/Train/All_fingerprints_train_Caco2.csv')\n",
    "df_train = df_fp_train.sort_values(by='ID')\n",
    "df_train = df_train.dropna()\n",
    "train = df_train.drop(['ID','SMILES'],axis=1)\n",
    "train = train.select_dtypes(include=['number'])\n",
    "train, _ = remove_low_variance_columns(train)\n",
    "selected_features = features(train, \"Permeability\")\n",
    "df_fp_train = pd.concat( [df_train[['ID','SMILES','Permeability']],df_train[selected_features] ], axis=1)\n",
    "df_fp_test = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Fingerprints/Test/All_fingerprints_test_Caco2.csv')\n",
    "df_fp_test = df_fp_test.sort_values(by='ID')\n",
    "df_fp_test = df_fp_test.dropna()\n",
    "df_fp_test =  df_fp_test[df_fp_train.columns]\n",
    "\n",
    "\n",
    "#Smiles Embeddings\n",
    "df_emb_train = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Embeddings/Train_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_caco2.csv')\n",
    "df_train = df_emb_train.sort_values(by='ID')\n",
    "df_train = df_train.dropna()\n",
    "train = df_train.drop(['ID','SMILES'],axis=1)\n",
    "train = train.select_dtypes(include=['number'])\n",
    "train, _ = remove_low_variance_columns(train)\n",
    "selected_features = features(train, \"Permeability\")\n",
    "df_emb_train = pd.concat( [df_train[['ID','SMILES','Permeability']],df_train[selected_features] ], axis=1)\n",
    "df_emb_test = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Embeddings/Test_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_caco2.csv')\n",
    "df_emb_test = df_emb_test.sort_values(by='ID')\n",
    "df_emb_test = df_emb_test.dropna()\n",
    "df_emb_test =  df_emb_test[df_emb_train.columns]\n",
    "\n",
    "#ATomic features\n",
    "df_atomic_train = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Atomic/Train_all_atomic_desc_Caco2.csv')\n",
    "df_train = df_atomic_train.sort_values(by='ID')\n",
    "df_train = df_train.dropna()\n",
    "train = df_train.drop(['ID','SMILES'],axis=1)\n",
    "train = train.select_dtypes(include=['number'])\n",
    "train, _ = remove_low_variance_columns(train)\n",
    "selected_features = features(train, \"Permeability\")\n",
    "df_atomic_train = pd.concat( [df_train[['ID','SMILES','Permeability']],df_train[selected_features] ], axis=1)\n",
    "# df_atomic_train =pd.concat( [df_train['SMILES'], df_train.select_dtypes(include=['number'])], axis=1)\n",
    "df_atomic_test = pd.read_csv('/home/users/akshay/PCPpred/Caco2/features/Atomic/Test_all_atomic_desc_Caco2.csv')\n",
    "df_atomic_test = df_atomic_test.sort_values(by='ID')\n",
    "df_atomic_test = df_atomic_test.dropna()\n",
    "df_atomic_test =  df_atomic_test[df_atomic_train.columns]\n",
    "\n",
    "\n",
    "print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "print('Data Loading completed')\n",
    "print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "df_fp_test = df_fp_test[df_fp_test['ID'].isin(df_desc_test['ID'])]\n",
    "df_fp_train = df_fp_train[df_fp_train['ID'].isin(df_desc_train['ID'])]\n",
    "\n",
    "df_emb_test = df_emb_test[df_emb_test['ID'].isin(df_desc_test['ID'])]\n",
    "df_emb_train = df_emb_train[df_emb_train['ID'].isin(df_desc_train['ID'])]\n",
    "\n",
    "df_atomic_test = df_atomic_test[df_atomic_test['ID'].isin(df_desc_test['ID'])]\n",
    "df_atomic_train = df_atomic_train[df_atomic_train['ID'].isin(df_desc_train['ID'])]\n",
    "print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "print(df_desc_train.shape)\n",
    "print(df_desc_test.shape)\n",
    "print(df_fp_train.shape)\n",
    "print(df_fp_test.shape)\n",
    "print(df_emb_train.shape)\n",
    "print(df_emb_test.shape)\n",
    "print(df_atomic_train.shape)\n",
    "print(df_atomic_test.shape)\n",
    "print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc9e841-b66a-4382-a803-83dcd72e5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_keys = ['ID', 'SMILES', 'Permeability']\n",
    "\n",
    "merged_train = df_desc_train.merge(df_fp_train, on=merge_keys)\n",
    "merged_train = merged_train.merge(df_emb_train, on=merge_keys)\n",
    "merged_train = merged_train.merge(df_atomic_train, on=merge_keys)\n",
    "\n",
    "merged_test = df_desc_test.merge(df_fp_test, on=merge_keys)\n",
    "merged_test = merged_test.merge(df_emb_test, on=merge_keys)\n",
    "merged_test = merged_test.merge(df_atomic_test, on=merge_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc3fd41-d369-4d23-b322-489a1bd480c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_final_features ['qed', 'SPS', 'FpDensityMorgan1', 'AvgIpc', 'Ipc', 'PEOE_VSA14', 'EState_VSA11', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumUnspecifiedAtomStereoCenters', 'fr_Al_OH_noTert', 'fr_Ar_N', 'fr_aryl_methyl', 'fr_bicyclic', 'fr_methoxy', 'fr_morpholine', 'fr_para_hydroxylation', 'fr_piperdine', 'fr_unbrch_alkane', 'BasicGroupCount', 'AdjacencyMatrix.6', 'AdjacencyMatrix.9', 'AATS', 'AATS.5', 'AATS.19', 'AATS.90', 'AATS.95', 'AATS.98', 'ATSC.4', 'ATSC.5', 'ATSC.7', 'ATSC.11', 'ATSC.16', 'ATSC.20', 'ATSC.21', 'ATSC.22', 'ATSC.23', 'ATSC.24', 'ATSC.25', 'ATSC.26', 'ATSC.32', 'ATSC.33', 'ATSC.37', 'ATSC.41', 'ATSC.43', 'ATSC.44', 'ATSC.62', 'ATSC.64', 'ATSC.68', 'ATSC.75', 'ATSC.76', 'ATSC.82', 'ATSC.87', 'ATSC.88', 'ATSC.101', 'ATSC.106', 'AATSC.9', 'AATSC.11', 'AATSC.12', 'AATSC.13', 'AATSC.14', 'AATSC.15', 'AATSC.16', 'AATSC.17', 'AATSC.38', 'AATSC.39', 'AATSC.40', 'AATSC.42', 'AATSC.52', 'AATSC.59', 'AATSC.61', 'AATSC.62', 'AATSC.100', 'GATS.3', 'GATS.13', 'GATS.18', 'GATS.67', 'GATS.78', 'GATS.79', 'GATS.88', 'BCUT.3', 'BCUT.7', 'BCUT.23', 'BalabanJ_y', 'AtomTypeEState.16', 'AtomTypeEState.87', 'AtomTypeEState.89', 'AtomTypeEState.95', 'AtomTypeEState.131', 'AtomTypeEState.132', 'AtomTypeEState.170', 'AtomTypeEState.173', 'AtomTypeEState.181', 'AtomTypeEState.252', 'AtomTypeEState.271', 'EtaVEMCount.6', 'ComplementaryIC.5', 'ModifiedIC.5', 'MolecularDistanceEdge.7', 'RingCount.52', 'ALogP', 'AATS1i', 'AATS3i', 'AATS4i', 'AATS6i', 'AATS7i', 'AATS3s', 'AATS4s', 'ATSC2c', 'ATSC5c', 'ATSC6c', 'ATSC8c', 'ATSC3v', 'ATSC7v', 'ATSC2e', 'ATSC8e', 'ATSC8p', 'ATSC3i', 'ATSC5i', 'ATSC6i', 'ATSC1s', 'ATSC3s', 'ATSC8s', 'AATSC1m', 'AATSC8m', 'AATSC0v', 'AATSC3v', 'AATSC6v', 'AATSC5s', 'GATS2c', 'GATS5c', 'GATS6c', 'GATS7c', 'GATS8c', 'GATS4s', 'VE3_Dzm', 'VE1_Dzv', 'VE3_Dzv', 'VR1_Dzv', 'VE3_Dzi', 'VE3_Dzs', 'VR1_Dzs', 'BCUTp-1l', 'BCUTp-1h', 'SpMax1_Bhm', 'SpMax4_Bhs', 'SpMax5_Bhs', 'SpMax7_Bhs', 'VE3_Dt', 'VR1_Dt', 'nHBint4', 'nHBint5', 'nHBint7', 'nHBint8', 'nHBint9', 'nHBint10', 'nssO', 'SHBint3', 'SHBint4', 'SHBint7', 'SHBint9', 'SHBint10', 'SHssNH', 'SdsN', 'minHBa', 'minHBint2', 'minHBint3', 'minHBint4', 'minHBint5', 'minHBint6', 'minHBint7', 'minHBint8', 'minHBint9', 'minHBint10', 'minsCH3', 'minssCH2', 'minsssCH', 'minssssC', 'minssNH', 'mindsN', 'minsssN', 'maxHBd', 'maxHBint2', 'maxHBint3', 'maxHBint4', 'maxHBint5', 'maxHBint6', 'maxHBint8', 'maxHBint9', 'maxHBint10', 'maxHsOH', 'maxsCH3', 'maxssCH2', 'maxdsCH', 'maxdssC', 'meanI', 'hmax', 'LipoaffinityIndex', 'IC1', 'nAtomLC', 'nAtomP', 'nAtomLAC', 'MDEC-11', 'MDEC-12', 'MDEC-13', 'MDEC-14', 'MDEC-22', 'MDEC-23', 'MDEC-33', 'MDEN-12', 'MDEN-22', 'MLFER_A', 'nTRing', 'LipinskiFailures', 'XLogP', '3d_rdkit_4', '3d_rdkit_10', '3d_rdkit_11', 'TDB10u', 'TDB5m', 'TDB5e', 'TDB6e', 'TDB7e', 'TDB8e', 'TDB1i', 'TDB2i', 'TDB3i', 'TDB4i', 'TDB5i', 'TDB6i', 'TDB7i', 'TDB8i', 'TDB6s', 'TDB7s', 'TDB8s', 'TDB9s', 'TDB9r', 'RPCS', 'RNCS', 'TPSA_y', 'LOBMAX', 'LOBMIN', 'MOMI-XY', 'MOMI-YZ', 'geomShape', 'RDF30s', 'L2m', 'L3m', 'Dv', 'De', 'Morgan_fp_2', 'Morgan_fp_19', 'Morgan_fp_84', 'Morgan_fp_94', 'Morgan_fp_109', 'Morgan_fp_115', 'Morgan_fp_119', 'Morgan_fp_130', 'Morgan_fp_167', 'Morgan_fp_231', 'Morgan_fp_253', 'Morgan_fp_269', 'Morgan_fp_310', 'Morgan_fp_328', 'Morgan_fp_334', 'Morgan_fp_340', 'Morgan_fp_370', 'Morgan_fp_476', 'Morgan_fp_534', 'Morgan_fp_562', 'Morgan_fp_591', 'Morgan_fp_598', 'Morgan_fp_634', 'Morgan_fp_675', 'Morgan_fp_684', 'Morgan_fp_713', 'Morgan_fp_739', 'Morgan_fp_745', 'Morgan_fp_784', 'Morgan_fp_798', 'Morgan_fp_832', 'Morgan_fp_890', 'Morgan_fp_893', 'Morgan_fp_926', 'Morgan_fp_958', 'Morgan_fp_999', 'Morgan_fp_1001', 'Morgan_fp_1006', 'Morgan_fp_1028', 'Morgan_fp_1052', 'Morgan_fp_1069', 'Morgan_fp_1088', 'Morgan_fp_1139', 'Morgan_fp_1162', 'Morgan_fp_1240', 'Morgan_fp_1274', 'Morgan_fp_1309', 'Morgan_fp_1325', 'Morgan_fp_1345', 'Morgan_fp_1352', 'Morgan_fp_1421', 'Morgan_fp_1456', 'Morgan_fp_1495', 'Morgan_fp_1506', 'Morgan_fp_1516', 'Morgan_fp_1543', 'Morgan_fp_1545', 'Morgan_fp_1613', 'Morgan_fp_1662', 'Morgan_fp_1689', 'Morgan_fp_1693', 'Morgan_fp_1783', 'Morgan_fp_1840', 'Morgan_fp_1898', 'Morgan_fp_1911', 'Morgan_fp_1920', 'Morgan_fp_1946', 'Morgan_fp_1949', 'count_fp_2', 'count_fp_19', 'count_fp_65', 'count_fp_80', 'count_fp_84', 'count_fp_126', 'count_fp_160', 'count_fp_173', 'count_fp_174', 'count_fp_216', 'count_fp_219', 'count_fp_231', 'count_fp_235', 'count_fp_250', 'count_fp_269', 'count_fp_296', 'count_fp_310', 'count_fp_358', 'count_fp_362', 'count_fp_458', 'count_fp_473', 'count_fp_476', 'count_fp_552', 'count_fp_619', 'count_fp_638', 'count_fp_654', 'count_fp_684', 'count_fp_687', 'count_fp_692', 'count_fp_725', 'count_fp_749', 'count_fp_798', 'count_fp_807', 'count_fp_811', 'count_fp_857', 'count_fp_870', 'count_fp_875', 'count_fp_881', 'count_fp_890', 'count_fp_893', 'count_fp_914', 'count_fp_950', 'count_fp_957', 'count_fp_963', 'count_fp_979', 'count_fp_1060', 'count_fp_1087', 'count_fp_1089', 'count_fp_1118', 'count_fp_1208', 'count_fp_1248', 'count_fp_1260', 'count_fp_1280', 'count_fp_1309', 'count_fp_1315', 'count_fp_1325', 'count_fp_1345', 'count_fp_1373', 'count_fp_1454', 'count_fp_1480', 'count_fp_1495', 'count_fp_1506', 'count_fp_1516', 'count_fp_1527', 'count_fp_1535', 'count_fp_1599', 'count_fp_1607', 'count_fp_1613', 'count_fp_1620', 'count_fp_1662', 'count_fp_1676', 'count_fp_1689', 'count_fp_1693', 'count_fp_1709', 'count_fp_1734', 'count_fp_1750', 'count_fp_1776', 'count_fp_1783', 'count_fp_1853', 'count_fp_1879', 'count_fp_1882', 'count_fp_1937', 'count_fp_1946', 'count_fp_2008', 'AD2D183', 'AD2D189', 'AD2D267', 'AD2D407', 'AD2D492', 'AD2D638', 'AD2D648', 'AD2D651', 'AD2D657', 'AD2D735', 'APC2D4_N_O', 'APC2D4_O_O', 'APC2D4_F_F', 'APC2D5_N_N', 'APC2D6_N_F', 'APC2D7_N_F', 'APC2D7_N_X', 'APC2D7_O_X', 'APC2D8_N_N', 'APC2D8_N_S', 'APC2D8_N_X', 'APC2D8_O_F', 'APC2D8_O_X', 'APC2D9_O_O', 'APC2D9_O_S', 'APC2D10_C_F', 'APC2D10_C_X', 'APC2D10_N_O', 'APC2D10_N_F', 'APC2D10_N_X', 'APC2D10_O_O', 'ExtFP4', 'ExtFP6', 'ExtFP12', 'ExtFP13', 'ExtFP21', 'ExtFP26', 'ExtFP28', 'ExtFP29', 'ExtFP31', 'ExtFP37', 'ExtFP40', 'ExtFP46', 'ExtFP65', 'ExtFP69', 'ExtFP70', 'ExtFP71', 'ExtFP76', 'ExtFP82', 'ExtFP85', 'ExtFP86', 'ExtFP89', 'ExtFP90', 'ExtFP91', 'ExtFP97', 'ExtFP98', 'ExtFP106', 'ExtFP108', 'ExtFP110', 'ExtFP118', 'ExtFP128', 'ExtFP135', 'ExtFP136', 'ExtFP138', 'ExtFP145', 'ExtFP148', 'ExtFP150', 'ExtFP152', 'ExtFP155', 'ExtFP160', 'ExtFP168', 'ExtFP171', 'ExtFP181', 'ExtFP188', 'ExtFP195', 'ExtFP204', 'ExtFP205', 'ExtFP211', 'ExtFP214', 'ExtFP217', 'ExtFP221', 'ExtFP223', 'ExtFP224', 'ExtFP227', 'ExtFP233', 'ExtFP234', 'ExtFP249', 'ExtFP250', 'ExtFP265', 'ExtFP266', 'ExtFP267', 'ExtFP268', 'ExtFP269', 'ExtFP275', 'ExtFP278', 'ExtFP281', 'ExtFP286', 'ExtFP287', 'ExtFP289', 'ExtFP294', 'ExtFP303', 'ExtFP308', 'ExtFP311', 'ExtFP312', 'ExtFP314', 'ExtFP316', 'ExtFP318', 'ExtFP322', 'ExtFP324', 'ExtFP327', 'ExtFP328', 'ExtFP329', 'ExtFP331', 'ExtFP333', 'ExtFP336', 'ExtFP341', 'ExtFP347', 'ExtFP348', 'ExtFP353', 'ExtFP368', 'ExtFP370', 'ExtFP373', 'ExtFP374', 'ExtFP375', 'ExtFP376', 'ExtFP382', 'ExtFP384', 'ExtFP386', 'ExtFP387', 'ExtFP388', 'ExtFP401', 'ExtFP405', 'ExtFP407', 'ExtFP409', 'ExtFP413', 'ExtFP417', 'ExtFP423', 'ExtFP430', 'ExtFP434', 'ExtFP441', 'ExtFP442', 'ExtFP449', 'ExtFP452', 'ExtFP457', 'ExtFP458', 'ExtFP459', 'ExtFP465', 'ExtFP467', 'ExtFP469', 'ExtFP470', 'ExtFP471', 'ExtFP472', 'ExtFP474', 'ExtFP475', 'ExtFP486', 'ExtFP487', 'ExtFP500', 'ExtFP507', 'ExtFP510', 'ExtFP517', 'ExtFP527', 'ExtFP530', 'ExtFP545', 'ExtFP551', 'ExtFP552', 'ExtFP558', 'ExtFP560', 'ExtFP568', 'ExtFP574', 'ExtFP575', 'ExtFP576', 'ExtFP583', 'ExtFP586', 'ExtFP587', 'ExtFP589', 'ExtFP592', 'ExtFP596', 'ExtFP602', 'ExtFP605', 'ExtFP618', 'ExtFP620', 'ExtFP630', 'ExtFP632', 'ExtFP638', 'ExtFP639', 'ExtFP643', 'ExtFP645', 'ExtFP649', 'ExtFP672', 'ExtFP676', 'ExtFP679', 'ExtFP688', 'ExtFP689', 'ExtFP690', 'ExtFP694', 'ExtFP704', 'ExtFP707', 'ExtFP711', 'ExtFP724', 'ExtFP728', 'ExtFP731', 'ExtFP741', 'ExtFP745', 'ExtFP749', 'ExtFP751', 'ExtFP754', 'ExtFP756', 'ExtFP760', 'ExtFP767', 'ExtFP776', 'ExtFP781', 'ExtFP786', 'ExtFP789', 'ExtFP795', 'ExtFP797', 'ExtFP800', 'ExtFP801', 'ExtFP802', 'ExtFP805', 'ExtFP806', 'ExtFP807', 'ExtFP808', 'ExtFP813', 'ExtFP818', 'ExtFP819', 'ExtFP820', 'ExtFP827', 'ExtFP828', 'ExtFP830', 'ExtFP833', 'ExtFP834', 'ExtFP846', 'ExtFP848', 'ExtFP849', 'ExtFP852', 'ExtFP853', 'ExtFP855', 'ExtFP856', 'ExtFP857', 'ExtFP859', 'ExtFP864', 'ExtFP865', 'ExtFP866', 'ExtFP867', 'ExtFP868', 'ExtFP870', 'ExtFP873', 'ExtFP875', 'ExtFP882', 'ExtFP889', 'ExtFP894', 'ExtFP898', 'ExtFP900', 'ExtFP902', 'ExtFP903', 'ExtFP905', 'ExtFP906', 'ExtFP908', 'ExtFP913', 'ExtFP924', 'ExtFP926', 'ExtFP928', 'ExtFP931', 'ExtFP932', 'ExtFP936', 'ExtFP943', 'ExtFP948', 'ExtFP949', 'ExtFP952', 'ExtFP953', 'ExtFP954', 'ExtFP960', 'ExtFP963', 'ExtFP966', 'ExtFP974', 'ExtFP976', 'ExtFP981', 'ExtFP988', 'ExtFP993', 'ExtFP997', 'ExtFP1012', 'ExtFP1013', 'ExtFP1016', 'ExtFP1017', 'FP5', 'FP10', 'FP12', 'FP13', 'FP14', 'FP16', 'FP21', 'FP25', 'FP26', 'FP27', 'FP30', 'FP31', 'FP36', 'FP43', 'FP44', 'FP47', 'FP48', 'FP49', 'FP50', 'FP56', 'FP60', 'FP63', 'FP66', 'FP70', 'FP71', 'FP75', 'FP76', 'FP77', 'FP80', 'FP84', 'FP89', 'FP91', 'FP97', 'FP98', 'FP102', 'FP114', 'FP120', 'FP121', 'FP127', 'FP137', 'FP142', 'FP144', 'FP146', 'FP153', 'FP157', 'FP170', 'FP171', 'FP173', 'FP182', 'FP184', 'FP193', 'FP195', 'FP197', 'FP215', 'FP216', 'FP218', 'FP220', 'FP225', 'FP226', 'FP227', 'FP230', 'FP234', 'FP244', 'FP247', 'FP251', 'FP253', 'FP262', 'FP265', 'FP266', 'FP268', 'FP275', 'FP283', 'FP284', 'FP285', 'FP286', 'FP292', 'FP302', 'FP305', 'FP310', 'FP311', 'FP316', 'FP324', 'FP331', 'FP334', 'FP337', 'FP340', 'FP341', 'FP342', 'FP343', 'FP344', 'FP345', 'FP352', 'FP354', 'FP355', 'FP363', 'FP376', 'FP379', 'FP385', 'FP389', 'FP390', 'FP393', 'FP403', 'FP413', 'FP415', 'FP416', 'FP422', 'FP425', 'FP427', 'FP430', 'FP431', 'FP442', 'FP444', 'FP448', 'FP454', 'FP459', 'FP461', 'FP463', 'FP464', 'FP465', 'FP473', 'FP475', 'FP483', 'FP488', 'FP489', 'FP493', 'FP497', 'FP498', 'FP500', 'FP501', 'FP510', 'FP525', 'FP531', 'FP539', 'FP546', 'FP547', 'FP548', 'FP553', 'FP560', 'FP563', 'FP564', 'FP566', 'FP569', 'FP571', 'FP576', 'FP581', 'FP582', 'FP583', 'FP587', 'FP600', 'FP601', 'FP614', 'FP618', 'FP619', 'FP622', 'FP623', 'FP632', 'FP633', 'FP635', 'FP646', 'FP658', 'FP659', 'FP664', 'FP691', 'FP692', 'FP708', 'FP717', 'FP720', 'FP726', 'FP728', 'FP731', 'FP735', 'FP737', 'FP738', 'FP748', 'FP757', 'FP764', 'FP765', 'FP766', 'FP773', 'FP777', 'FP787', 'FP808', 'FP809', 'FP810', 'FP811', 'FP813', 'FP815', 'FP819', 'FP820', 'FP822', 'FP831', 'FP833', 'FP836', 'FP837', 'FP839', 'FP841', 'FP843', 'FP849', 'FP851', 'FP852', 'FP855', 'FP861', 'FP862', 'FP870', 'FP873', 'FP876', 'FP879', 'FP889', 'FP891', 'FP893', 'FP894', 'FP897', 'FP904', 'FP908', 'FP911', 'FP915', 'FP917', 'FP919', 'FP920', 'FP922', 'FP933', 'FP935', 'FP943', 'FP944', 'FP950', 'FP958', 'FP959', 'FP961', 'FP963', 'FP967', 'FP969', 'FP970', 'FP973', 'FP977', 'FP980', 'FP982', 'FP984', 'FP988', 'FP994', 'FP998', 'FP1001', 'FP1008', 'FP1009', 'FP1011', 'FP1013', 'FP1015', 'FP1016', 'FP1017', 'FP1019', 'FP1022', 'GraphFP6', 'GraphFP8', 'GraphFP21', 'GraphFP23', 'GraphFP25', 'GraphFP41', 'GraphFP44', 'GraphFP47', 'GraphFP59', 'GraphFP64', 'GraphFP73', 'GraphFP83', 'GraphFP124', 'GraphFP130', 'GraphFP170', 'GraphFP175', 'GraphFP197', 'GraphFP214', 'GraphFP241', 'GraphFP255', 'GraphFP259', 'GraphFP264', 'GraphFP268', 'GraphFP270', 'GraphFP302', 'GraphFP303', 'GraphFP305', 'GraphFP315', 'GraphFP319', 'GraphFP320', 'GraphFP335', 'GraphFP358', 'GraphFP363', 'GraphFP380', 'GraphFP411', 'GraphFP427', 'GraphFP443', 'GraphFP455', 'GraphFP465', 'GraphFP487', 'GraphFP492', 'GraphFP499', 'GraphFP509', 'GraphFP522', 'GraphFP523', 'GraphFP534', 'GraphFP551', 'GraphFP553', 'GraphFP563', 'GraphFP578', 'GraphFP586', 'GraphFP632', 'GraphFP639', 'GraphFP641', 'GraphFP714', 'GraphFP723', 'GraphFP728', 'GraphFP744', 'GraphFP750', 'GraphFP751', 'GraphFP754', 'GraphFP765', 'GraphFP768', 'GraphFP772', 'GraphFP775', 'GraphFP777', 'GraphFP788', 'GraphFP790', 'GraphFP808', 'GraphFP817', 'GraphFP833', 'GraphFP834', 'GraphFP836', 'GraphFP837', 'GraphFP838', 'GraphFP850', 'GraphFP851', 'GraphFP852', 'GraphFP882', 'GraphFP886', 'GraphFP893', 'GraphFP894', 'GraphFP899', 'GraphFP905', 'GraphFP909', 'GraphFP910', 'GraphFP911', 'GraphFP913', 'GraphFP914', 'GraphFP915', 'GraphFP920', 'GraphFP926', 'GraphFP929', 'GraphFP937', 'GraphFP940', 'GraphFP965', 'GraphFP983', 'KRFP92', 'KRFP303', 'KRFP314', 'KRFP344', 'KRFP382', 'KRFP398', 'KRFP413', 'KRFP444', 'KRFP481', 'KRFP504', 'KRFP508', 'KRFP555', 'KRFP608', 'KRFP610', 'KRFP648', 'KRFP682', 'KRFP690', 'KRFP841', 'KRFP842', 'KRFP2308', 'KRFP3058', 'KRFP3369', 'KRFP3393', 'KRFP3659', 'KRFP3661', 'KRFP3730', 'KRFP3753', 'KRFP3764', 'KRFP3767', 'KRFPC2', 'KRFPC14', 'KRFPC218', 'KRFPC297', 'KRFPC298', 'KRFPC299', 'KRFPC303', 'KRFPC314', 'KRFPC344', 'KRFPC346', 'KRFPC401', 'KRFPC421', 'KRFPC435', 'KRFPC444', 'KRFPC467', 'KRFPC504', 'KRFPC506', 'KRFPC507', 'KRFPC555', 'KRFPC605', 'KRFPC608', 'KRFPC610', 'KRFPC621', 'KRFPC648', 'KRFPC690', 'KRFPC697', 'KRFPC700', 'KRFPC839', 'KRFPC840', 'KRFPC842', 'KRFPC848', 'KRFPC1566', 'KRFPC3058', 'KRFPC3149', 'KRFPC3369', 'KRFPC3660', 'KRFPC3706', 'KRFPC3726', 'KRFPC3729', 'KRFPC3734', 'KRFPC3778', 'KRFPC3786', 'KRFPC3897', 'KRFPC4291', 'MACCSFP53', 'MACCSFP54', 'MACCSFP57', 'MACCSFP62', 'MACCSFP74', 'MACCSFP75', 'MACCSFP82', 'MACCSFP86', 'MACCSFP90', 'MACCSFP91', 'MACCSFP104', 'MACCSFP105', 'MACCSFP106', 'MACCSFP108', 'MACCSFP115', 'MACCSFP116', 'MACCSFP128', 'MACCSFP129', 'MACCSFP133', 'MACCSFP138', 'MACCSFP153', 'PubchemFP0', 'PubchemFP1', 'PubchemFP13', 'PubchemFP21', 'PubchemFP22', 'PubchemFP38', 'PubchemFP145', 'PubchemFP150', 'PubchemFP157', 'PubchemFP186', 'PubchemFP192', 'PubchemFP193', 'PubchemFP199', 'PubchemFP200', 'PubchemFP206', 'PubchemFP256', 'PubchemFP259', 'PubchemFP261', 'PubchemFP379', 'PubchemFP389', 'PubchemFP596', 'PubchemFP617', 'PubchemFP637', 'PubchemFP680', 'PubchemFP704', 'PubchemFP710', 'SubFPC179', 'x_fine_emb_MFXL0', 'x_fine_emb_MFXL1', 'x_fine_emb_MFXL2', 'x_fine_emb_MFXL3', 'x_fine_emb_MFXL4', 'x_fine_emb_MFXL5', 'x_fine_emb_MFXL6', 'x_fine_emb_MFXL7', 'x_fine_emb_MFXL8', 'x_fine_emb_MFXL9', 'x_fine_emb_MFXL10', 'x_fine_emb_MFXL11', 'x_fine_emb_MFXL12', 'x_fine_emb_MFXL13', 'x_fine_emb_MFXL14', 'x_fine_emb_MFXL15', 'x_fine_emb_MFXL16', 'x_fine_emb_MFXL17', 'x_fine_emb_MFXL18', 'x_fine_emb_MFXL19', 'x_fine_emb_MFXL20', 'x_fine_emb_MFXL21', 'x_fine_emb_MFXL22', 'x_fine_emb_MFXL23', 'x_fine_emb_MFXL24', 'x_fine_emb_MFXL25', 'x_fine_emb_MFXL26', 'x_fine_emb_MFXL27', 'x_fine_emb_MFXL28', 'x_fine_emb_MFXL29', 'x_fine_emb_MFXL30', 'x_fine_emb_MFXL31', 'x_fine_emb_MFXL32', 'x_fine_emb_MFXL33', 'x_fine_emb_MFXL34', 'x_fine_emb_MFXL35', 'x_fine_emb_MFXL36', 'x_fine_emb_MFXL37', 'x_fine_emb_MFXL38', 'x_fine_emb_MFXL39', 'x_fine_emb_MFXL40', 'x_fine_emb_MFXL41', 'x_fine_emb_MFXL42', 'x_fine_emb_MFXL43', 'x_fine_emb_MFXL44', 'x_fine_emb_MFXL45', 'x_fine_emb_MFXL46', 'x_fine_emb_MFXL47', 'x_fine_emb_MFXL48', 'x_fine_emb_MFXL49', 'x_fine_emb_MFXL50', 'x_fine_emb_MFXL51', 'x_fine_emb_MFXL52', 'x_fine_emb_MFXL53', 'x_fine_emb_MFXL54', 'x_fine_emb_MFXL55', 'x_fine_emb_MFXL57', 'x_fine_emb_MFXL58', 'x_fine_emb_MFXL59', 'x_fine_emb_MFXL60', 'x_fine_emb_MFXL61', 'x_fine_emb_MFXL62', 'x_fine_emb_MFXL63', 'x_fine_emb_MFXL64', 'x_fine_emb_MFXL65', 'x_fine_emb_MFXL66', 'x_fine_emb_MFXL67', 'x_fine_emb_MFXL68', 'x_fine_emb_MFXL69', 'x_fine_emb_MFXL70', 'x_fine_emb_MFXL71', 'x_fine_emb_MFXL72', 'x_fine_emb_MFXL73', 'x_fine_emb_MFXL74', 'x_fine_emb_MFXL75', 'x_fine_emb_MFXL76', 'x_fine_emb_MFXL77', 'x_fine_emb_MFXL78', 'x_fine_emb_MFXL79', 'x_fine_emb_MFXL80', 'x_fine_emb_MFXL81', 'x_fine_emb_MFXL82', 'x_fine_emb_MFXL83', 'x_fine_emb_MFXL84', 'x_fine_emb_MFXL85', 'x_fine_emb_MFXL86', 'x_fine_emb_MFXL87', 'x_fine_emb_MFXL88', 'x_fine_emb_MFXL89', 'x_fine_emb_MFXL90', 'x_fine_emb_MFXL91', 'x_fine_emb_MFXL92', 'x_fine_emb_MFXL93', 'x_fine_emb_MFXL94', 'x_fine_emb_MFXL95', 'x_fine_emb_MFXL96', 'x_fine_emb_MFXL97', 'x_fine_emb_MFXL98', 'x_fine_emb_MFXL99', 'x_fine_emb_MFXL100', 'x_fine_emb_MFXL101', 'x_fine_emb_MFXL102', 'x_fine_emb_MFXL103', 'x_fine_emb_MFXL104', 'x_fine_emb_MFXL105', 'x_fine_emb_MFXL106', 'x_fine_emb_MFXL107', 'x_fine_emb_MFXL108', 'x_fine_emb_MFXL109', 'x_fine_emb_MFXL110', 'x_fine_emb_MFXL111', 'x_fine_emb_MFXL112', 'x_fine_emb_MFXL113', 'x_fine_emb_MFXL114', 'x_fine_emb_MFXL115', 'x_fine_emb_MFXL116', 'x_fine_emb_MFXL117', 'x_fine_emb_MFXL118', 'x_fine_emb_MFXL119', 'x_fine_emb_MFXL120', 'x_fine_emb_MFXL121', 'x_fine_emb_MFXL122', 'x_fine_emb_MFXL123', 'x_fine_emb_MFXL124', 'x_fine_emb_MFXL125', 'x_fine_emb_MFXL126', 'x_fine_emb_MFXL127', 'x_fine_emb_MFXL128', 'x_fine_emb_MFXL129', 'x_fine_emb_MFXL130', 'x_fine_emb_MFXL131', 'x_fine_emb_MFXL132', 'x_fine_emb_MFXL133', 'x_fine_emb_MFXL134', 'x_fine_emb_MFXL135', 'x_fine_emb_MFXL136', 'x_fine_emb_MFXL137', 'x_fine_emb_MFXL138', 'x_fine_emb_MFXL139', 'x_fine_emb_MFXL140', 'x_fine_emb_MFXL141', 'x_fine_emb_MFXL142', 'x_fine_emb_MFXL143', 'x_fine_emb_MFXL144', 'x_fine_emb_MFXL145', 'x_fine_emb_MFXL146', 'x_fine_emb_MFXL147', 'x_fine_emb_MFXL148', 'x_fine_emb_MFXL149', 'x_fine_emb_MFXL150', 'x_fine_emb_MFXL151', 'x_fine_emb_MFXL152', 'x_fine_emb_MFXL153', 'x_fine_emb_MFXL154', 'x_fine_emb_MFXL155', 'x_fine_emb_MFXL156', 'x_fine_emb_MFXL157', 'x_fine_emb_MFXL158', 'x_fine_emb_MFXL159', 'x_fine_emb_MFXL160', 'x_fine_emb_MFXL161', 'x_fine_emb_MFXL162', 'x_fine_emb_MFXL163', 'x_fine_emb_MFXL164', 'x_fine_emb_MFXL165', 'x_fine_emb_MFXL166', 'x_fine_emb_MFXL167', 'x_fine_emb_MFXL168', 'x_fine_emb_MFXL169', 'x_fine_emb_MFXL171', 'x_fine_emb_MFXL172', 'x_fine_emb_MFXL174', 'x_fine_emb_MFXL175', 'x_fine_emb_MFXL176', 'x_fine_emb_MFXL177', 'x_fine_emb_MFXL178', 'x_fine_emb_MFXL179', 'x_fine_emb_MFXL180', 'x_fine_emb_MFXL181', 'x_fine_emb_MFXL182', 'x_fine_emb_MFXL183', 'x_fine_emb_MFXL184', 'x_fine_emb_MFXL185', 'x_fine_emb_MFXL186', 'x_fine_emb_MFXL187', 'x_fine_emb_MFXL188', 'x_fine_emb_MFXL189', 'x_fine_emb_MFXL190', 'x_fine_emb_MFXL191', 'x_fine_emb_MFXL192', 'x_fine_emb_MFXL193', 'x_fine_emb_MFXL194', 'x_fine_emb_MFXL195', 'x_fine_emb_MFXL196', 'x_fine_emb_MFXL197', 'x_fine_emb_MFXL198', 'x_fine_emb_MFXL199', 'x_fine_emb_MFXL200', 'x_fine_emb_MFXL201', 'x_fine_emb_MFXL202', 'x_fine_emb_MFXL203', 'x_fine_emb_MFXL204', 'x_fine_emb_MFXL205', 'x_fine_emb_MFXL206', 'x_fine_emb_MFXL207', 'x_fine_emb_MFXL208', 'x_fine_emb_MFXL209', 'x_fine_emb_MFXL210', 'x_fine_emb_MFXL211', 'x_fine_emb_MFXL212', 'x_fine_emb_MFXL213', 'x_fine_emb_MFXL214', 'x_fine_emb_MFXL215', 'x_fine_emb_MFXL216', 'x_fine_emb_MFXL217', 'x_fine_emb_MFXL218', 'x_fine_emb_MFXL219', 'x_fine_emb_MFXL220', 'x_fine_emb_MFXL221', 'x_fine_emb_MFXL222', 'x_fine_emb_MFXL223', 'x_fine_emb_MFXL224', 'x_fine_emb_MFXL225', 'x_fine_emb_MFXL226', 'x_fine_emb_MFXL227', 'x_fine_emb_MFXL228', 'x_fine_emb_MFXL229', 'x_fine_emb_MFXL230', 'x_fine_emb_MFXL231', 'x_fine_emb_MFXL232', 'x_fine_emb_MFXL233', 'x_fine_emb_MFXL234', 'x_fine_emb_MFXL235', 'x_fine_emb_MFXL236', 'x_fine_emb_MFXL237', 'x_fine_emb_MFXL238', 'x_fine_emb_MFXL239', 'x_fine_emb_MFXL240', 'x_fine_emb_MFXL241', 'x_fine_emb_MFXL242', 'x_fine_emb_MFXL243', 'x_fine_emb_MFXL244', 'x_fine_emb_MFXL245', 'x_fine_emb_MFXL246', 'x_fine_emb_MFXL247', 'x_fine_emb_MFXL248', 'x_fine_emb_MFXL249', 'x_fine_emb_MFXL250', 'x_fine_emb_MFXL251', 'x_fine_emb_MFXL252', 'x_fine_emb_MFXL253', 'x_fine_emb_MFXL254', 'x_fine_emb_MFXL255', 'x_fine_emb_MFXL256', 'x_fine_emb_MFXL257', 'x_fine_emb_MFXL258', 'x_fine_emb_MFXL259', 'x_fine_emb_MFXL260', 'x_fine_emb_MFXL261', 'x_fine_emb_MFXL262', 'x_fine_emb_MFXL263', 'x_fine_emb_MFXL264', 'x_fine_emb_MFXL265', 'x_fine_emb_MFXL266', 'x_fine_emb_MFXL267', 'x_fine_emb_MFXL268', 'x_fine_emb_MFXL269', 'x_fine_emb_MFXL270', 'x_fine_emb_MFXL271', 'x_fine_emb_MFXL272', 'x_fine_emb_MFXL273', 'x_fine_emb_MFXL274', 'x_fine_emb_MFXL275', 'x_fine_emb_MFXL276', 'x_fine_emb_MFXL277', 'x_fine_emb_MFXL278', 'x_fine_emb_MFXL279', 'x_fine_emb_MFXL280', 'x_fine_emb_MFXL281', 'x_fine_emb_MFXL282', 'x_fine_emb_MFXL283', 'x_fine_emb_MFXL284', 'x_fine_emb_MFXL285', 'x_fine_emb_MFXL286', 'x_fine_emb_MFXL287', 'x_fine_emb_MFXL288', 'x_fine_emb_MFXL289', 'x_fine_emb_MFXL290', 'x_fine_emb_MFXL291', 'x_fine_emb_MFXL292', 'x_fine_emb_MFXL293', 'x_fine_emb_MFXL294', 'x_fine_emb_MFXL295', 'x_fine_emb_MFXL296', 'x_fine_emb_MFXL297', 'x_fine_emb_MFXL298', 'x_fine_emb_MFXL299', 'x_fine_emb_MFXL300', 'x_fine_emb_MFXL301', 'x_fine_emb_MFXL302', 'x_fine_emb_MFXL303', 'x_fine_emb_MFXL304', 'x_fine_emb_MFXL305', 'x_fine_emb_MFXL306', 'x_fine_emb_MFXL307', 'x_fine_emb_MFXL308', 'x_fine_emb_MFXL309', 'x_fine_emb_MFXL310', 'x_fine_emb_MFXL311', 'x_fine_emb_MFXL312', 'x_fine_emb_MFXL313', 'x_fine_emb_MFXL314', 'x_fine_emb_MFXL315', 'x_fine_emb_MFXL316', 'x_fine_emb_MFXL317', 'x_fine_emb_MFXL318', 'x_fine_emb_MFXL319', 'x_fine_emb_MFXL320', 'x_fine_emb_MFXL321', 'x_fine_emb_MFXL322', 'x_fine_emb_MFXL323', 'x_fine_emb_MFXL324', 'x_fine_emb_MFXL325', 'x_fine_emb_MFXL326', 'x_fine_emb_MFXL327', 'x_fine_emb_MFXL328', 'x_fine_emb_MFXL329', 'x_fine_emb_MFXL330', 'x_fine_emb_MFXL331', 'x_fine_emb_MFXL332', 'x_fine_emb_MFXL333', 'x_fine_emb_MFXL334', 'x_fine_emb_MFXL335', 'x_fine_emb_MFXL336', 'x_fine_emb_MFXL337', 'x_fine_emb_MFXL338', 'x_fine_emb_MFXL339', 'x_fine_emb_MFXL340', 'x_fine_emb_MFXL341', 'x_fine_emb_MFXL342', 'x_fine_emb_MFXL343', 'x_fine_emb_MFXL344', 'x_fine_emb_MFXL345', 'x_fine_emb_MFXL346', 'x_fine_emb_MFXL347', 'x_fine_emb_MFXL348', 'x_fine_emb_MFXL349', 'x_fine_emb_MFXL350', 'x_fine_emb_MFXL351', 'x_fine_emb_MFXL352', 'x_fine_emb_MFXL353', 'x_fine_emb_MFXL354', 'x_fine_emb_MFXL355', 'x_fine_emb_MFXL356', 'x_fine_emb_MFXL357', 'x_fine_emb_MFXL358', 'x_fine_emb_MFXL359', 'x_fine_emb_MFXL360', 'x_fine_emb_MFXL361', 'x_fine_emb_MFXL362', 'x_fine_emb_MFXL363', 'x_fine_emb_MFXL364', 'x_fine_emb_MFXL365', 'x_fine_emb_MFXL366', 'x_fine_emb_MFXL367', 'x_fine_emb_MFXL368', 'x_fine_emb_MFXL369', 'x_fine_emb_MFXL370', 'x_fine_emb_MFXL371', 'x_fine_emb_MFXL372', 'x_fine_emb_MFXL373', 'x_fine_emb_MFXL374', 'x_fine_emb_MFXL375', 'x_fine_emb_MFXL376', 'x_fine_emb_MFXL378', 'x_fine_emb_MFXL379', 'x_fine_emb_MFXL380', 'x_fine_emb_MFXL381', 'x_fine_emb_MFXL382', 'x_fine_emb_MFXL383', 'x_fine_emb_MFXL384', 'x_fine_emb_MFXL385', 'x_fine_emb_MFXL386', 'x_fine_emb_MFXL387', 'x_fine_emb_MFXL388', 'x_fine_emb_MFXL389', 'x_fine_emb_MFXL390', 'x_fine_emb_MFXL391', 'x_fine_emb_MFXL392', 'x_fine_emb_MFXL393', 'x_fine_emb_MFXL394', 'x_fine_emb_MFXL395', 'x_fine_emb_MFXL396', 'x_fine_emb_MFXL397', 'x_fine_emb_MFXL398', 'x_fine_emb_MFXL399', 'x_fine_emb_MFXL400', 'x_fine_emb_MFXL401', 'x_fine_emb_MFXL402', 'x_fine_emb_MFXL403', 'x_fine_emb_MFXL404', 'x_fine_emb_MFXL405', 'x_fine_emb_MFXL406', 'x_fine_emb_MFXL407', 'x_fine_emb_MFXL408', 'x_fine_emb_MFXL409', 'x_fine_emb_MFXL410', 'x_fine_emb_MFXL411', 'x_fine_emb_MFXL412', 'x_fine_emb_MFXL413', 'x_fine_emb_MFXL414', 'x_fine_emb_MFXL415', 'x_fine_emb_MFXL416', 'x_fine_emb_MFXL417', 'x_fine_emb_MFXL418', 'x_fine_emb_MFXL419', 'x_fine_emb_MFXL420', 'x_fine_emb_MFXL421', 'x_fine_emb_MFXL422', 'x_fine_emb_MFXL423', 'x_fine_emb_MFXL424', 'x_fine_emb_MFXL425', 'x_fine_emb_MFXL426', 'x_fine_emb_MFXL427', 'x_fine_emb_MFXL428', 'x_fine_emb_MFXL429', 'x_fine_emb_MFXL430', 'x_fine_emb_MFXL431', 'x_fine_emb_MFXL432', 'x_fine_emb_MFXL433', 'x_fine_emb_MFXL434', 'x_fine_emb_MFXL435', 'x_fine_emb_MFXL436', 'x_fine_emb_MFXL437', 'x_fine_emb_MFXL438', 'x_fine_emb_MFXL439', 'x_fine_emb_MFXL440', 'x_fine_emb_MFXL441', 'x_fine_emb_MFXL442', 'x_fine_emb_MFXL443', 'x_fine_emb_MFXL444', 'x_fine_emb_MFXL445', 'x_fine_emb_MFXL446', 'x_fine_emb_MFXL447', 'x_fine_emb_MFXL448', 'x_fine_emb_MFXL449', 'x_fine_emb_MFXL450', 'x_fine_emb_MFXL451', 'x_fine_emb_MFXL452', 'x_fine_emb_MFXL453', 'x_fine_emb_MFXL454', 'x_fine_emb_MFXL455', 'x_fine_emb_MFXL456', 'x_fine_emb_MFXL457', 'x_fine_emb_MFXL458', 'x_fine_emb_MFXL459', 'x_fine_emb_MFXL460', 'x_fine_emb_MFXL461', 'x_fine_emb_MFXL462', 'x_fine_emb_MFXL463', 'x_fine_emb_MFXL464', 'x_fine_emb_MFXL465', 'x_fine_emb_MFXL466', 'x_fine_emb_MFXL467', 'x_fine_emb_MFXL468', 'x_fine_emb_MFXL469', 'x_fine_emb_MFXL470', 'x_fine_emb_MFXL471', 'x_fine_emb_MFXL472', 'x_fine_emb_MFXL473', 'x_fine_emb_MFXL474', 'x_fine_emb_MFXL475', 'x_fine_emb_MFXL476', 'x_fine_emb_MFXL477', 'x_fine_emb_MFXL478', 'x_fine_emb_MFXL479', 'x_fine_emb_MFXL480', 'x_fine_emb_MFXL481', 'x_fine_emb_MFXL482', 'x_fine_emb_MFXL483', 'x_fine_emb_MFXL484', 'x_fine_emb_MFXL485', 'x_fine_emb_MFXL486', 'x_fine_emb_MFXL487', 'x_fine_emb_MFXL488', 'x_fine_emb_MFXL489', 'x_fine_emb_MFXL490', 'x_fine_emb_MFXL491', 'x_fine_emb_MFXL492', 'x_fine_emb_MFXL493', 'x_fine_emb_MFXL494', 'x_fine_emb_MFXL495', 'x_fine_emb_MFXL496', 'x_fine_emb_MFXL497', 'x_fine_emb_MFXL498', 'x_fine_emb_MFXL499', 'x_fine_emb_MFXL500', 'x_fine_emb_MFXL501', 'x_fine_emb_MFXL502', 'x_fine_emb_MFXL503', 'x_fine_emb_MFXL504', 'x_fine_emb_MFXL505', 'x_fine_emb_MFXL506', 'x_fine_emb_MFXL507', 'x_fine_emb_MFXL508', 'x_fine_emb_MFXL509', 'x_fine_emb_MFXL510', 'x_fine_emb_MFXL511', 'x_fine_emb_MFXL512', 'x_fine_emb_MFXL513', 'x_fine_emb_MFXL514', 'x_fine_emb_MFXL515', 'x_fine_emb_MFXL516', 'x_fine_emb_MFXL517', 'x_fine_emb_MFXL518', 'x_fine_emb_MFXL519', 'x_fine_emb_MFXL520', 'x_fine_emb_MFXL521', 'x_fine_emb_MFXL522', 'x_fine_emb_MFXL523', 'x_fine_emb_MFXL524', 'x_fine_emb_MFXL525', 'x_fine_emb_MFXL526', 'x_fine_emb_MFXL527', 'x_fine_emb_MFXL528', 'x_fine_emb_MFXL529', 'x_fine_emb_MFXL530', 'x_fine_emb_MFXL531', 'x_fine_emb_MFXL532', 'x_fine_emb_MFXL533', 'x_fine_emb_MFXL534', 'x_fine_emb_MFXL535', 'x_fine_emb_MFXL536', 'x_fine_emb_MFXL537', 'x_fine_emb_MFXL538', 'x_fine_emb_MFXL539', 'x_fine_emb_MFXL541', 'x_fine_emb_MFXL542', 'x_fine_emb_MFXL543', 'x_fine_emb_MFXL544', 'x_fine_emb_MFXL545', 'x_fine_emb_MFXL546', 'x_fine_emb_MFXL547', 'x_fine_emb_MFXL548', 'x_fine_emb_MFXL549', 'x_fine_emb_MFXL550', 'x_fine_emb_MFXL551', 'x_fine_emb_MFXL552', 'x_fine_emb_MFXL553', 'x_fine_emb_MFXL554', 'x_fine_emb_MFXL555', 'x_fine_emb_MFXL556', 'x_fine_emb_MFXL557', 'x_fine_emb_MFXL558', 'x_fine_emb_MFXL559', 'x_fine_emb_MFXL560', 'x_fine_emb_MFXL561', 'x_fine_emb_MFXL562', 'x_fine_emb_MFXL563', 'x_fine_emb_MFXL564', 'x_fine_emb_MFXL565', 'x_fine_emb_MFXL566', 'x_fine_emb_MFXL567', 'x_fine_emb_MFXL568', 'x_fine_emb_MFXL569', 'x_fine_emb_MFXL570', 'x_fine_emb_MFXL571', 'x_fine_emb_MFXL572', 'x_fine_emb_MFXL573', 'x_fine_emb_MFXL574', 'x_fine_emb_MFXL575', 'x_fine_emb_MFXL576', 'x_fine_emb_MFXL577', 'x_fine_emb_MFXL578', 'x_fine_emb_MFXL579', 'x_fine_emb_MFXL580', 'x_fine_emb_MFXL581', 'x_fine_emb_MFXL582', 'x_fine_emb_MFXL583', 'x_fine_emb_MFXL584', 'x_fine_emb_MFXL585', 'x_fine_emb_MFXL586', 'x_fine_emb_MFXL587', 'x_fine_emb_MFXL588', 'x_fine_emb_MFXL589', 'x_fine_emb_MFXL590', 'x_fine_emb_MFXL591', 'x_fine_emb_MFXL592', 'x_fine_emb_MFXL593', 'x_fine_emb_MFXL594', 'x_fine_emb_MFXL595', 'x_fine_emb_MFXL596', 'x_fine_emb_MFXL597', 'x_fine_emb_MFXL598', 'x_fine_emb_MFXL599', 'x_fine_emb_MFXL600', 'x_fine_emb_MFXL601', 'x_fine_emb_MFXL603', 'x_fine_emb_MFXL604', 'x_fine_emb_MFXL605', 'x_fine_emb_MFXL606', 'x_fine_emb_MFXL607', 'x_fine_emb_MFXL608', 'x_fine_emb_MFXL609', 'x_fine_emb_MFXL610', 'x_fine_emb_MFXL611', 'x_fine_emb_MFXL612', 'x_fine_emb_MFXL613', 'x_fine_emb_MFXL614', 'x_fine_emb_MFXL615', 'x_fine_emb_MFXL616', 'x_fine_emb_MFXL617', 'x_fine_emb_MFXL618', 'x_fine_emb_MFXL619', 'x_fine_emb_MFXL620', 'x_fine_emb_MFXL621', 'x_fine_emb_MFXL622', 'x_fine_emb_MFXL623', 'x_fine_emb_MFXL624', 'x_fine_emb_MFXL625', 'x_fine_emb_MFXL626', 'x_fine_emb_MFXL627', 'x_fine_emb_MFXL628', 'x_fine_emb_MFXL630', 'x_fine_emb_MFXL631', 'x_fine_emb_MFXL632', 'x_fine_emb_MFXL633', 'x_fine_emb_MFXL634', 'x_fine_emb_MFXL635', 'x_fine_emb_MFXL636', 'x_fine_emb_MFXL638', 'x_fine_emb_MFXL639', 'x_fine_emb_MFXL640', 'x_fine_emb_MFXL641', 'x_fine_emb_MFXL642', 'x_fine_emb_MFXL643', 'x_fine_emb_MFXL644', 'x_fine_emb_MFXL645', 'x_fine_emb_MFXL646', 'x_fine_emb_MFXL647', 'x_fine_emb_MFXL648', 'x_fine_emb_MFXL649', 'x_fine_emb_MFXL650', 'x_fine_emb_MFXL651', 'x_fine_emb_MFXL652', 'x_fine_emb_MFXL653', 'x_fine_emb_MFXL654', 'x_fine_emb_MFXL655', 'x_fine_emb_MFXL656', 'x_fine_emb_MFXL657', 'x_fine_emb_MFXL658', 'x_fine_emb_MFXL659', 'x_fine_emb_MFXL660', 'x_fine_emb_MFXL661', 'x_fine_emb_MFXL662', 'x_fine_emb_MFXL663', 'x_fine_emb_MFXL664', 'x_fine_emb_MFXL665', 'x_fine_emb_MFXL666', 'x_fine_emb_MFXL667', 'x_fine_emb_MFXL668', 'x_fine_emb_MFXL669', 'x_fine_emb_MFXL670', 'x_fine_emb_MFXL671', 'x_fine_emb_MFXL672', 'x_fine_emb_MFXL673', 'x_fine_emb_MFXL674', 'x_fine_emb_MFXL675', 'x_fine_emb_MFXL676', 'x_fine_emb_MFXL677', 'x_fine_emb_MFXL678', 'x_fine_emb_MFXL679', 'x_fine_emb_MFXL680', 'x_fine_emb_MFXL681', 'x_fine_emb_MFXL682', 'x_fine_emb_MFXL683', 'x_fine_emb_MFXL684', 'x_fine_emb_MFXL685', 'x_fine_emb_MFXL686', 'x_fine_emb_MFXL687', 'x_fine_emb_MFXL688', 'x_fine_emb_MFXL689', 'x_fine_emb_MFXL690', 'x_fine_emb_MFXL691', 'x_fine_emb_MFXL692', 'x_fine_emb_MFXL693', 'x_fine_emb_MFXL694', 'x_fine_emb_MFXL695', 'x_fine_emb_MFXL696', 'x_fine_emb_MFXL697', 'x_fine_emb_MFXL698', 'x_fine_emb_MFXL699', 'x_fine_emb_MFXL700', 'x_fine_emb_MFXL701', 'x_fine_emb_MFXL702', 'x_fine_emb_MFXL703', 'x_fine_emb_MFXL704', 'x_fine_emb_MFXL705', 'x_fine_emb_MFXL706', 'x_fine_emb_MFXL707', 'x_fine_emb_MFXL708', 'x_fine_emb_MFXL709', 'x_fine_emb_MFXL710', 'x_fine_emb_MFXL711', 'x_fine_emb_MFXL712', 'x_fine_emb_MFXL713', 'x_fine_emb_MFXL714', 'x_fine_emb_MFXL715', 'x_fine_emb_MFXL716', 'x_fine_emb_MFXL717', 'x_fine_emb_MFXL718', 'x_fine_emb_MFXL719', 'x_fine_emb_MFXL720', 'x_fine_emb_MFXL721', 'x_fine_emb_MFXL722', 'x_fine_emb_MFXL723', 'x_fine_emb_MFXL724', 'x_fine_emb_MFXL725', 'x_fine_emb_MFXL726', 'x_fine_emb_MFXL727', 'x_fine_emb_MFXL728', 'x_fine_emb_MFXL729', 'x_fine_emb_MFXL730', 'x_fine_emb_MFXL731', 'x_fine_emb_MFXL732', 'x_fine_emb_MFXL733', 'x_fine_emb_MFXL734', 'x_fine_emb_MFXL735', 'x_fine_emb_MFXL736', 'x_fine_emb_MFXL737', 'x_fine_emb_MFXL738', 'x_fine_emb_MFXL739', 'x_fine_emb_MFXL740', 'x_fine_emb_MFXL741', 'x_fine_emb_MFXL742', 'x_fine_emb_MFXL743', 'x_fine_emb_MFXL744', 'x_fine_emb_MFXL745', 'x_fine_emb_MFXL746', 'x_fine_emb_MFXL747', 'x_fine_emb_MFXL748', 'x_fine_emb_MFXL749', 'x_fine_emb_MFXL750', 'x_fine_emb_MFXL751', 'x_fine_emb_MFXL752', 'x_fine_emb_MFXL753', 'x_fine_emb_MFXL754', 'x_fine_emb_MFXL755', 'x_fine_emb_MFXL756', 'x_fine_emb_MFXL757', 'x_fine_emb_MFXL758', 'x_fine_emb_MFXL759', 'x_fine_emb_MFXL760', 'x_fine_emb_MFXL761', 'x_fine_emb_MFXL762', 'x_fine_emb_MFXL763', 'x_fine_emb_MFXL764', 'x_fine_emb_MFXL765', 'x_fine_emb_MFXL766', 'x_fine_emb_MFXL767', 'Degree_O', 'Degree_N', 'Aromatic']\n",
      "Final Train shape: (1008, 1920)\n",
      "Final Test shape: (252, 1920)\n"
     ]
    }
   ],
   "source": [
    "X_train = merged_train.drop(columns=['ID', 'SMILES']).select_dtypes(include=['number'])\n",
    "selected_final_features = features(X_train, target_column='Permeability')\n",
    "\n",
    "train = pd.concat([merged_train[['ID', 'SMILES', 'Permeability']], X_train[selected_final_features]], axis=1)\n",
    "test = merged_test[train.columns] \n",
    "\n",
    "print('selected_final_features', selected_final_features )\n",
    "print(\"Final Train shape:\", train.shape)\n",
    "print(\"Final Test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ccc1808-a7cd-4320-9497-e80e63b9d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e05dc95-bdde-448d-b5e9-a84516f04f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 1917)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 1917)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249118\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 1653\n",
      "[LightGBM] [Info] Start training from score -6.294177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249128\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 1670\n",
      "[LightGBM] [Info] Start training from score -6.295407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249081\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 1652\n",
      "[LightGBM] [Info] Start training from score -6.270552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249123\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 1664\n",
      "[LightGBM] [Info] Start training from score -6.284236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249111\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 1660\n",
      "[LightGBM] [Info] Start training from score -6.280596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.666178729723111\n",
      "0.5913872284018676\n",
      "0.6537578795777192\n",
      "0.6693726941753484\n",
      "0.6260985159055706\n",
      "0.6489081748654303\n",
      "0.6725229592243207\n",
      "0.003865304588411278\n",
      "0.6987374730027949\n",
      "0.6941421380089813\n",
      "0.31948506754809225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.3129</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.4395</td>\n",
       "      <td>0.6662</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>0.8005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.4364</td>\n",
       "      <td>0.5843</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.7757</td>\n",
       "      <td>0.7399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1755</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.4189</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.4476</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.7881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>0.4374</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.8209</td>\n",
       "      <td>0.8024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>0.4652</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.7795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.4508</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.7877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.7277</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>1.0941</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>1.0460</td>\n",
       "      <td>-0.8045</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>0.5232</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.5721</td>\n",
       "      <td>0.7593</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>0.5864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1877</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.8071</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>0.6987</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.3996</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.8536</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.3236</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>0.6941</td>\n",
       "      <td>0.8355</td>\n",
       "      <td>0.8275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.7842</td>\n",
       "      <td>0.6384</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>-0.2934</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.5949</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.6768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1739                0.3129   \n",
       "DecisionTreeRegressor                    0.3415                0.4364   \n",
       "RandomForestRegressor                    0.1755                0.3124   \n",
       "GradientBoostingRegressor                0.1749                0.3135   \n",
       "AdaBoostRegressor                        0.1932                0.3345   \n",
       "XGBRegressor                             0.2029                0.3333   \n",
       "ExtraTreesRegressor                      0.1651                0.3047   \n",
       "LinearRegression                         1.0941                0.8077   \n",
       "KNeighborsRegressor                      0.1877                0.3190   \n",
       "SVR                                      0.1597                0.2977   \n",
       "MLPRegressor                             0.7842                0.6384   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4170               0.7132   \n",
       "DecisionTreeRegressor                     0.5843               0.4369   \n",
       "RandomForestRegressor                     0.4189               0.7106   \n",
       "GradientBoostingRegressor                 0.4182               0.7115   \n",
       "AdaBoostRegressor                         0.4396               0.6813   \n",
       "XGBRegressor                              0.4505               0.6653   \n",
       "ExtraTreesRegressor                       0.4063               0.7277   \n",
       "LinearRegression                          1.0460              -0.8045   \n",
       "KNeighborsRegressor                       0.4332               0.6905   \n",
       "SVR                                       0.3996               0.7366   \n",
       "MLPRegressor                              0.8856              -0.2934   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8445                0.8281   \n",
       "DecisionTreeRegressor                    0.7184                0.7009   \n",
       "RandomForestRegressor                    0.8436                0.8263   \n",
       "GradientBoostingRegressor                0.8436                0.8244   \n",
       "AdaBoostRegressor                        0.8294                0.8082   \n",
       "XGBRegressor                             0.8174                0.7998   \n",
       "ExtraTreesRegressor                      0.8537                0.8400   \n",
       "LinearRegression                         0.5198                0.5232   \n",
       "KNeighborsRegressor                      0.8340                0.8071   \n",
       "SVR                                      0.8591                0.8536   \n",
       "MLPRegressor                             0.5486                0.5949   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.1932   0.3420    0.4395  0.6662   \n",
       "DecisionTreeRegressor       0.2365   0.3644    0.4863  0.5914   \n",
       "RandomForestRegressor       0.2004   0.3505    0.4476  0.6538   \n",
       "GradientBoostingRegressor   0.1913   0.3409    0.4374  0.6694   \n",
       "AdaBoostRegressor           0.2164   0.3697    0.4652  0.6261   \n",
       "XGBRegressor                0.2032   0.3475    0.4508  0.6489   \n",
       "ExtraTreesRegressor         0.1895   0.3358    0.4353  0.6725   \n",
       "LinearRegression            0.5765   0.5721    0.7593  0.0039   \n",
       "KNeighborsRegressor         0.1743   0.3161    0.4175  0.6987   \n",
       "SVR                         0.1770   0.3236    0.4207  0.6941   \n",
       "MLPRegressor                0.3938   0.4835    0.6276  0.3195   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8183                    0.8005  \n",
       "DecisionTreeRegressor                       0.7757                    0.7399  \n",
       "RandomForestRegressor                       0.8116                    0.7881  \n",
       "GradientBoostingRegressor                   0.8209                    0.8024  \n",
       "AdaBoostRegressor                           0.8024                    0.7795  \n",
       "XGBRegressor                                0.8079                    0.7877  \n",
       "ExtraTreesRegressor                         0.8225                    0.8096  \n",
       "LinearRegression                            0.5820                    0.5864  \n",
       "KNeighborsRegressor                         0.8364                    0.8180  \n",
       "SVR                                         0.8355                    0.8275  \n",
       "MLPRegressor                                0.6474                    0.6768  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = test[X_train.columns]\n",
    "y_test = test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2443cfb-5544-4675-8dfd-bf4b5def6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/combined_features_caco2.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/prediction_combined_features_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26df2f71-68c2-4fa3-be8a-31a2f67d63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['ID', 'SMILES', 'Permeability'])\n",
    "y = train['Permeability']\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=101, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c131ee1e-398c-4528-8feb-6676e8b07018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features:\n",
      "\n",
      "['x_fine_emb_MFXL339', 'x_fine_emb_MFXL263', 'x_fine_emb_MFXL682', 'x_fine_emb_MFXL607', 'x_fine_emb_MFXL411', 'x_fine_emb_MFXL355', 'x_fine_emb_MFXL618', 'x_fine_emb_MFXL287', 'x_fine_emb_MFXL709', 'x_fine_emb_MFXL451']\n"
     ]
    }
   ],
   "source": [
    "#Top 10 features\n",
    "n = 10  \n",
    "top_10_indices = importances.argsort()[::-1][:n]  # indices of top n features\n",
    "top_10_features = feature_names[top_10_indices].tolist() \n",
    "\n",
    "# Output the list\n",
    "print(\"Top\", 10, \"features:\\n\")\n",
    "print(top_10_features)\n",
    "\n",
    "train_df = pd.concat([train[['ID', 'SMILES', 'Permeability']], X[top_10_features]], axis=1)\n",
    "test_df = test[train.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52682902-cfb8-4bf0-99fe-e105c05f0d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 10)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 10)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -6.294177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -6.295407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -6.270552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -6.284236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -6.280596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.608632679057812\n",
      "0.5576280432625158\n",
      "0.62016635791841\n",
      "0.5911393485832279\n",
      "0.5790151942382364\n",
      "0.6011061625489313\n",
      "0.6286262832285828\n",
      "0.5779293535512203\n",
      "0.5692218160699565\n",
      "0.622800227469709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43822206303697686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1937</td>\n",
       "      <td>0.3306</td>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.8257</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.6086</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3532</td>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.5943</td>\n",
       "      <td>0.4174</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.3990</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.7573</td>\n",
       "      <td>0.7289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>0.4688</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.7602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>0.4367</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.2366</td>\n",
       "      <td>0.3871</td>\n",
       "      <td>0.4864</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.3620</td>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.8044</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.2436</td>\n",
       "      <td>0.4006</td>\n",
       "      <td>0.4936</td>\n",
       "      <td>0.5790</td>\n",
       "      <td>0.7732</td>\n",
       "      <td>0.7447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>0.3708</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.6011</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.7427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8070</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.7705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>0.4453</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.8204</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.2443</td>\n",
       "      <td>0.4013</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0.7464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.3496</td>\n",
       "      <td>0.4617</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.7735</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.7643</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1937</td>\n",
       "      <td>0.3262</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.4672</td>\n",
       "      <td>0.6228</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.7620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.5063</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.4501</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.4382</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.6748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1937                0.3306   \n",
       "DecisionTreeRegressor                    0.3532                0.4518   \n",
       "RandomForestRegressor                    0.1862                0.3246   \n",
       "GradientBoostingRegressor                0.1907                0.3273   \n",
       "AdaBoostRegressor                        0.2178                0.3620   \n",
       "XGBRegressor                             0.2146                0.3489   \n",
       "ExtraTreesRegressor                      0.1867                0.3260   \n",
       "LinearRegression                         0.1983                0.3465   \n",
       "KNeighborsRegressor                      0.2132                0.3496   \n",
       "SVR                                      0.1937                0.3262   \n",
       "MLPRegressor                             0.2994                0.4246   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4402               0.6805   \n",
       "DecisionTreeRegressor                     0.5943               0.4174   \n",
       "RandomForestRegressor                     0.4315               0.6929   \n",
       "GradientBoostingRegressor                 0.4367               0.6855   \n",
       "AdaBoostRegressor                         0.4666               0.6409   \n",
       "XGBRegressor                              0.4633               0.6460   \n",
       "ExtraTreesRegressor                       0.4321               0.6921   \n",
       "LinearRegression                          0.4453               0.6730   \n",
       "KNeighborsRegressor                       0.4617               0.6485   \n",
       "SVR                                       0.4401               0.6805   \n",
       "MLPRegressor                              0.5471               0.5063   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8257                0.8029   \n",
       "DecisionTreeRegressor                    0.7164                0.6926   \n",
       "RandomForestRegressor                    0.8324                0.8100   \n",
       "GradientBoostingRegressor                0.8284                0.8050   \n",
       "AdaBoostRegressor                        0.8044                0.7795   \n",
       "XGBRegressor                             0.8076                0.7857   \n",
       "ExtraTreesRegressor                      0.8320                0.8070   \n",
       "LinearRegression                         0.8204                0.8047   \n",
       "KNeighborsRegressor                      0.8100                0.7735   \n",
       "SVR                                      0.8254                0.8017   \n",
       "MLPRegressor                             0.7397                0.7343   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2265   0.3757    0.4759  0.6086   \n",
       "DecisionTreeRegressor       0.2560   0.3990    0.5060  0.5576   \n",
       "RandomForestRegressor       0.2198   0.3718    0.4688  0.6202   \n",
       "GradientBoostingRegressor   0.2366   0.3871    0.4864  0.5911   \n",
       "AdaBoostRegressor           0.2436   0.4006    0.4936  0.5790   \n",
       "XGBRegressor                0.2308   0.3708    0.4805  0.6011   \n",
       "ExtraTreesRegressor         0.2149   0.3677    0.4636  0.6286   \n",
       "LinearRegression            0.2443   0.4013    0.4942  0.5779   \n",
       "KNeighborsRegressor         0.2493   0.3879    0.4993  0.5692   \n",
       "SVR                         0.2183   0.3654    0.4672  0.6228   \n",
       "MLPRegressor                0.3251   0.4501    0.5702  0.4382   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7826                    0.7491  \n",
       "DecisionTreeRegressor                       0.7573                    0.7289  \n",
       "RandomForestRegressor                       0.7906                    0.7602  \n",
       "GradientBoostingRegressor                   0.7724                    0.7378  \n",
       "AdaBoostRegressor                           0.7732                    0.7447  \n",
       "XGBRegressor                                0.7780                    0.7427  \n",
       "ExtraTreesRegressor                         0.7960                    0.7705  \n",
       "LinearRegression                            0.7648                    0.7464  \n",
       "KNeighborsRegressor                         0.7643                    0.7216  \n",
       "SVR                                         0.7906                    0.7620  \n",
       "MLPRegressor                                0.6926                    0.6748  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_df['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = test_df[X_train.columns]\n",
    "y_test = test_df['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fb1dd15-a461-4430-b982-e9b75146b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/combined_top_10_features_caco2.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/prediction_combined_top_10_features_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807e39af-3eef-4307-bc39-cfa71fd1b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features:\n",
      "\n",
      "['x_fine_emb_MFXL339', 'x_fine_emb_MFXL263', 'x_fine_emb_MFXL682', 'x_fine_emb_MFXL607', 'x_fine_emb_MFXL411', 'x_fine_emb_MFXL355', 'x_fine_emb_MFXL618', 'x_fine_emb_MFXL287', 'x_fine_emb_MFXL709', 'x_fine_emb_MFXL451', 'x_fine_emb_MFXL139', 'x_fine_emb_MFXL22', 'x_fine_emb_MFXL250', 'x_fine_emb_MFXL399', 'x_fine_emb_MFXL466', 'x_fine_emb_MFXL388', 'x_fine_emb_MFXL420', 'x_fine_emb_MFXL209', 'x_fine_emb_MFXL753', 'x_fine_emb_MFXL208']\n"
     ]
    }
   ],
   "source": [
    "#Top 20 features\n",
    "n = 20  \n",
    "top_20_indices = importances.argsort()[::-1][:n]  \n",
    "top_20_features = feature_names[top_20_indices].tolist()  # convert to list\n",
    "\n",
    "# Output the list\n",
    "print(\"Top\", 20, \"features:\\n\")\n",
    "print(top_20_features)\n",
    "\n",
    "train_df = pd.concat([train[['ID', 'SMILES', 'Permeability']], X[top_20_features]], axis=1)\n",
    "test_df = test[train.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296c3f45-e763-4e29-b09a-5cba67e154ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 20)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 20)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -6.294177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -6.295407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -6.270552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -6.284236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -6.280596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6155574919936736\n",
      "0.5603017323362447\n",
      "0.6399102272808589\n",
      "0.6202644837512442\n",
      "0.59653119644323\n",
      "0.6353508211224199\n",
      "0.6410793274048197\n",
      "0.5881311484740517\n",
      "0.6283192752366152\n",
      "0.6465269939497434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21894296441390593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.8267</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.3685</td>\n",
       "      <td>0.4717</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>0.7558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.4282</td>\n",
       "      <td>0.5784</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.5603</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.7308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.4271</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.8362</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>0.2084</td>\n",
       "      <td>0.3601</td>\n",
       "      <td>0.4565</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.8026</td>\n",
       "      <td>0.7775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>0.4688</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.2088</td>\n",
       "      <td>0.3541</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>0.7655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2097</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.6354</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.7722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.8335</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.4558</td>\n",
       "      <td>0.6411</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>0.7827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>0.8093</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>0.7707</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.8209</td>\n",
       "      <td>0.7891</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.7640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1911</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.8282</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.4523</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.7767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4298</td>\n",
       "      <td>0.5089</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>0.6675</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.4520</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.6135</td>\n",
       "      <td>0.5984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1925                0.3335   \n",
       "DecisionTreeRegressor                    0.3345                0.4282   \n",
       "RandomForestRegressor                    0.1824                0.3256   \n",
       "GradientBoostingRegressor                0.1918                0.3298   \n",
       "AdaBoostRegressor                        0.2088                0.3541   \n",
       "XGBRegressor                             0.2097                0.3468   \n",
       "ExtraTreesRegressor                      0.1852                0.3257   \n",
       "LinearRegression                         0.1950                0.3454   \n",
       "KNeighborsRegressor                      0.2010                0.3387   \n",
       "SVR                                      0.1911                0.3247   \n",
       "MLPRegressor                             0.4298                0.5089   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4388               0.6825   \n",
       "DecisionTreeRegressor                     0.5784               0.4483   \n",
       "RandomForestRegressor                     0.4271               0.6991   \n",
       "GradientBoostingRegressor                 0.4380               0.6836   \n",
       "AdaBoostRegressor                         0.4570               0.6556   \n",
       "XGBRegressor                              0.4579               0.6542   \n",
       "ExtraTreesRegressor                       0.4303               0.6946   \n",
       "LinearRegression                          0.4416               0.6784   \n",
       "KNeighborsRegressor                       0.4483               0.6685   \n",
       "SVR                                       0.4371               0.6849   \n",
       "MLPRegressor                              0.6556               0.2912   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8267                0.8027   \n",
       "DecisionTreeRegressor                    0.7306                0.7104   \n",
       "RandomForestRegressor                    0.8362                0.8129   \n",
       "GradientBoostingRegressor                0.8272                0.8034   \n",
       "AdaBoostRegressor                        0.8141                0.7895   \n",
       "XGBRegressor                             0.8112                0.7853   \n",
       "ExtraTreesRegressor                      0.8335                0.8086   \n",
       "LinearRegression                         0.8237                0.8093   \n",
       "KNeighborsRegressor                      0.8209                0.7891   \n",
       "SVR                                      0.8282                0.8076   \n",
       "MLPRegressor                             0.6675                0.6444   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2225   0.3685    0.4717  0.6156   \n",
       "DecisionTreeRegressor       0.2545   0.3816    0.5044  0.5603   \n",
       "RandomForestRegressor       0.2084   0.3601    0.4565  0.6399   \n",
       "GradientBoostingRegressor   0.2198   0.3670    0.4688  0.6203   \n",
       "AdaBoostRegressor           0.2335   0.3933    0.4832  0.5965   \n",
       "XGBRegressor                0.2110   0.3642    0.4594  0.6354   \n",
       "ExtraTreesRegressor         0.2077   0.3588    0.4558  0.6411   \n",
       "LinearRegression            0.2384   0.3964    0.4882  0.5881   \n",
       "KNeighborsRegressor         0.2151   0.3569    0.4638  0.6283   \n",
       "SVR                         0.2046   0.3503    0.4523  0.6465   \n",
       "MLPRegressor                0.4520   0.5340    0.6723  0.2189   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7879                    0.7558  \n",
       "DecisionTreeRegressor                       0.7647                    0.7308  \n",
       "RandomForestRegressor                       0.8026                    0.7775  \n",
       "GradientBoostingRegressor                   0.7907                    0.7600  \n",
       "AdaBoostRegressor                           0.7869                    0.7655  \n",
       "XGBRegressor                                0.7998                    0.7722  \n",
       "ExtraTreesRegressor                         0.8036                    0.7827  \n",
       "LinearRegression                            0.7707                    0.7549  \n",
       "KNeighborsRegressor                         0.7964                    0.7640  \n",
       "SVR                                         0.8048                    0.7767  \n",
       "MLPRegressor                                0.6135                    0.5984  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_df['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = test_df[X_train.columns]\n",
    "y_test = test_df['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b9d723c-c7ea-4881-8ded-b0f983d0006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/combined_top_20_features_caco2.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/prediction_combined_top_20_features_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dbaa1a7-eb2e-4ece-8f86-c42627456cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 features:\n",
      "\n",
      "['x_fine_emb_MFXL339', 'x_fine_emb_MFXL263', 'x_fine_emb_MFXL682', 'x_fine_emb_MFXL607', 'x_fine_emb_MFXL411', 'x_fine_emb_MFXL355', 'x_fine_emb_MFXL618', 'x_fine_emb_MFXL287', 'x_fine_emb_MFXL709', 'x_fine_emb_MFXL451', 'x_fine_emb_MFXL139', 'x_fine_emb_MFXL22', 'x_fine_emb_MFXL250', 'x_fine_emb_MFXL399', 'x_fine_emb_MFXL466', 'x_fine_emb_MFXL388', 'x_fine_emb_MFXL420', 'x_fine_emb_MFXL209', 'x_fine_emb_MFXL753', 'x_fine_emb_MFXL208', 'x_fine_emb_MFXL571', 'x_fine_emb_MFXL333', 'x_fine_emb_MFXL530', 'x_fine_emb_MFXL359', 'x_fine_emb_MFXL659', 'x_fine_emb_MFXL678', 'x_fine_emb_MFXL721', 'x_fine_emb_MFXL675', 'x_fine_emb_MFXL76', 'ATSC.7', 'x_fine_emb_MFXL632', 'x_fine_emb_MFXL33', 'x_fine_emb_MFXL517', 'ATSC8s', 'x_fine_emb_MFXL184', 'x_fine_emb_MFXL100', 'x_fine_emb_MFXL275', 'x_fine_emb_MFXL315', 'x_fine_emb_MFXL667', 'x_fine_emb_MFXL88', 'maxHBint6', 'x_fine_emb_MFXL660', 'x_fine_emb_MFXL62', 'x_fine_emb_MFXL169', 'x_fine_emb_MFXL604', 'x_fine_emb_MFXL136', 'x_fine_emb_MFXL103', 'x_fine_emb_MFXL168', 'x_fine_emb_MFXL695', 'x_fine_emb_MFXL41']\n"
     ]
    }
   ],
   "source": [
    "#Top 50 features\n",
    "n = 50  \n",
    "top_50_indices = importances.argsort()[::-1][:n] \n",
    "top_50_features = feature_names[top_50_indices].tolist()  # convert to list\n",
    "\n",
    "# Output the list\n",
    "print(\"Top\", 50, \"features:\\n\")\n",
    "print(top_50_features)\n",
    "\n",
    "train_df = pd.concat([train[['ID', 'SMILES', 'Permeability']], X[top_50_features]], axis=1)\n",
    "test_df = test[train.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2cba639-77a7-4175-b20d-618197baefea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 50)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 50)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -6.294177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -6.295407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -6.270552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -6.284236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -6.280596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6430001626358259\n",
      "0.5672070783318917\n",
      "0.653746763770987\n",
      "0.6446150323094184\n",
      "0.624056008078725\n",
      "0.6352411297426115\n",
      "0.649061989238263\n",
      "0.6218461460283882\n",
      "0.6265855035314896\n",
      "0.6329900390603103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12784119242402636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.3137</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.7809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3211</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.3878</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.7325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1716</td>\n",
       "      <td>0.3099</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.3476</td>\n",
       "      <td>0.4476</td>\n",
       "      <td>0.6537</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>0.7842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.3177</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.7826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.3373</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>0.7806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.3314</td>\n",
       "      <td>0.4419</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.7743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.4138</td>\n",
       "      <td>0.7176</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.7922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.8359</td>\n",
       "      <td>0.8208</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>0.7914</td>\n",
       "      <td>0.7719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>0.4405</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.8282</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.4649</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.7751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1736</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.7969</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4749</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.6134</td>\n",
       "      <td>0.5944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1739                0.3137   \n",
       "DecisionTreeRegressor                    0.3211                0.4200   \n",
       "RandomForestRegressor                    0.1716                0.3099   \n",
       "GradientBoostingRegressor                0.1773                0.3177   \n",
       "AdaBoostRegressor                        0.1910                0.3373   \n",
       "XGBRegressor                             0.1953                0.3314   \n",
       "ExtraTreesRegressor                      0.1712                0.3103   \n",
       "LinearRegression                         0.1830                0.3300   \n",
       "KNeighborsRegressor                      0.1941                0.3252   \n",
       "SVR                                      0.1736                0.3095   \n",
       "MLPRegressor                             0.4749                0.5368   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4170               0.7132   \n",
       "DecisionTreeRegressor                     0.5667               0.4704   \n",
       "RandomForestRegressor                     0.4143               0.7169   \n",
       "GradientBoostingRegressor                 0.4211               0.7075   \n",
       "AdaBoostRegressor                         0.4371               0.6850   \n",
       "XGBRegressor                              0.4419               0.6780   \n",
       "ExtraTreesRegressor                       0.4138               0.7176   \n",
       "LinearRegression                          0.4278               0.6982   \n",
       "KNeighborsRegressor                       0.4405               0.6799   \n",
       "SVR                                       0.4166               0.7137   \n",
       "MLPRegressor                              0.6891               0.2168   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8447                0.8271   \n",
       "DecisionTreeRegressor                    0.7392                0.7129   \n",
       "RandomForestRegressor                    0.8468                0.8272   \n",
       "GradientBoostingRegressor                0.8412                0.8197   \n",
       "AdaBoostRegressor                        0.8324                0.8125   \n",
       "XGBRegressor                             0.8251                0.8032   \n",
       "ExtraTreesRegressor                      0.8472                0.8293   \n",
       "LinearRegression                         0.8359                0.8208   \n",
       "KNeighborsRegressor                      0.8282                0.8054   \n",
       "SVR                                      0.8451                0.8293   \n",
       "MLPRegressor                             0.6641                0.6507   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2066   0.3479    0.4545  0.6430   \n",
       "DecisionTreeRegressor       0.2505   0.3878    0.5005  0.5672   \n",
       "RandomForestRegressor       0.2004   0.3476    0.4476  0.6537   \n",
       "GradientBoostingRegressor   0.2057   0.3515    0.4535  0.6446   \n",
       "AdaBoostRegressor           0.2176   0.3737    0.4664  0.6241   \n",
       "XGBRegressor                0.2111   0.3564    0.4595  0.6352   \n",
       "ExtraTreesRegressor         0.2031   0.3501    0.4507  0.6491   \n",
       "LinearRegression            0.2188   0.3793    0.4678  0.6218   \n",
       "KNeighborsRegressor         0.2161   0.3583    0.4649  0.6266   \n",
       "SVR                         0.2124   0.3505    0.4609  0.6330   \n",
       "MLPRegressor                0.5047   0.5457    0.7104  0.1278   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8042                    0.7809  \n",
       "DecisionTreeRegressor                       0.7635                    0.7325  \n",
       "RandomForestRegressor                       0.8104                    0.7842  \n",
       "GradientBoostingRegressor                   0.8057                    0.7826  \n",
       "AdaBoostRegressor                           0.8018                    0.7806  \n",
       "XGBRegressor                                0.7990                    0.7743  \n",
       "ExtraTreesRegressor                         0.8077                    0.7922  \n",
       "LinearRegression                            0.7914                    0.7719  \n",
       "KNeighborsRegressor                         0.7967                    0.7751  \n",
       "SVR                                         0.7969                    0.7710  \n",
       "MLPRegressor                                0.6134                    0.5944  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_df['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = test_df[X_train.columns]\n",
    "y_test = test_df['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5ed9ed4-4e5e-4a1c-a98e-642c4504ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/combined_top_50_features_caco2.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/prediction_combined_top_50_features_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0325323d-d0bd-4e33-bd6f-bce78b425f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 features:\n",
      "\n",
      "['x_fine_emb_MFXL339', 'x_fine_emb_MFXL263', 'x_fine_emb_MFXL682', 'x_fine_emb_MFXL607', 'x_fine_emb_MFXL411', 'x_fine_emb_MFXL355', 'x_fine_emb_MFXL618', 'x_fine_emb_MFXL287', 'x_fine_emb_MFXL709', 'x_fine_emb_MFXL451', 'x_fine_emb_MFXL139', 'x_fine_emb_MFXL22', 'x_fine_emb_MFXL250', 'x_fine_emb_MFXL399', 'x_fine_emb_MFXL466', 'x_fine_emb_MFXL388', 'x_fine_emb_MFXL420', 'x_fine_emb_MFXL209', 'x_fine_emb_MFXL753', 'x_fine_emb_MFXL208', 'x_fine_emb_MFXL571', 'x_fine_emb_MFXL333', 'x_fine_emb_MFXL530', 'x_fine_emb_MFXL359', 'x_fine_emb_MFXL659', 'x_fine_emb_MFXL678', 'x_fine_emb_MFXL721', 'x_fine_emb_MFXL675', 'x_fine_emb_MFXL76', 'ATSC.7', 'x_fine_emb_MFXL632', 'x_fine_emb_MFXL33', 'x_fine_emb_MFXL517', 'ATSC8s', 'x_fine_emb_MFXL184', 'x_fine_emb_MFXL100', 'x_fine_emb_MFXL275', 'x_fine_emb_MFXL315', 'x_fine_emb_MFXL667', 'x_fine_emb_MFXL88', 'maxHBint6', 'x_fine_emb_MFXL660', 'x_fine_emb_MFXL62', 'x_fine_emb_MFXL169', 'x_fine_emb_MFXL604', 'x_fine_emb_MFXL136', 'x_fine_emb_MFXL103', 'x_fine_emb_MFXL168', 'x_fine_emb_MFXL695', 'x_fine_emb_MFXL41', 'x_fine_emb_MFXL151', 'SpMax7_Bhs', 'AATSC.9', 'x_fine_emb_MFXL387', 'x_fine_emb_MFXL541', 'maxHBint2', 'x_fine_emb_MFXL581', 'x_fine_emb_MFXL478', 'x_fine_emb_MFXL224', 'x_fine_emb_MFXL543', 'maxHBd', 'x_fine_emb_MFXL73', 'x_fine_emb_MFXL496', 'x_fine_emb_MFXL142', 'x_fine_emb_MFXL524', 'x_fine_emb_MFXL479', 'x_fine_emb_MFXL361', 'x_fine_emb_MFXL523', 'maxHBint9', 'x_fine_emb_MFXL611', 'x_fine_emb_MFXL14', 'x_fine_emb_MFXL674', 'x_fine_emb_MFXL500', 'x_fine_emb_MFXL623', 'x_fine_emb_MFXL200', 'x_fine_emb_MFXL21', 'x_fine_emb_MFXL641', 'x_fine_emb_MFXL454', 'x_fine_emb_MFXL379', 'x_fine_emb_MFXL480', 'x_fine_emb_MFXL273', 'x_fine_emb_MFXL473', 'x_fine_emb_MFXL593', 'x_fine_emb_MFXL766', 'x_fine_emb_MFXL351', 'x_fine_emb_MFXL553', 'x_fine_emb_MFXL630', 'x_fine_emb_MFXL237', 'x_fine_emb_MFXL589', 'x_fine_emb_MFXL751', 'x_fine_emb_MFXL329', 'MOMI-XY', 'x_fine_emb_MFXL691', 'x_fine_emb_MFXL248', 'x_fine_emb_MFXL463', 'x_fine_emb_MFXL244', 'x_fine_emb_MFXL572', 'x_fine_emb_MFXL736', 'qed', 'x_fine_emb_MFXL384']\n"
     ]
    }
   ],
   "source": [
    "#Top 100 features\n",
    "n = 100  \n",
    "top_100_indices = importances.argsort()[::-1][:n]  # indices of top n features\n",
    "top_100_features = feature_names[top_100_indices].tolist()  # convert to list\n",
    "\n",
    "# Output the list\n",
    "print(\"Top\", 100, \"features:\\n\")\n",
    "print(top_100_features)\n",
    "\n",
    "train_df = pd.concat([train[['ID', 'SMILES', 'Permeability']], X[top_100_features]], axis=1)\n",
    "test_df = test[train.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2022b727-3da2-448b-b1fb-6686ebf45c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 100)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 100)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 25498\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -6.294177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25498\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -6.295407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25499\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -6.270552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25498\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -6.284236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -6.280596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6610357266280446\n",
      "0.6045223718097494\n",
      "0.6577644129658351\n",
      "0.6475373508268062\n",
      "0.6256370307635661\n",
      "0.6544742477287986\n",
      "0.6539427213780885\n",
      "0.6173320389827031\n",
      "0.6647266918139422\n",
      "0.6565315690461642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12093306381170499\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1682</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.4101</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.8502</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.3437</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.7986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.7473</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>0.2289</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.7534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.7926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.3146</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>0.7885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.8012</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.3328</td>\n",
       "      <td>0.4405</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.8257</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.7957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>0.4072</td>\n",
       "      <td>0.7265</td>\n",
       "      <td>0.8526</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1777</td>\n",
       "      <td>0.3226</td>\n",
       "      <td>0.4216</td>\n",
       "      <td>0.7069</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>0.8331</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.7741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1835</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.4284</td>\n",
       "      <td>0.6973</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.3359</td>\n",
       "      <td>0.4405</td>\n",
       "      <td>0.6647</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.8034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>0.4079</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.8404</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.3389</td>\n",
       "      <td>0.4458</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.5087</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>0.6034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1682                0.3077   \n",
       "DecisionTreeRegressor                    0.3072                0.4107   \n",
       "RandomForestRegressor                    0.1681                0.3054   \n",
       "GradientBoostingRegressor                0.1747                0.3146   \n",
       "AdaBoostRegressor                        0.1879                0.3348   \n",
       "XGBRegressor                             0.1940                0.3328   \n",
       "ExtraTreesRegressor                      0.1658                0.3032   \n",
       "LinearRegression                         0.1777                0.3226   \n",
       "KNeighborsRegressor                      0.1835                0.3207   \n",
       "SVR                                      0.1664                0.3027   \n",
       "MLPRegressor                             0.4731                0.5351   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4101               0.7226   \n",
       "DecisionTreeRegressor                     0.5543               0.4933   \n",
       "RandomForestRegressor                     0.4100               0.7227   \n",
       "GradientBoostingRegressor                 0.4179               0.7119   \n",
       "AdaBoostRegressor                         0.4335               0.6901   \n",
       "XGBRegressor                              0.4405               0.6800   \n",
       "ExtraTreesRegressor                       0.4072               0.7265   \n",
       "LinearRegression                          0.4216               0.7069   \n",
       "KNeighborsRegressor                       0.4284               0.6973   \n",
       "SVR                                       0.4079               0.7256   \n",
       "MLPRegressor                              0.6878               0.2197   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8502                0.8311   \n",
       "DecisionTreeRegressor                    0.7473                0.7112   \n",
       "RandomForestRegressor                    0.8504                0.8311   \n",
       "GradientBoostingRegressor                0.8438                0.8258   \n",
       "AdaBoostRegressor                        0.8347                0.8176   \n",
       "XGBRegressor                             0.8257                0.8051   \n",
       "ExtraTreesRegressor                      0.8526                0.8360   \n",
       "LinearRegression                         0.8416                0.8331   \n",
       "KNeighborsRegressor                      0.8390                0.8098   \n",
       "SVR                                      0.8520                0.8404   \n",
       "MLPRegressor                             0.6610                0.6476   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.1962   0.3437    0.4429  0.6610   \n",
       "DecisionTreeRegressor       0.2289   0.3613    0.4784  0.6045   \n",
       "RandomForestRegressor       0.1981   0.3462    0.4450  0.6578   \n",
       "GradientBoostingRegressor   0.2040   0.3501    0.4516  0.6475   \n",
       "AdaBoostRegressor           0.2167   0.3721    0.4655  0.6256   \n",
       "XGBRegressor                0.2000   0.3458    0.4472  0.6545   \n",
       "ExtraTreesRegressor         0.2003   0.3489    0.4475  0.6539   \n",
       "LinearRegression            0.2215   0.3751    0.4706  0.6173   \n",
       "KNeighborsRegressor         0.1940   0.3359    0.4405  0.6647   \n",
       "SVR                         0.1988   0.3389    0.4458  0.6565   \n",
       "MLPRegressor                0.5087   0.5695    0.7133  0.1209   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8147                    0.7986  \n",
       "DecisionTreeRegressor                       0.7853                    0.7534  \n",
       "RandomForestRegressor                       0.8132                    0.7926  \n",
       "GradientBoostingRegressor                   0.8064                    0.7885  \n",
       "AdaBoostRegressor                           0.8012                    0.7888  \n",
       "XGBRegressor                                0.8110                    0.7957  \n",
       "ExtraTreesRegressor                         0.8106                    0.7945  \n",
       "LinearRegression                            0.7909                    0.7741  \n",
       "KNeighborsRegressor                         0.8175                    0.8034  \n",
       "SVR                                         0.8109                    0.7964  \n",
       "MLPRegressor                                0.6079                    0.6034  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_df['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = test_df[X_train.columns]\n",
    "y_test = test_df['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56df2888-64b6-400d-a05d-72a26c16ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/combined_top_100_features_caco2.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/prediction_combined_top_100_features_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "380297fb-8d27-4889-8167-b32574df5461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 200 features:\n",
      "\n",
      "['x_fine_emb_MFXL339', 'x_fine_emb_MFXL263', 'x_fine_emb_MFXL682', 'x_fine_emb_MFXL607', 'x_fine_emb_MFXL411', 'x_fine_emb_MFXL355', 'x_fine_emb_MFXL618', 'x_fine_emb_MFXL287', 'x_fine_emb_MFXL709', 'x_fine_emb_MFXL451', 'x_fine_emb_MFXL139', 'x_fine_emb_MFXL22', 'x_fine_emb_MFXL250', 'x_fine_emb_MFXL399', 'x_fine_emb_MFXL466', 'x_fine_emb_MFXL388', 'x_fine_emb_MFXL420', 'x_fine_emb_MFXL209', 'x_fine_emb_MFXL753', 'x_fine_emb_MFXL208', 'x_fine_emb_MFXL571', 'x_fine_emb_MFXL333', 'x_fine_emb_MFXL530', 'x_fine_emb_MFXL359', 'x_fine_emb_MFXL659', 'x_fine_emb_MFXL678', 'x_fine_emb_MFXL721', 'x_fine_emb_MFXL675', 'x_fine_emb_MFXL76', 'ATSC.7', 'x_fine_emb_MFXL632', 'x_fine_emb_MFXL33', 'x_fine_emb_MFXL517', 'ATSC8s', 'x_fine_emb_MFXL184', 'x_fine_emb_MFXL100', 'x_fine_emb_MFXL275', 'x_fine_emb_MFXL315', 'x_fine_emb_MFXL667', 'x_fine_emb_MFXL88', 'maxHBint6', 'x_fine_emb_MFXL660', 'x_fine_emb_MFXL62', 'x_fine_emb_MFXL169', 'x_fine_emb_MFXL604', 'x_fine_emb_MFXL136', 'x_fine_emb_MFXL103', 'x_fine_emb_MFXL168', 'x_fine_emb_MFXL695', 'x_fine_emb_MFXL41', 'x_fine_emb_MFXL151', 'SpMax7_Bhs', 'AATSC.9', 'x_fine_emb_MFXL387', 'x_fine_emb_MFXL541', 'maxHBint2', 'x_fine_emb_MFXL581', 'x_fine_emb_MFXL478', 'x_fine_emb_MFXL224', 'x_fine_emb_MFXL543', 'maxHBd', 'x_fine_emb_MFXL73', 'x_fine_emb_MFXL496', 'x_fine_emb_MFXL142', 'x_fine_emb_MFXL524', 'x_fine_emb_MFXL479', 'x_fine_emb_MFXL361', 'x_fine_emb_MFXL523', 'maxHBint9', 'x_fine_emb_MFXL611', 'x_fine_emb_MFXL14', 'x_fine_emb_MFXL674', 'x_fine_emb_MFXL500', 'x_fine_emb_MFXL623', 'x_fine_emb_MFXL200', 'x_fine_emb_MFXL21', 'x_fine_emb_MFXL641', 'x_fine_emb_MFXL454', 'x_fine_emb_MFXL379', 'x_fine_emb_MFXL480', 'x_fine_emb_MFXL273', 'x_fine_emb_MFXL473', 'x_fine_emb_MFXL593', 'x_fine_emb_MFXL766', 'x_fine_emb_MFXL351', 'x_fine_emb_MFXL553', 'x_fine_emb_MFXL630', 'x_fine_emb_MFXL237', 'x_fine_emb_MFXL589', 'x_fine_emb_MFXL751', 'x_fine_emb_MFXL329', 'MOMI-XY', 'x_fine_emb_MFXL691', 'x_fine_emb_MFXL248', 'x_fine_emb_MFXL463', 'x_fine_emb_MFXL244', 'x_fine_emb_MFXL572', 'x_fine_emb_MFXL736', 'qed', 'x_fine_emb_MFXL384', 'x_fine_emb_MFXL177', 'maxssCH2', 'SHBint4', 'x_fine_emb_MFXL187', 'x_fine_emb_MFXL337', 'x_fine_emb_MFXL325', 'x_fine_emb_MFXL175', 'x_fine_emb_MFXL456', 'x_fine_emb_MFXL29', 'minHBint8', 'maxHsOH', 'x_fine_emb_MFXL79', 'x_fine_emb_MFXL178', 'ATSC5c', 'x_fine_emb_MFXL508', 'x_fine_emb_MFXL461', 'x_fine_emb_MFXL740', 'x_fine_emb_MFXL338', 'x_fine_emb_MFXL249', 'x_fine_emb_MFXL693', 'x_fine_emb_MFXL161', 'x_fine_emb_MFXL764', 'x_fine_emb_MFXL196', 'x_fine_emb_MFXL741', 'x_fine_emb_MFXL616', 'KRFPC435', 'x_fine_emb_MFXL185', 'x_fine_emb_MFXL563', 'x_fine_emb_MFXL35', 'x_fine_emb_MFXL546', 'AATS.5', 'GATS2c', 'x_fine_emb_MFXL72', 'x_fine_emb_MFXL696', 'x_fine_emb_MFXL144', 'x_fine_emb_MFXL509', 'x_fine_emb_MFXL689', 'x_fine_emb_MFXL435', 'x_fine_emb_MFXL331', 'x_fine_emb_MFXL422', 'x_fine_emb_MFXL233', 'x_fine_emb_MFXL580', 'x_fine_emb_MFXL47', '3d_rdkit_11', 'IC1', 'TDB3i', 'x_fine_emb_MFXL609', 'x_fine_emb_MFXL750', 'x_fine_emb_MFXL585', 'x_fine_emb_MFXL53', 'BCUTp-1l', 'x_fine_emb_MFXL574', 'x_fine_emb_MFXL49', 'x_fine_emb_MFXL460', 'x_fine_emb_MFXL19', 'AtomTypeEState.170', 'x_fine_emb_MFXL90', 'x_fine_emb_MFXL700', 'x_fine_emb_MFXL240', 'x_fine_emb_MFXL243', 'x_fine_emb_MFXL215', 'x_fine_emb_MFXL357', 'x_fine_emb_MFXL368', 'x_fine_emb_MFXL633', 'x_fine_emb_MFXL724', 'x_fine_emb_MFXL733', 'XLogP', 'x_fine_emb_MFXL191', 'AATSC.14', 'TPSA_y', 'x_fine_emb_MFXL380', 'x_fine_emb_MFXL672', 'x_fine_emb_MFXL483', 'x_fine_emb_MFXL676', 'x_fine_emb_MFXL75', 'x_fine_emb_MFXL314', 'x_fine_emb_MFXL603', 'minsCH3', 'x_fine_emb_MFXL619', 'ATSC.75', 'x_fine_emb_MFXL230', 'x_fine_emb_MFXL149', 'x_fine_emb_MFXL381', 'x_fine_emb_MFXL320', 'count_fp_881', 'ATSC3s', 'x_fine_emb_MFXL560', 'TDB5i', 'x_fine_emb_MFXL537', 'LOBMIN', 'x_fine_emb_MFXL610', 'x_fine_emb_MFXL464', 'x_fine_emb_MFXL450', 'x_fine_emb_MFXL297', 'TDB5e', 'x_fine_emb_MFXL17', 'x_fine_emb_MFXL109', 'x_fine_emb_MFXL111', 'minssCH2', 'maxHBint3']\n"
     ]
    }
   ],
   "source": [
    "#Top 200 features\n",
    "n = 200  \n",
    "top_200_indices = importances.argsort()[::-1][:n]  # indices of top n features\n",
    "top_200_features = feature_names[top_200_indices].tolist()  # convert to list\n",
    "\n",
    "# Output the list\n",
    "print(\"Top\", 200, \"features:\\n\")\n",
    "print(top_200_features)\n",
    "\n",
    "train_df = pd.concat([train[['ID', 'SMILES', 'Permeability']], X[top_200_features]], axis=1)\n",
    "test_df = test[train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd5994aa-4d09-4af1-bea3-03a4503eea82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 200)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 200)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50496\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 200\n",
      "[LightGBM] [Info] Start training from score -6.294177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50494\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 200\n",
      "[LightGBM] [Info] Start training from score -6.295407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50496\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 200\n",
      "[LightGBM] [Info] Start training from score -6.270552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50494\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 200\n",
      "[LightGBM] [Info] Start training from score -6.284236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50496\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 200\n",
      "[LightGBM] [Info] Start training from score -6.280596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6598784992543906\n",
      "0.5934997683024845\n",
      "0.6504415839339741\n",
      "0.6526239287204216\n",
      "0.6397948650054377\n",
      "0.6284042772114828\n",
      "0.6638424359598971\n",
      "0.6026840465209776\n",
      "0.6977816368870118\n",
      "0.6678516391527156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3223417413454741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.3092</td>\n",
       "      <td>0.4092</td>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.8332</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.8140</td>\n",
       "      <td>0.8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3278</td>\n",
       "      <td>0.4253</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.7293</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>0.4850</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.7792</td>\n",
       "      <td>0.7530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.7870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.7928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1912</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.4373</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>0.4566</td>\n",
       "      <td>0.6398</td>\n",
       "      <td>0.8105</td>\n",
       "      <td>0.7930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.3274</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>0.8315</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.7807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>0.8011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8216</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.4795</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.7779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.3192</td>\n",
       "      <td>0.4279</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.3138</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.8359</td>\n",
       "      <td>0.8244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>0.4058</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>0.8098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4112</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.6809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1675                0.3092   \n",
       "DecisionTreeRegressor                    0.3278                0.4253   \n",
       "RandomForestRegressor                    0.1681                0.3051   \n",
       "GradientBoostingRegressor                0.1715                0.3080   \n",
       "AdaBoostRegressor                        0.1912                0.3321   \n",
       "XGBRegressor                             0.1879                0.3274   \n",
       "ExtraTreesRegressor                      0.1621                0.3010   \n",
       "LinearRegression                         0.2021                0.3432   \n",
       "KNeighborsRegressor                      0.1831                0.3192   \n",
       "SVR                                      0.1646                0.3013   \n",
       "MLPRegressor                             0.4112                0.4981   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4092               0.7238   \n",
       "DecisionTreeRegressor                     0.5725               0.4594   \n",
       "RandomForestRegressor                     0.4100               0.7227   \n",
       "GradientBoostingRegressor                 0.4141               0.7172   \n",
       "AdaBoostRegressor                         0.4373               0.6846   \n",
       "XGBRegressor                              0.4335               0.6901   \n",
       "ExtraTreesRegressor                       0.4026               0.7326   \n",
       "LinearRegression                          0.4495               0.6667   \n",
       "KNeighborsRegressor                       0.4279               0.6981   \n",
       "SVR                                       0.4058               0.7285   \n",
       "MLPRegressor                              0.6412               0.3219   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8508                0.8332   \n",
       "DecisionTreeRegressor                    0.7293                0.7033   \n",
       "RandomForestRegressor                    0.8506                0.8325   \n",
       "GradientBoostingRegressor                0.8469                0.8296   \n",
       "AdaBoostRegressor                        0.8305                0.8111   \n",
       "XGBRegressor                             0.8315                0.8152   \n",
       "ExtraTreesRegressor                      0.8563                0.8398   \n",
       "LinearRegression                         0.8216                0.8160   \n",
       "KNeighborsRegressor                      0.8392                0.8096   \n",
       "SVR                                      0.8537                0.8426   \n",
       "MLPRegressor                             0.6995                0.6933   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.1968   0.3406    0.4437  0.6599   \n",
       "DecisionTreeRegressor       0.2353   0.3645    0.4850  0.5935   \n",
       "RandomForestRegressor       0.2023   0.3480    0.4498  0.6504   \n",
       "GradientBoostingRegressor   0.2010   0.3479    0.4484  0.6526   \n",
       "AdaBoostRegressor           0.2085   0.3672    0.4566  0.6398   \n",
       "XGBRegressor                0.2151   0.3626    0.4637  0.6284   \n",
       "ExtraTreesRegressor         0.1945   0.3411    0.4411  0.6638   \n",
       "LinearRegression            0.2299   0.3738    0.4795  0.6027   \n",
       "KNeighborsRegressor         0.1749   0.3138    0.4182  0.6978   \n",
       "SVR                         0.1922   0.3365    0.4384  0.6679   \n",
       "MLPRegressor                0.3922   0.4890    0.6262  0.3223   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8140                    0.8003  \n",
       "DecisionTreeRegressor                       0.7792                    0.7530  \n",
       "RandomForestRegressor                       0.8086                    0.7870  \n",
       "GradientBoostingRegressor                   0.8100                    0.7928  \n",
       "AdaBoostRegressor                           0.8105                    0.7930  \n",
       "XGBRegressor                                0.7952                    0.7807  \n",
       "ExtraTreesRegressor                         0.8166                    0.8011  \n",
       "LinearRegression                            0.7835                    0.7779  \n",
       "KNeighborsRegressor                         0.8359                    0.8244  \n",
       "SVR                                         0.8178                    0.8098  \n",
       "MLPRegressor                                0.6807                    0.6809  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_df['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = test_df[X_train.columns]\n",
    "y_test = test_df['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75add8a4-50a6-4ea0-9597-11eea146aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/combined_top_200_features_caco2.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/prediction_combined_top_200_features_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad854a47-d0f3-4db5-905c-9c0d903a2d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 500 features:\n",
      "\n",
      "['x_fine_emb_MFXL339', 'x_fine_emb_MFXL263', 'x_fine_emb_MFXL682', 'x_fine_emb_MFXL607', 'x_fine_emb_MFXL411', 'x_fine_emb_MFXL355', 'x_fine_emb_MFXL618', 'x_fine_emb_MFXL287', 'x_fine_emb_MFXL709', 'x_fine_emb_MFXL451', 'x_fine_emb_MFXL139', 'x_fine_emb_MFXL22', 'x_fine_emb_MFXL250', 'x_fine_emb_MFXL399', 'x_fine_emb_MFXL466', 'x_fine_emb_MFXL388', 'x_fine_emb_MFXL420', 'x_fine_emb_MFXL209', 'x_fine_emb_MFXL753', 'x_fine_emb_MFXL208', 'x_fine_emb_MFXL571', 'x_fine_emb_MFXL333', 'x_fine_emb_MFXL530', 'x_fine_emb_MFXL359', 'x_fine_emb_MFXL659', 'x_fine_emb_MFXL678', 'x_fine_emb_MFXL721', 'x_fine_emb_MFXL675', 'x_fine_emb_MFXL76', 'ATSC.7', 'x_fine_emb_MFXL632', 'x_fine_emb_MFXL33', 'x_fine_emb_MFXL517', 'ATSC8s', 'x_fine_emb_MFXL184', 'x_fine_emb_MFXL100', 'x_fine_emb_MFXL275', 'x_fine_emb_MFXL315', 'x_fine_emb_MFXL667', 'x_fine_emb_MFXL88', 'maxHBint6', 'x_fine_emb_MFXL660', 'x_fine_emb_MFXL62', 'x_fine_emb_MFXL169', 'x_fine_emb_MFXL604', 'x_fine_emb_MFXL136', 'x_fine_emb_MFXL103', 'x_fine_emb_MFXL168', 'x_fine_emb_MFXL695', 'x_fine_emb_MFXL41', 'x_fine_emb_MFXL151', 'SpMax7_Bhs', 'AATSC.9', 'x_fine_emb_MFXL387', 'x_fine_emb_MFXL541', 'maxHBint2', 'x_fine_emb_MFXL581', 'x_fine_emb_MFXL478', 'x_fine_emb_MFXL224', 'x_fine_emb_MFXL543', 'maxHBd', 'x_fine_emb_MFXL73', 'x_fine_emb_MFXL496', 'x_fine_emb_MFXL142', 'x_fine_emb_MFXL524', 'x_fine_emb_MFXL479', 'x_fine_emb_MFXL361', 'x_fine_emb_MFXL523', 'maxHBint9', 'x_fine_emb_MFXL611', 'x_fine_emb_MFXL14', 'x_fine_emb_MFXL674', 'x_fine_emb_MFXL500', 'x_fine_emb_MFXL623', 'x_fine_emb_MFXL200', 'x_fine_emb_MFXL21', 'x_fine_emb_MFXL641', 'x_fine_emb_MFXL454', 'x_fine_emb_MFXL379', 'x_fine_emb_MFXL480', 'x_fine_emb_MFXL273', 'x_fine_emb_MFXL473', 'x_fine_emb_MFXL593', 'x_fine_emb_MFXL766', 'x_fine_emb_MFXL351', 'x_fine_emb_MFXL553', 'x_fine_emb_MFXL630', 'x_fine_emb_MFXL237', 'x_fine_emb_MFXL589', 'x_fine_emb_MFXL751', 'x_fine_emb_MFXL329', 'MOMI-XY', 'x_fine_emb_MFXL691', 'x_fine_emb_MFXL248', 'x_fine_emb_MFXL463', 'x_fine_emb_MFXL244', 'x_fine_emb_MFXL572', 'x_fine_emb_MFXL736', 'qed', 'x_fine_emb_MFXL384', 'x_fine_emb_MFXL177', 'maxssCH2', 'SHBint4', 'x_fine_emb_MFXL187', 'x_fine_emb_MFXL337', 'x_fine_emb_MFXL325', 'x_fine_emb_MFXL175', 'x_fine_emb_MFXL456', 'x_fine_emb_MFXL29', 'minHBint8', 'maxHsOH', 'x_fine_emb_MFXL79', 'x_fine_emb_MFXL178', 'ATSC5c', 'x_fine_emb_MFXL508', 'x_fine_emb_MFXL461', 'x_fine_emb_MFXL740', 'x_fine_emb_MFXL338', 'x_fine_emb_MFXL249', 'x_fine_emb_MFXL693', 'x_fine_emb_MFXL161', 'x_fine_emb_MFXL764', 'x_fine_emb_MFXL196', 'x_fine_emb_MFXL741', 'x_fine_emb_MFXL616', 'KRFPC435', 'x_fine_emb_MFXL185', 'x_fine_emb_MFXL563', 'x_fine_emb_MFXL35', 'x_fine_emb_MFXL546', 'AATS.5', 'GATS2c', 'x_fine_emb_MFXL72', 'x_fine_emb_MFXL696', 'x_fine_emb_MFXL144', 'x_fine_emb_MFXL509', 'x_fine_emb_MFXL689', 'x_fine_emb_MFXL435', 'x_fine_emb_MFXL331', 'x_fine_emb_MFXL422', 'x_fine_emb_MFXL233', 'x_fine_emb_MFXL580', 'x_fine_emb_MFXL47', '3d_rdkit_11', 'IC1', 'TDB3i', 'x_fine_emb_MFXL609', 'x_fine_emb_MFXL750', 'x_fine_emb_MFXL585', 'x_fine_emb_MFXL53', 'BCUTp-1l', 'x_fine_emb_MFXL574', 'x_fine_emb_MFXL49', 'x_fine_emb_MFXL460', 'x_fine_emb_MFXL19', 'AtomTypeEState.170', 'x_fine_emb_MFXL90', 'x_fine_emb_MFXL700', 'x_fine_emb_MFXL240', 'x_fine_emb_MFXL243', 'x_fine_emb_MFXL215', 'x_fine_emb_MFXL357', 'x_fine_emb_MFXL368', 'x_fine_emb_MFXL633', 'x_fine_emb_MFXL724', 'x_fine_emb_MFXL733', 'XLogP', 'x_fine_emb_MFXL191', 'AATSC.14', 'TPSA_y', 'x_fine_emb_MFXL380', 'x_fine_emb_MFXL672', 'x_fine_emb_MFXL483', 'x_fine_emb_MFXL676', 'x_fine_emb_MFXL75', 'x_fine_emb_MFXL314', 'x_fine_emb_MFXL603', 'minsCH3', 'x_fine_emb_MFXL619', 'ATSC.75', 'x_fine_emb_MFXL230', 'x_fine_emb_MFXL149', 'x_fine_emb_MFXL381', 'x_fine_emb_MFXL320', 'count_fp_881', 'ATSC3s', 'x_fine_emb_MFXL560', 'TDB5i', 'x_fine_emb_MFXL537', 'LOBMIN', 'x_fine_emb_MFXL610', 'x_fine_emb_MFXL464', 'x_fine_emb_MFXL450', 'x_fine_emb_MFXL297', 'TDB5e', 'x_fine_emb_MFXL17', 'x_fine_emb_MFXL109', 'x_fine_emb_MFXL111', 'minssCH2', 'maxHBint3', 'x_fine_emb_MFXL120', 'x_fine_emb_MFXL117', 'ATSC.88', 'x_fine_emb_MFXL391', 'x_fine_emb_MFXL9', 'x_fine_emb_MFXL666', 'x_fine_emb_MFXL520', 'x_fine_emb_MFXL55', 'x_fine_emb_MFXL507', 'De', 'x_fine_emb_MFXL138', 'ATSC.16', 'x_fine_emb_MFXL125', 'x_fine_emb_MFXL492', 'x_fine_emb_MFXL174', 'L2m', 'x_fine_emb_MFXL5', 'x_fine_emb_MFXL264', 'x_fine_emb_MFXL612', 'x_fine_emb_MFXL85', 'x_fine_emb_MFXL592', 'x_fine_emb_MFXL670', 'ATSC.26', 'x_fine_emb_MFXL470', 'ATSC8c', 'x_fine_emb_MFXL281', 'x_fine_emb_MFXL265', 'x_fine_emb_MFXL310', 'x_fine_emb_MFXL335', 'ATSC.5', 'x_fine_emb_MFXL129', 'x_fine_emb_MFXL430', 'x_fine_emb_MFXL622', 'x_fine_emb_MFXL254', 'x_fine_emb_MFXL714', 'x_fine_emb_MFXL658', 'x_fine_emb_MFXL561', 'x_fine_emb_MFXL525', 'x_fine_emb_MFXL558', 'x_fine_emb_MFXL104', 'LOBMAX', 'x_fine_emb_MFXL573', 'x_fine_emb_MFXL745', 'x_fine_emb_MFXL68', 'x_fine_emb_MFXL638', 'x_fine_emb_MFXL203', 'x_fine_emb_MFXL702', 'x_fine_emb_MFXL575', 'x_fine_emb_MFXL78', 'TDB10u', 'AATSC.39', 'x_fine_emb_MFXL755', 'x_fine_emb_MFXL341', 'x_fine_emb_MFXL489', 'VE3_Dzv', 'AATS', 'geomShape', 'x_fine_emb_MFXL304', 'MOMI-YZ', 'x_fine_emb_MFXL704', 'x_fine_emb_MFXL296', 'x_fine_emb_MFXL316', 'AtomTypeEState.252', 'x_fine_emb_MFXL697', 'x_fine_emb_MFXL256', 'x_fine_emb_MFXL44', 'x_fine_emb_MFXL613', 'x_fine_emb_MFXL646', 'SpMax5_Bhs', 'TDB6e', 'x_fine_emb_MFXL252', 'x_fine_emb_MFXL598', 'x_fine_emb_MFXL708', 'x_fine_emb_MFXL202', 'x_fine_emb_MFXL301', 'x_fine_emb_MFXL484', 'x_fine_emb_MFXL52', 'AATSC6v', 'x_fine_emb_MFXL279', 'minHBa', 'x_fine_emb_MFXL362', 'x_fine_emb_MFXL516', 'x_fine_emb_MFXL491', 'x_fine_emb_MFXL402', 'x_fine_emb_MFXL82', 'x_fine_emb_MFXL428', 'x_fine_emb_MFXL657', 'x_fine_emb_MFXL608', 'GATS8c', 'ATSC.23', 'x_fine_emb_MFXL653', 'x_fine_emb_MFXL239', 'x_fine_emb_MFXL36', 'RDF30s', 'x_fine_emb_MFXL163', 'x_fine_emb_MFXL267', 'x_fine_emb_MFXL716', 'TDB7s', 'x_fine_emb_MFXL214', 'TDB9r', 'x_fine_emb_MFXL4', 'x_fine_emb_MFXL211', 'MACCSFP138', 'x_fine_emb_MFXL152', 'x_fine_emb_MFXL729', 'x_fine_emb_MFXL15', 'x_fine_emb_MFXL403', 'x_fine_emb_MFXL93', 'x_fine_emb_MFXL232', 'x_fine_emb_MFXL231', 'x_fine_emb_MFXL739', 'x_fine_emb_MFXL13', 'x_fine_emb_MFXL241', 'x_fine_emb_MFXL371', 'x_fine_emb_MFXL61', 'x_fine_emb_MFXL568', 'x_fine_emb_MFXL531', 'x_fine_emb_MFXL65', 'x_fine_emb_MFXL452', 'x_fine_emb_MFXL556', 'x_fine_emb_MFXL324', 'AATSC.38', 'VR1_Dzs', 'x_fine_emb_MFXL424', 'x_fine_emb_MFXL192', 'x_fine_emb_MFXL225', 'x_fine_emb_MFXL32', 'x_fine_emb_MFXL680', 'x_fine_emb_MFXL688', 'x_fine_emb_MFXL63', 'x_fine_emb_MFXL669', 'ATSC6c', 'maxHBint8', 'x_fine_emb_MFXL317', 'x_fine_emb_MFXL624', 'AtomTypeEState.271', 'minsssN', 'ATSC.11', 'AvgIpc', 'x_fine_emb_MFXL668', 'x_fine_emb_MFXL425', 'BCUT.7', 'x_fine_emb_MFXL731', 'count_fp_80', 'x_fine_emb_MFXL431', 'x_fine_emb_MFXL730', 'x_fine_emb_MFXL673', 'x_fine_emb_MFXL567', 'x_fine_emb_MFXL760', 'x_fine_emb_MFXL59', 'x_fine_emb_MFXL245', 'VR1_Dt', 'VE3_Dzs', 'ATSC8e', 'x_fine_emb_MFXL213', 'SHBint9', 'x_fine_emb_MFXL99', 'x_fine_emb_MFXL559', 'x_fine_emb_MFXL126', 'x_fine_emb_MFXL366', 'VR1_Dzv', 'x_fine_emb_MFXL268', 'x_fine_emb_MFXL506', 'x_fine_emb_MFXL348', 'x_fine_emb_MFXL440', 'x_fine_emb_MFXL579', 'x_fine_emb_MFXL549', 'x_fine_emb_MFXL651', 'x_fine_emb_MFXL625', 'AATSC.17', 'x_fine_emb_MFXL576', 'x_fine_emb_MFXL269', 'x_fine_emb_MFXL394', 'SpMax1_Bhm', 'x_fine_emb_MFXL74', 'x_fine_emb_MFXL720', 'x_fine_emb_MFXL692', 'TDB8e', 'x_fine_emb_MFXL505', 'x_fine_emb_MFXL518', 'TDB5m', 'x_fine_emb_MFXL289', 'x_fine_emb_MFXL528', 'ATSC.32', 'x_fine_emb_MFXL690', 'x_fine_emb_MFXL259', 'x_fine_emb_MFXL503', 'x_fine_emb_MFXL756', 'x_fine_emb_MFXL436', 'x_fine_emb_MFXL360', 'x_fine_emb_MFXL734', 'ATSC5i', 'x_fine_emb_MFXL386', 'RNCS', 'x_fine_emb_MFXL538', 'x_fine_emb_MFXL6', 'x_fine_emb_MFXL164', 'x_fine_emb_MFXL595', 'minHBint5', 'x_fine_emb_MFXL189', 'x_fine_emb_MFXL455', 'x_fine_emb_MFXL487', 'AATSC3v', 'x_fine_emb_MFXL719', 'x_fine_emb_MFXL276', 'x_fine_emb_MFXL110', 'x_fine_emb_MFXL504', 'x_fine_emb_MFXL77', 'Morgan_fp_231', 'x_fine_emb_MFXL754', 'x_fine_emb_MFXL343', 'x_fine_emb_MFXL535', 'GATS6c', 'x_fine_emb_MFXL26', 'TDB1i', 'x_fine_emb_MFXL421', 'SHBint7', 'x_fine_emb_MFXL398', 'maxHBint10', 'x_fine_emb_MFXL490', 'x_fine_emb_MFXL121', 'x_fine_emb_MFXL694', 'x_fine_emb_MFXL392', 'x_fine_emb_MFXL367', 'x_fine_emb_MFXL180', 'ATSC.25', 'x_fine_emb_MFXL253', 'LipoaffinityIndex', 'x_fine_emb_MFXL255', 'ALogP', 'x_fine_emb_MFXL742', 'x_fine_emb_MFXL725', 'x_fine_emb_MFXL24', 'x_fine_emb_MFXL438', 'x_fine_emb_MFXL272', 'x_fine_emb_MFXL650', 'EState_VSA11', 'GATS.67', 'x_fine_emb_MFXL108', 'x_fine_emb_MFXL577', 'x_fine_emb_MFXL133', 'x_fine_emb_MFXL410', 'x_fine_emb_MFXL217', 'x_fine_emb_MFXL171', 'x_fine_emb_MFXL686', 'x_fine_emb_MFXL416', 'GATS5c', 'GATS.79', 'x_fine_emb_MFXL701', 'x_fine_emb_MFXL159', 'x_fine_emb_MFXL393', 'AATS4i', 'x_fine_emb_MFXL46', 'x_fine_emb_MFXL186', 'x_fine_emb_MFXL467', 'x_fine_emb_MFXL288', 'x_fine_emb_MFXL309', 'x_fine_emb_MFXL319', 'x_fine_emb_MFXL445', 'maxHBint5', 'x_fine_emb_MFXL587', 'ATSC.87', 'x_fine_emb_MFXL396', 'x_fine_emb_MFXL210', 'x_fine_emb_MFXL635', 'x_fine_emb_MFXL661', 'x_fine_emb_MFXL135', 'x_fine_emb_MFXL176', 'TDB7e', 'GATS.88', 'x_fine_emb_MFXL614', 'x_fine_emb_MFXL378', 'minHBint10', 'x_fine_emb_MFXL488', 'x_fine_emb_MFXL299', 'GATS.3', 'x_fine_emb_MFXL30', 'x_fine_emb_MFXL150', 'x_fine_emb_MFXL113', 'x_fine_emb_MFXL643', 'x_fine_emb_MFXL698', 'x_fine_emb_MFXL671', 'x_fine_emb_MFXL498', 'x_fine_emb_MFXL148', 'AtomTypeEState.95', 'ATSC.22', 'x_fine_emb_MFXL578', 'x_fine_emb_MFXL226', 'x_fine_emb_MFXL606', 'x_fine_emb_MFXL302', 'VE3_Dt', 'x_fine_emb_MFXL238', 'AdjacencyMatrix.6', 'x_fine_emb_MFXL260', 'x_fine_emb_MFXL323', 'x_fine_emb_MFXL372', 'ATSC.106', 'x_fine_emb_MFXL636', 'x_fine_emb_MFXL105', 'x_fine_emb_MFXL141']\n"
     ]
    }
   ],
   "source": [
    "#Top 500 features\n",
    "n = 500  \n",
    "top_500_indices = importances.argsort()[::-1][:n]  # indices of top n features\n",
    "top_500_features = feature_names[top_500_indices].tolist()  # convert to list\n",
    "\n",
    "# Output the list\n",
    "print(\"Top\", 500, \"features:\\n\")\n",
    "print(top_500_features)\n",
    "\n",
    "train_df = pd.concat([train[['ID', 'SMILES', 'Permeability']], X[top_500_features]], axis=1)\n",
    "test_df = test[train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a5bf997-9729-4794-bf02-969b14402b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 500)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 500)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126012\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -6.294177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126007\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -6.295407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126006\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -6.270552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126008\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -6.284236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126006\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -6.280596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6592865088218348\n",
      "0.5755611053501466\n",
      "0.6548149263177478\n",
      "0.6596809088458894\n",
      "0.6311401249453642\n",
      "0.6463503560705861\n",
      "0.6607563055028631\n",
      "0.36702362372420827\n",
      "0.6861175485779856\n",
      "0.6642303057670682\n",
      "0.31517562761747175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>0.1972</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.7938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.4266</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>0.7267</td>\n",
       "      <td>0.7118</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3753</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.5756</td>\n",
       "      <td>0.7653</td>\n",
       "      <td>0.7364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.4113</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>0.7893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.3126</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.7944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.4367</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.3702</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.6311</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.7848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1998</td>\n",
       "      <td>0.3349</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.3535</td>\n",
       "      <td>0.4524</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>0.8059</td>\n",
       "      <td>0.7933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.4431</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>0.7980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3937</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.3506</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.7115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.3237</td>\n",
       "      <td>0.4376</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.8056</td>\n",
       "      <td>0.1817</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1698</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.8151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.5321</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.3963</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1710                0.3102   \n",
       "DecisionTreeRegressor                    0.3350                0.4266   \n",
       "RandomForestRegressor                    0.1692                0.3064   \n",
       "GradientBoostingRegressor                0.1743                0.3126   \n",
       "AdaBoostRegressor                        0.1907                0.3318   \n",
       "XGBRegressor                             0.1998                0.3349   \n",
       "ExtraTreesRegressor                      0.1614                0.2984   \n",
       "LinearRegression                         0.3937                0.4735   \n",
       "KNeighborsRegressor                      0.1915                0.3237   \n",
       "SVR                                      0.1698                0.3023   \n",
       "MLPRegressor                             0.4856                0.5321   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4135               0.7180   \n",
       "DecisionTreeRegressor                     0.5788               0.4475   \n",
       "RandomForestRegressor                     0.4113               0.7210   \n",
       "GradientBoostingRegressor                 0.4175               0.7125   \n",
       "AdaBoostRegressor                         0.4367               0.6855   \n",
       "XGBRegressor                              0.4470               0.6705   \n",
       "ExtraTreesRegressor                       0.4017               0.7338   \n",
       "LinearRegression                          0.6275               0.3506   \n",
       "KNeighborsRegressor                       0.4376               0.6842   \n",
       "SVR                                       0.4120               0.7200   \n",
       "MLPRegressor                              0.6968               0.1992   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8473                0.8308   \n",
       "DecisionTreeRegressor                    0.7267                0.7118   \n",
       "RandomForestRegressor                    0.8497                0.8320   \n",
       "GradientBoostingRegressor                0.8442                0.8245   \n",
       "AdaBoostRegressor                        0.8311                0.8132   \n",
       "XGBRegressor                             0.8199                0.8043   \n",
       "ExtraTreesRegressor                      0.8573                0.8414   \n",
       "LinearRegression                         0.7131                0.7110   \n",
       "KNeighborsRegressor                      0.8317                0.8056   \n",
       "SVR                                      0.8489                0.8432   \n",
       "MLPRegressor                             0.6756                0.6869   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.1972   0.3468    0.4440  0.6593   \n",
       "DecisionTreeRegressor       0.2456   0.3753    0.4956  0.5756   \n",
       "RandomForestRegressor       0.1998   0.3489    0.4470  0.6548   \n",
       "GradientBoostingRegressor   0.1970   0.3466    0.4438  0.6597   \n",
       "AdaBoostRegressor           0.2135   0.3702    0.4620  0.6311   \n",
       "XGBRegressor                0.2047   0.3535    0.4524  0.6464   \n",
       "ExtraTreesRegressor         0.1963   0.3454    0.4431  0.6608   \n",
       "LinearRegression            0.3663   0.4454    0.6052  0.3670   \n",
       "KNeighborsRegressor         0.1817   0.3229    0.4262  0.6861   \n",
       "SVR                         0.1943   0.3383    0.4408  0.6642   \n",
       "MLPRegressor                0.3963   0.4950    0.6295  0.3152   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8137                    0.7938  \n",
       "DecisionTreeRegressor                       0.7653                    0.7364  \n",
       "RandomForestRegressor                       0.8120                    0.7893  \n",
       "GradientBoostingRegressor                   0.8145                    0.7944  \n",
       "AdaBoostRegressor                           0.8054                    0.7848  \n",
       "XGBRegressor                                0.8059                    0.7933  \n",
       "ExtraTreesRegressor                         0.8149                    0.7980  \n",
       "LinearRegression                            0.6926                    0.7115  \n",
       "KNeighborsRegressor                         0.8295                    0.8164  \n",
       "SVR                                         0.8168                    0.8151  \n",
       "MLPRegressor                                0.6816                    0.6784  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_df['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = test_df[X_train.columns]\n",
    "y_test = test_df['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7dcd203-d74b-4267-9727-2127627e93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/combined_top_500_features_caco2.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/Caco2/results/combined_features/prediction_combined_top_500_features_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b770cf-881e-4c34-b388-4187aa610b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fac5b8-8c95-4bf3-a58d-10109a81c4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a227c-7e50-416e-bd88-d49e476ea9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066b14a-fe52-4a98-a4bd-baca24ebb6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa66aa9-e8d1-4ba0-b70b-7252ab6d75ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5becfa-8be0-456e-ab19-df9df258effd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdad8a-9857-4c31-a2f2-e858419fd40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
