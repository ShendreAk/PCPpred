{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13095fe3-1fce-41e9-ae0b-93ab205e1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression  # LogisticRegression is not used for regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c170d9-67e1-48e4-9c19-577182fe3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2611815b-4c5f-4259-a5e0-23e6de30ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 23)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 23)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 783\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5122403120043475\n",
      "0.5128696397915589\n",
      "0.5467092828469056\n",
      "0.4620738379905157\n",
      "0.16088186266576476\n",
      "0.5494187212067152\n",
      "0.5384520272795623\n",
      "0.22656464503079965\n",
      "0.47165885423077536\n",
      "0.41162932555161513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454063830430938\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.7206</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.3087</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.6020</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.6748</td>\n",
       "      <td>0.6618</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.5552</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.7129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2833</td>\n",
       "      <td>0.3848</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.2869</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3314</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.5757</td>\n",
       "      <td>0.4679</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.4361</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>0.4621</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.6628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5505</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2836</td>\n",
       "      <td>0.3826</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.5494</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.3823</td>\n",
       "      <td>0.5321</td>\n",
       "      <td>0.5454</td>\n",
       "      <td>0.7409</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.2921</td>\n",
       "      <td>0.3876</td>\n",
       "      <td>0.5404</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.7362</td>\n",
       "      <td>0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>0.6961</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.4713</td>\n",
       "      <td>0.4781</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.2266</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.4913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.4138</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.4108</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.4717</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>0.6821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.4253</td>\n",
       "      <td>0.5928</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.3723</td>\n",
       "      <td>0.4307</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.6501</td>\n",
       "      <td>0.6446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3211</td>\n",
       "      <td>0.4155</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.6680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.3003                0.4043   \n",
       "DecisionTreeRegressor                    0.3624                0.4142   \n",
       "RandomForestRegressor                    0.2833                0.3848   \n",
       "GradientBoostingRegressor                0.3314                0.4333   \n",
       "AdaBoostRegressor                        0.5505                0.5909   \n",
       "XGBRegressor                             0.2836                0.3826   \n",
       "ExtraTreesRegressor                      0.2832                0.3823   \n",
       "LinearRegression                         0.4846                0.5260   \n",
       "KNeighborsRegressor                      0.3321                0.4138   \n",
       "SVR                                      0.3514                0.4253   \n",
       "MLPRegressor                             0.3211                0.4155   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.5480               0.5179   \n",
       "DecisionTreeRegressor                     0.6020               0.4182   \n",
       "RandomForestRegressor                     0.5322               0.5452   \n",
       "GradientBoostingRegressor                 0.5757               0.4679   \n",
       "AdaBoostRegressor                         0.7419               0.1162   \n",
       "XGBRegressor                              0.5325               0.5447   \n",
       "ExtraTreesRegressor                       0.5321               0.5454   \n",
       "LinearRegression                          0.6961               0.2219   \n",
       "KNeighborsRegressor                       0.5763               0.4668   \n",
       "SVR                                       0.5928               0.4358   \n",
       "MLPRegressor                              0.5666               0.4845   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7206                0.6835   \n",
       "DecisionTreeRegressor                    0.6748                0.6618   \n",
       "RandomForestRegressor                    0.7389                0.7051   \n",
       "GradientBoostingRegressor                0.6893                0.6365   \n",
       "AdaBoostRegressor                        0.4503                0.4349   \n",
       "XGBRegressor                             0.7396                0.7046   \n",
       "ExtraTreesRegressor                      0.7409                0.7073   \n",
       "LinearRegression                         0.4713                0.4781   \n",
       "KNeighborsRegressor                      0.6943                0.6584   \n",
       "SVR                                      0.6648                0.6406   \n",
       "MLPRegressor                             0.6968                0.6632   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.3087   0.4052    0.5556  0.5122   \n",
       "DecisionTreeRegressor       0.3083   0.3918    0.5552  0.5129   \n",
       "RandomForestRegressor       0.2869   0.3865    0.5356  0.5467   \n",
       "GradientBoostingRegressor   0.3404   0.4361    0.5835  0.4621   \n",
       "AdaBoostRegressor           0.5310   0.5820    0.7287  0.1609   \n",
       "XGBRegressor                0.2851   0.3833    0.5340  0.5494   \n",
       "ExtraTreesRegressor         0.2921   0.3876    0.5404  0.5385   \n",
       "LinearRegression            0.4895   0.5267    0.6996  0.2266   \n",
       "KNeighborsRegressor         0.3343   0.4108    0.5782  0.4717   \n",
       "SVR                         0.3723   0.4307    0.6102  0.4116   \n",
       "MLPRegressor                0.3455   0.4205    0.5878  0.4541   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7164                    0.7008  \n",
       "DecisionTreeRegressor                       0.7221                    0.7129  \n",
       "RandomForestRegressor                       0.7402                    0.7210  \n",
       "GradientBoostingRegressor                   0.6840                    0.6628  \n",
       "AdaBoostRegressor                           0.4880                    0.4821  \n",
       "XGBRegressor                                0.7426                    0.7237  \n",
       "ExtraTreesRegressor                         0.7362                    0.7184  \n",
       "LinearRegression                            0.4767                    0.4913  \n",
       "KNeighborsRegressor                         0.6967                    0.6821  \n",
       "SVR                                         0.6501                    0.6446  \n",
       "MLPRegressor                                0.6757                    0.6680  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atomic descriptors\n",
    "df_train = pd.read_csv('Atomic_features/Train_all_atomic_desc.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('Atomic_features/Test_all_atomic_desc.csv')\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models_degree = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models_degree, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebef633e-3971-4f7f-a788-3539452673b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.405973830435521, -7.0384272989401495, -6.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.992337917250762, -6.465291933458534, -6.5...</td>\n",
       "      <td>[-7.019794368729011, -6.453482372820912, -6.62...</td>\n",
       "      <td>[0.07466501971828703, 0.10907219133879548, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-5.49, -7.0, -7.0, -4.77, -4.55, -4.885, -5.0...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.24, -5.49, -6.244999999999999, -7.0...</td>\n",
       "      <td>[-7.0, -6.518000000000001, -6.396, -6.819, -6....</td>\n",
       "      <td>[0.0, 0.39640383449204913, 0.7397459023205197,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.623700000000001, -6.9048, -6.4150266666666...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.934900000000002, -6.651100000000003, -6.7...</td>\n",
       "      <td>[-6.9674000000000005, -6.70864, -6.73914200000...</td>\n",
       "      <td>[0.025088244259014517, 0.10905856408370683, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.414804492400767, -6.745252825886334, -5.87...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.019412028211235, -6.3399219342912145, -6....</td>\n",
       "      <td>[-7.15415627455958, -6.4807759111983305, -6.45...</td>\n",
       "      <td>[0.07836106393656384, 0.1595291429758868, 0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.786376090159455, -5.869923779070385, -5.78...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.869923779070385, -5.786376090159455, -5.8...</td>\n",
       "      <td>[-5.785333304981799, -5.703138760558792, -5.73...</td>\n",
       "      <td>[0.05472609266014173, 0.06611179707686692, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.369783, -7.138793, -6.2215147, -5.1384716,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.616264, -6.427373, -6.568331, -5.539065, ...</td>\n",
       "      <td>[-6.8326797, -6.6089973, -6.7012877, -6.077459...</td>\n",
       "      <td>[0.1327724, 0.19248006, 0.099578865, 0.3078653...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.8585, -6.9889, -5.928466666666663, -4.7699...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.964700000000002, -6.944400000000001, -6.2...</td>\n",
       "      <td>[-6.975240000000002, -6.849799999999999, -6.42...</td>\n",
       "      <td>[0.010616515435866846, 0.2304392240917349, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.127934954999589, -6.787257203614937, -5.56...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.599264686444286, -3.9, -4.887417778847503...</td>\n",
       "      <td>[-6.57357645783934, -3.930882232119134, -4.836...</td>\n",
       "      <td>[0.06058044276649575, 0.039914685448258484, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.603333333333333, -6.986666666666667, -5.88...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -5.603333333333333, -6.4...</td>\n",
       "      <td>[-6.989333333333333, -6.294, -6.43333333333333...</td>\n",
       "      <td>[0.005333333333333102, 0.4281142111373762, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.030529280036772, -6.962966906331343, -5.55...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.893252488494217, -5.7866606060715275, -6....</td>\n",
       "      <td>[-6.969591059520324, -6.048453782919074, -5.99...</td>\n",
       "      <td>[0.07993592437697429, 0.18249963727699886, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.527613808288999, -6.833847744277928, -5.66...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.164543628192858, -6.374584580211206, -6.2...</td>\n",
       "      <td>[-7.280698183404415, -6.417934684993055, -6.22...</td>\n",
       "      <td>[0.18305812706623198, 0.1538983009731225, 0.08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.405973830435521, -7.0384272989401495, -6.1...   \n",
       "1   [-5.49, -7.0, -7.0, -4.77, -4.55, -4.885, -5.0...   \n",
       "2   [-6.623700000000001, -6.9048, -6.4150266666666...   \n",
       "3   [-6.414804492400767, -6.745252825886334, -5.87...   \n",
       "4   [-5.786376090159455, -5.869923779070385, -5.78...   \n",
       "5   [-6.369783, -7.138793, -6.2215147, -5.1384716,...   \n",
       "6   [-6.8585, -6.9889, -5.928466666666663, -4.7699...   \n",
       "7   [-4.127934954999589, -6.787257203614937, -5.56...   \n",
       "8   [-5.603333333333333, -6.986666666666667, -5.88...   \n",
       "9   [-6.030529280036772, -6.962966906331343, -5.55...   \n",
       "10  [-6.527613808288999, -6.833847744277928, -5.66...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.992337917250762, -6.465291933458534, -6.5...   \n",
       "1   [[-7.0, -6.24, -5.49, -6.244999999999999, -7.0...   \n",
       "2   [[-6.934900000000002, -6.651100000000003, -6.7...   \n",
       "3   [[-7.019412028211235, -6.3399219342912145, -6....   \n",
       "4   [[-5.869923779070385, -5.786376090159455, -5.8...   \n",
       "5   [[-6.616264, -6.427373, -6.568331, -5.539065, ...   \n",
       "6   [[-6.964700000000002, -6.944400000000001, -6.2...   \n",
       "7   [[-6.599264686444286, -3.9, -4.887417778847503...   \n",
       "8   [[-6.986666666666667, -5.603333333333333, -6.4...   \n",
       "9   [[-6.893252488494217, -5.7866606060715275, -6....   \n",
       "10  [[-7.164543628192858, -6.374584580211206, -6.2...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.019794368729011, -6.453482372820912, -6.62...   \n",
       "1   [-7.0, -6.518000000000001, -6.396, -6.819, -6....   \n",
       "2   [-6.9674000000000005, -6.70864, -6.73914200000...   \n",
       "3   [-7.15415627455958, -6.4807759111983305, -6.45...   \n",
       "4   [-5.785333304981799, -5.703138760558792, -5.73...   \n",
       "5   [-6.8326797, -6.6089973, -6.7012877, -6.077459...   \n",
       "6   [-6.975240000000002, -6.849799999999999, -6.42...   \n",
       "7   [-6.57357645783934, -3.930882232119134, -4.836...   \n",
       "8   [-6.989333333333333, -6.294, -6.43333333333333...   \n",
       "9   [-6.969591059520324, -6.048453782919074, -5.99...   \n",
       "10  [-7.280698183404415, -6.417934684993055, -6.22...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.07466501971828703, 0.10907219133879548, 0.0...  \n",
       "1   [0.0, 0.39640383449204913, 0.7397459023205197,...  \n",
       "2   [0.025088244259014517, 0.10905856408370683, 0....  \n",
       "3   [0.07836106393656384, 0.1595291429758868, 0.15...  \n",
       "4   [0.05472609266014173, 0.06611179707686692, 0.0...  \n",
       "5   [0.1327724, 0.19248006, 0.099578865, 0.3078653...  \n",
       "6   [0.010616515435866846, 0.2304392240917349, 0.2...  \n",
       "7   [0.06058044276649575, 0.039914685448258484, 0....  \n",
       "8   [0.005333333333333102, 0.4281142111373762, 0.3...  \n",
       "9   [0.07993592437697429, 0.18249963727699886, 0.1...  \n",
       "10  [0.18305812706623198, 0.1538983009731225, 0.08...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebc794a0-2f80-4ae5-8f34-b1990cac44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('atomic_results/Results_all_atomic_desc.csv')\n",
    "prediction_df.to_csv('atomic_results/Prediction_data_all_atomic_desc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1534ac18-47f0-4a18-94c9-825491271741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Permeability</th>\n",
       "      <th>A</th>\n",
       "      <th>dA</th>\n",
       "      <th>meA</th>\n",
       "      <th>Me_dA</th>\n",
       "      <th>Ala(tBu)</th>\n",
       "      <th>Ala(indol-2-yl)</th>\n",
       "      <th>dAla(indol-2-yl)</th>\n",
       "      <th>...</th>\n",
       "      <th>Degree_O</th>\n",
       "      <th>Single</th>\n",
       "      <th>Double</th>\n",
       "      <th>Triple</th>\n",
       "      <th>Aromatic</th>\n",
       "      <th>Conjugated</th>\n",
       "      <th>No-bond</th>\n",
       "      <th>Overall_Formal_Charge</th>\n",
       "      <th>Is_Aromatic</th>\n",
       "      <th>Is_In_Ring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@@H]1CC(=O)N[C@@H](Cc2...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>888</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1cccc(Cl)c1)N(C)...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>C/N=C(\\NC)NCCC[C@@H]1NC(=O)[C@H](Cc2ccccc2)N(C...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>916</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@@H](NC(=O)[C@@H]1CC(=...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)N(C)C(=O...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>2469</td>\n",
       "      <td>CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>2467</td>\n",
       "      <td>CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>2512</td>\n",
       "      <td>CC(C)C[C@H]1NC(=O)[C@@H](C)NCCCCCCNC(=O)[C@H](...</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>2511</td>\n",
       "      <td>CC(C)[C@@H]1NC(=O)[C@@H](CO)NC(=O)[C@@H](C)NCC...</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>2506</td>\n",
       "      <td>CC(C)[C@@H]1NC(=O)[C@@H](CO)NC(=O)CNCCCCCCNC1=O</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows Ã— 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                             SMILES  Permeability  \\\n",
       "0      915  CC[C@H](C)[C@H](NC(=O)[C@@H]1CC(=O)N[C@@H](Cc2...          -7.0   \n",
       "1      888  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1cccc(Cl)c1)N(C)...          -7.0   \n",
       "2      593  C/N=C(\\NC)NCCC[C@@H]1NC(=O)[C@H](Cc2ccccc2)N(C...          -7.0   \n",
       "3      916  CC[C@H](C)[C@H](NC(=O)[C@@H](NC(=O)[C@@H]1CC(=...          -7.0   \n",
       "4      900  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)N(C)C(=O...          -7.0   \n",
       "...    ...                                                ...           ...   \n",
       "5563  2469  CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...          -4.7   \n",
       "5564  2467  CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...          -5.6   \n",
       "5565  2512  CC(C)C[C@H]1NC(=O)[C@@H](C)NCCCCCCNC(=O)[C@H](...          -5.5   \n",
       "5566  2511  CC(C)[C@@H]1NC(=O)[C@@H](CO)NC(=O)[C@@H](C)NCC...          -6.3   \n",
       "5567  2506    CC(C)[C@@H]1NC(=O)[C@@H](CO)NC(=O)CNCCCCCCNC1=O          -7.8   \n",
       "\n",
       "             A   dA       meA  Me_dA  Ala(tBu)  Ala(indol-2-yl)  \\\n",
       "0     0.066667  0.0  0.066667    0.0       0.0              0.0   \n",
       "1     0.000000  0.0  0.071429    0.0       0.0              0.0   \n",
       "2     0.071429  0.0  0.000000    0.0       0.0              0.0   \n",
       "3     0.000000  0.0  0.066667    0.0       0.0              0.0   \n",
       "4     0.066667  0.0  0.066667    0.0       0.0              0.0   \n",
       "...        ...  ...       ...    ...       ...              ...   \n",
       "5563  0.333333  0.0  0.000000    0.0       0.0              0.0   \n",
       "5564  0.333333  0.0  0.000000    0.0       0.0              0.0   \n",
       "5565  0.000000  0.0  0.000000    0.0       0.0              0.0   \n",
       "5566  0.000000  0.0  0.000000    0.0       0.0              0.0   \n",
       "5567  0.000000  0.0  0.000000    0.0       0.0              0.0   \n",
       "\n",
       "      dAla(indol-2-yl)  ...  Degree_O  Single  Double  Triple  Aromatic  \\\n",
       "0                  0.0  ...         2      98      15       0        18   \n",
       "1                  0.0  ...         1      91      14       0        24   \n",
       "2                  0.0  ...         1      91      15       0        24   \n",
       "3                  0.0  ...         2      99      15       0        12   \n",
       "4                  0.0  ...         1      99      15       0        12   \n",
       "...                ...  ...       ...     ...     ...     ...       ...   \n",
       "5563               0.0  ...         1      21       3       0         6   \n",
       "5564               0.0  ...         1      19       3       0         6   \n",
       "5565               0.0  ...         1      23       3       0         0   \n",
       "5566               0.0  ...         1      22       3       0         0   \n",
       "5567               0.0  ...         1      21       3       0         0   \n",
       "\n",
       "      Conjugated  No-bond  Overall_Formal_Charge  Is_Aromatic  Is_In_Ring  \n",
       "0              0        0                    163            1           1  \n",
       "1              0        0                    167            1           1  \n",
       "2              0        0                    156            1           1  \n",
       "3              0        0                    155            1           1  \n",
       "4              0        0                    153            1           1  \n",
       "...          ...      ...                    ...          ...         ...  \n",
       "5563           0        0                     35            1           1  \n",
       "5564           0        0                     35            1           1  \n",
       "5565           0        0                     33            0           1  \n",
       "5566           0        0                     33            0           1  \n",
       "5567           0        0                     32            0           1  \n",
       "\n",
       "[5568 rows x 411 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atomic + monomeric_composition based features\n",
    "df1 = pd.read_csv('Monomer_features/Train_mon_comp.csv')\n",
    "df2 = pd.read_csv('Atomic_features/Train_all_atomic_desc.csv')\n",
    "df_train = pd.merge(df1, df2, on=['ID', 'SMILES', 'Permeability'], how='inner')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5367e544-dc3a-42b4-8cea-f2f8f69e2d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Permeability</th>\n",
       "      <th>A</th>\n",
       "      <th>dA</th>\n",
       "      <th>meA</th>\n",
       "      <th>Me_dA</th>\n",
       "      <th>Ala(tBu)</th>\n",
       "      <th>Ala(indol-2-yl)</th>\n",
       "      <th>dAla(indol-2-yl)</th>\n",
       "      <th>...</th>\n",
       "      <th>Degree_O</th>\n",
       "      <th>Single</th>\n",
       "      <th>Double</th>\n",
       "      <th>Triple</th>\n",
       "      <th>Aromatic</th>\n",
       "      <th>Conjugated</th>\n",
       "      <th>No-bond</th>\n",
       "      <th>Overall_Formal_Charge</th>\n",
       "      <th>Is_Aromatic</th>\n",
       "      <th>Is_In_Ring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>908</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>923</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](C)N(C)C(=O)[C@H](...</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](Cc2ccccc2)N(C)C(=...</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>587</td>\n",
       "      <td>CC(C)C[C@@H]1NC(=O)[C@H](Cc2c[nH]cn2)NC(=O)[C@...</td>\n",
       "      <td>-6.74</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>921</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...</td>\n",
       "      <td>-5.54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>2481</td>\n",
       "      <td>CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2ccccc...</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>2485</td>\n",
       "      <td>CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@@H](Cc2cccc...</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>5604</td>\n",
       "      <td>CC(C)CN1CC(=O)N[C@@H](Cc2ccccc2)C(=O)NCCCCC(=O...</td>\n",
       "      <td>-6.38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>2513</td>\n",
       "      <td>C[C@H]1NCCCCCCNC(=O)[C@H](Cc2ccc(O)cc2)NC(=O)[...</td>\n",
       "      <td>-7.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>2468</td>\n",
       "      <td>CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1392 rows Ã— 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                             SMILES  Permeability  \\\n",
       "0      908  CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...         -7.00   \n",
       "1      923  CC[C@H](C)[C@@H]1NC(=O)[C@H](C)N(C)C(=O)[C@H](...         -7.00   \n",
       "2      897  CC[C@H](C)[C@@H]1NC(=O)[C@H](Cc2ccccc2)N(C)C(=...         -7.00   \n",
       "3      587  CC(C)C[C@@H]1NC(=O)[C@H](Cc2c[nH]cn2)NC(=O)[C@...         -6.74   \n",
       "4      921  CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...         -5.54   \n",
       "...    ...                                                ...           ...   \n",
       "1387  2481  CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2ccccc...         -4.50   \n",
       "1388  2485  CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@@H](Cc2cccc...         -4.80   \n",
       "1389  5604  CC(C)CN1CC(=O)N[C@@H](Cc2ccccc2)C(=O)NCCCCC(=O...         -6.38   \n",
       "1390  2513  C[C@H]1NCCCCCCNC(=O)[C@H](Cc2ccc(O)cc2)NC(=O)[...         -7.80   \n",
       "1391  2468  CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...         -4.90   \n",
       "\n",
       "             A   dA       meA     Me_dA  Ala(tBu)  Ala(indol-2-yl)  \\\n",
       "0     0.000000  0.0  0.133333  0.000000       0.0              0.0   \n",
       "1     0.000000  0.0  0.133333  0.066667       0.0              0.0   \n",
       "2     0.000000  0.0  0.133333  0.000000       0.0              0.0   \n",
       "3     0.071429  0.0  0.000000  0.000000       0.0              0.0   \n",
       "4     0.000000  0.0  0.133333  0.066667       0.0              0.0   \n",
       "...        ...  ...       ...       ...       ...              ...   \n",
       "1387  0.333333  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1388  0.333333  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1389  0.250000  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1390  0.000000  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1391  0.333333  0.0  0.000000  0.000000       0.0              0.0   \n",
       "\n",
       "      dAla(indol-2-yl)  ...  Degree_O  Single  Double  Triple  Aromatic  \\\n",
       "0                  0.0  ...         1      97      15       0        18   \n",
       "1                  0.0  ...         2      99      15       0        12   \n",
       "2                  0.0  ...         1      93      15       0        18   \n",
       "3                  0.0  ...         1      85      14       0        29   \n",
       "4                  0.0  ...         1      95      15       0        12   \n",
       "...                ...  ...       ...     ...     ...     ...       ...   \n",
       "1387               0.0  ...         1      23       3       0         6   \n",
       "1388               0.0  ...         1      23       3       0         6   \n",
       "1389               0.0  ...         1      22       4       0         6   \n",
       "1390               0.0  ...         1      24       3       0         6   \n",
       "1391               0.0  ...         1      20       3       0         6   \n",
       "\n",
       "      Conjugated  No-bond  Overall_Formal_Charge  Is_Aromatic  Is_In_Ring  \n",
       "0              0        0                    166            1           1  \n",
       "1              0        0                    157            1           1  \n",
       "2              0        0                    159            1           1  \n",
       "3              0        0                    157            1           1  \n",
       "4              0        0                    156            1           1  \n",
       "...          ...      ...                    ...          ...         ...  \n",
       "1387           0        0                     35            1           1  \n",
       "1388           0        0                     35            1           1  \n",
       "1389           0        0                     40            1           1  \n",
       "1390           0        0                     39            1           1  \n",
       "1391           0        0                     35            1           1  \n",
       "\n",
       "[1392 rows x 411 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('Monomer_features/Test_mon_comp.csv')\n",
    "df2 = pd.read_csv('Atomic_features/Test_all_atomic_desc.csv')\n",
    "df_test = pd.merge(df1, df2, on=['ID', 'SMILES', 'Permeability'], how='inner')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e665bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_feature_names(df):\n",
    "    def clean_name(name):\n",
    "        return re.sub(r'[^a-zA-Z0-9_]', '_', name)\n",
    "    df.columns = [clean_name(col) for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823eec94-032f-43da-8b0a-089b91d51ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of constant columns\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    \n",
    "    df_cleaned = df.drop(columns=constant_columns)\n",
    "    \n",
    "    return df_cleaned, constant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90bc377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 408)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 408)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1350\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1387\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6041158401656442\n",
      "0.5249689864150955\n",
      "0.5954164790463048\n",
      "0.5486588458792524\n",
      "0.2685393303795597\n",
      "0.6480607939538405\n",
      "0.5911986998570872\n",
      "0.4111088875515517\n",
      "0.473224463696027\n",
      "0.527933210941874\n",
      "0.547072977851865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>0.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3888</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.6236</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.3006</td>\n",
       "      <td>0.3893</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2656</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.5736</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.7723</td>\n",
       "      <td>0.7375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.4041</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.5344</td>\n",
       "      <td>0.5487</td>\n",
       "      <td>0.7499</td>\n",
       "      <td>0.7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.5741</td>\n",
       "      <td>0.5379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.8053</td>\n",
       "      <td>0.7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.3821</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.7503</td>\n",
       "      <td>0.7068</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.3665</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>0.7291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.6244</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.6831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.4336</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.4209</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.6643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.3921</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.2987</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.7095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>0.3946</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.5354</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.7369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2456                0.3656   \n",
       "DecisionTreeRegressor                    0.3888                0.4412   \n",
       "RandomForestRegressor                    0.2656                0.3767   \n",
       "GradientBoostingRegressor                0.2882                0.4041   \n",
       "AdaBoostRegressor                        0.4671                0.5466   \n",
       "XGBRegressor                             0.2257                0.3464   \n",
       "ExtraTreesRegressor                      0.2778                0.3821   \n",
       "LinearRegression                         0.3899                0.4426   \n",
       "KNeighborsRegressor                      0.3468                0.4336   \n",
       "SVR                                      0.3020                0.3921   \n",
       "MLPRegressor                             0.3771                0.4172   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4955               0.6057   \n",
       "DecisionTreeRegressor                     0.6236               0.3757   \n",
       "RandomForestRegressor                     0.5154               0.5736   \n",
       "GradientBoostingRegressor                 0.5368               0.5373   \n",
       "AdaBoostRegressor                         0.6835               0.2500   \n",
       "XGBRegressor                              0.4750               0.6377   \n",
       "ExtraTreesRegressor                       0.5270               0.5540   \n",
       "LinearRegression                          0.6244               0.3739   \n",
       "KNeighborsRegressor                       0.5889               0.4432   \n",
       "SVR                                       0.5496               0.5150   \n",
       "MLPRegressor                              0.6141               0.3946   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7796                0.7363   \n",
       "DecisionTreeRegressor                    0.6735                0.6330   \n",
       "RandomForestRegressor                    0.7586                0.7128   \n",
       "GradientBoostingRegressor                0.7403                0.6940   \n",
       "AdaBoostRegressor                        0.5584                0.4851   \n",
       "XGBRegressor                             0.7987                0.7547   \n",
       "ExtraTreesRegressor                      0.7503                0.7068   \n",
       "LinearRegression                         0.6337                0.6568   \n",
       "KNeighborsRegressor                      0.6770                0.6370   \n",
       "SVR                                      0.7215                0.6982   \n",
       "MLPRegressor                             0.6690                0.6870   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2505   0.3642    0.5005  0.6041   \n",
       "DecisionTreeRegressor       0.3006   0.3893    0.5483  0.5250   \n",
       "RandomForestRegressor       0.2560   0.3627    0.5060  0.5954   \n",
       "GradientBoostingRegressor   0.2856   0.4018    0.5344  0.5487   \n",
       "AdaBoostRegressor           0.4629   0.5435    0.6804  0.2685   \n",
       "XGBRegressor                0.2227   0.3395    0.4719  0.6481   \n",
       "ExtraTreesRegressor         0.2587   0.3665    0.5086  0.5912   \n",
       "LinearRegression            0.3727   0.4380    0.6105  0.4111   \n",
       "KNeighborsRegressor         0.3334   0.4209    0.5774  0.4732   \n",
       "SVR                         0.2987   0.3896    0.5466  0.5279   \n",
       "MLPRegressor                0.2866   0.3833    0.5354  0.5471   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7787                    0.7532  \n",
       "DecisionTreeRegressor                       0.7386                    0.6946  \n",
       "RandomForestRegressor                       0.7723                    0.7375  \n",
       "GradientBoostingRegressor                   0.7499                    0.7183  \n",
       "AdaBoostRegressor                           0.5741                    0.5379  \n",
       "XGBRegressor                                0.8053                    0.7721  \n",
       "ExtraTreesRegressor                         0.7722                    0.7291  \n",
       "LinearRegression                            0.6514                    0.6831  \n",
       "KNeighborsRegressor                         0.6940                    0.6643  \n",
       "SVR                                         0.7299                    0.7095  \n",
       "MLPRegressor                                0.7445                    0.7369  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_train = clean_feature_names(X_train)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_test = clean_feature_names(X_test)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6229bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('atomic_results/Results_all_atomic_desc_and_mono_comp.csv')\n",
    "prediction_df.to_csv('atomic_results/Prediction_data_all_atomic_desc_and_mono_comp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80997242-615f-488c-9256-619d3c387010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 262)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 262)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1350\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1387\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6041158401656442\n",
      "0.5245745104269488\n",
      "0.5957014291688538\n",
      "0.549335220979188\n",
      "0.2602755400335861\n",
      "0.6480607939538405\n",
      "0.5911926927173083\n",
      "0.41110888755155295\n",
      "0.4741669710813472\n",
      "0.527933577985747\n",
      "0.5153453716980363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>0.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3923</td>\n",
       "      <td>0.4434</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.6279</td>\n",
       "      <td>0.3009</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>0.6909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.7380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.4041</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.4014</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.5493</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.5561</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.4681</td>\n",
       "      <td>0.5487</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.8053</td>\n",
       "      <td>0.7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>0.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.6244</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.6831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.3328</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.6645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.3921</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.2987</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.7095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4174</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.6716</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.3067</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.5153</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2456                0.3656   \n",
       "DecisionTreeRegressor                    0.3923                0.4434   \n",
       "RandomForestRegressor                    0.2654                0.3765   \n",
       "GradientBoostingRegressor                0.2882                0.4041   \n",
       "AdaBoostRegressor                        0.4798                0.5561   \n",
       "XGBRegressor                             0.2257                0.3464   \n",
       "ExtraTreesRegressor                      0.2768                0.3816   \n",
       "LinearRegression                         0.3899                0.4426   \n",
       "KNeighborsRegressor                      0.3464                0.4335   \n",
       "SVR                                      0.3020                0.3921   \n",
       "MLPRegressor                             0.3750                0.4174   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4955               0.6057   \n",
       "DecisionTreeRegressor                     0.6264               0.3701   \n",
       "RandomForestRegressor                     0.5152               0.5739   \n",
       "GradientBoostingRegressor                 0.5368               0.5373   \n",
       "AdaBoostRegressor                         0.6927               0.2297   \n",
       "XGBRegressor                              0.4750               0.6377   \n",
       "ExtraTreesRegressor                       0.5261               0.5556   \n",
       "LinearRegression                          0.6244               0.3739   \n",
       "KNeighborsRegressor                       0.5885               0.4438   \n",
       "SVR                                       0.5496               0.5150   \n",
       "MLPRegressor                              0.6124               0.3979   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7796                0.7363   \n",
       "DecisionTreeRegressor                    0.6697                0.6279   \n",
       "RandomForestRegressor                    0.7588                0.7128   \n",
       "GradientBoostingRegressor                0.7403                0.6942   \n",
       "AdaBoostRegressor                        0.5549                0.4856   \n",
       "XGBRegressor                             0.7987                0.7547   \n",
       "ExtraTreesRegressor                      0.7514                0.7075   \n",
       "LinearRegression                         0.6337                0.6568   \n",
       "KNeighborsRegressor                      0.6772                0.6366   \n",
       "SVR                                      0.7215                0.6982   \n",
       "MLPRegressor                             0.6716                0.6850   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2505   0.3642    0.5005  0.6041   \n",
       "DecisionTreeRegressor       0.3009   0.3918    0.5485  0.5246   \n",
       "RandomForestRegressor       0.2559   0.3624    0.5058  0.5957   \n",
       "GradientBoostingRegressor   0.2852   0.4014    0.5340  0.5493   \n",
       "AdaBoostRegressor           0.4681   0.5487    0.6842  0.2603   \n",
       "XGBRegressor                0.2227   0.3395    0.4719  0.6481   \n",
       "ExtraTreesRegressor         0.2587   0.3666    0.5086  0.5912   \n",
       "LinearRegression            0.3727   0.4380    0.6105  0.4111   \n",
       "KNeighborsRegressor         0.3328   0.4204    0.5769  0.4742   \n",
       "SVR                         0.2987   0.3896    0.5466  0.5279   \n",
       "MLPRegressor                0.3067   0.3942    0.5538  0.5153   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7787                    0.7532  \n",
       "DecisionTreeRegressor                       0.7384                    0.6909  \n",
       "RandomForestRegressor                       0.7725                    0.7380  \n",
       "GradientBoostingRegressor                   0.7505                    0.7188  \n",
       "AdaBoostRegressor                           0.5825                    0.5489  \n",
       "XGBRegressor                                0.8053                    0.7721  \n",
       "ExtraTreesRegressor                         0.7722                    0.7293  \n",
       "LinearRegression                            0.6514                    0.6831  \n",
       "KNeighborsRegressor                         0.6945                    0.6645  \n",
       "SVR                                         0.7299                    0.7095  \n",
       "MLPRegressor                                0.7302                    0.7352  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_train = clean_feature_names(X_train)\n",
    "X_train, const_col = remove_constant_columns(X_train)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_test = clean_feature_names(X_test)\n",
    "X_test = X_test.drop(const_col,axis=1)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8543731f-a114-48f1-9739-30b9c798002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('atomic_results/Results_all_atomic_desc_and_mono_comp_const_rem.csv')\n",
    "prediction_df.to_csv('atomic_results/Prediction_data_all_atomic_desc_and_mono_comp_const_rem.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "816a1471-bfbe-45cc-80bc-1d7176abf3ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.658856691033044, -6.949840742667949, -5.77...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.053776975089306, -6.472870625624551, -7.0...</td>\n",
       "      <td>[-6.991698615663445, -6.411408445763892, -6.89...</td>\n",
       "      <td>[0.14585691905540257, 0.10495600928578822, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-8.0, -7.0, -5.15, -4.85, -5.85, -5.09, -5.09...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -8.0, -7.0, -7.0, -6.24, -5.15, -6.85,...</td>\n",
       "      <td>[-7.0, -7.048, -6.731999999999999, -7.0, -6.05...</td>\n",
       "      <td>[0.0, 0.5596570378365665, 0.5359999999999999, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.646585714285713, -6.7796999999999965, -6.0...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.904400000000001, -6.696482461389999, -6.7...</td>\n",
       "      <td>[-6.856584666666668, -6.708258492278, -6.61847...</td>\n",
       "      <td>[0.05192408182893296, 0.09590561162345373, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.42764231529753, -6.65592018174737, -5.5782...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.7004713117236046, -6.320734974959236, -6....</td>\n",
       "      <td>[-6.621170816630338, -6.267014705290754, -6.74...</td>\n",
       "      <td>[0.12209059489006517, 0.10126695056081805, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.798135090265214, -5.798135090265214, -5.79...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.76579539559827, -5.76579539559827, -5.765...</td>\n",
       "      <td>[-5.763516193627824, -5.763099762649212, -5.77...</td>\n",
       "      <td>[0.013481632314794649, 0.012934910665411936, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.742195, -6.990505, -5.996362, -5.2777576, ...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.596901, -6.454024, -7.3800654, -6.5661736...</td>\n",
       "      <td>[-6.708071, -6.613443, -7.3051972, -6.545186, ...</td>\n",
       "      <td>[0.14307745, 0.08720191, 0.26316768, 0.1302703...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.807700000000002, -6.925599999999999, -5.73...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.965500000000002, -6.693000000000001, -6.8...</td>\n",
       "      <td>[-6.963620000000001, -6.729140000000001, -6.78...</td>\n",
       "      <td>[0.006400046874828443, 0.054015057160018184, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.847762903472198, -6.978361273968966, -5.18...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.096561243440529, -5.438960291853395, -5.6...</td>\n",
       "      <td>[-7.162350714307841, -5.444344040572174, -5.56...</td>\n",
       "      <td>[0.0582278485483556, 0.10941785363993842, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-4.76, -7.0, -5.853333333333333, -4.926666666...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.533333333333332, -6.04, -5.38333333...</td>\n",
       "      <td>[-6.9093333333333335, -5.18, -6.23199999999999...</td>\n",
       "      <td>[0.04533333333333331, 0.32550132274863536, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.2767587783303975, -6.9897419865102215, -4....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.046643613936923, -5.114429729215835, -5.7...</td>\n",
       "      <td>[-7.0170324713951615, -5.139884039360652, -5.5...</td>\n",
       "      <td>[0.025014925909915168, 0.028926368389684987, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.9689641569803005, -7.509578742986041, -5.4...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-8.04075961779099, -6.707909064484587, -7.52...</td>\n",
       "      <td>[-7.95503555488837, -6.607626681466693, -7.269...</td>\n",
       "      <td>[0.14483896732725646, 0.1662590256059486, 0.13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.658856691033044, -6.949840742667949, -5.77...   \n",
       "1   [-8.0, -7.0, -5.15, -4.85, -5.85, -5.09, -5.09...   \n",
       "2   [-6.646585714285713, -6.7796999999999965, -6.0...   \n",
       "3   [-6.42764231529753, -6.65592018174737, -5.5782...   \n",
       "4   [-5.798135090265214, -5.798135090265214, -5.79...   \n",
       "5   [-6.742195, -6.990505, -5.996362, -5.2777576, ...   \n",
       "6   [-6.807700000000002, -6.925599999999999, -5.73...   \n",
       "7   [-5.847762903472198, -6.978361273968966, -5.18...   \n",
       "8   [-4.76, -7.0, -5.853333333333333, -4.926666666...   \n",
       "9   [-5.2767587783303975, -6.9897419865102215, -4....   \n",
       "10  [-6.9689641569803005, -7.509578742986041, -5.4...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.053776975089306, -6.472870625624551, -7.0...   \n",
       "1   [[-7.0, -8.0, -7.0, -7.0, -6.24, -5.15, -6.85,...   \n",
       "2   [[-6.904400000000001, -6.696482461389999, -6.7...   \n",
       "3   [[-6.7004713117236046, -6.320734974959236, -6....   \n",
       "4   [[-5.76579539559827, -5.76579539559827, -5.765...   \n",
       "5   [[-6.596901, -6.454024, -7.3800654, -6.5661736...   \n",
       "6   [[-6.965500000000002, -6.693000000000001, -6.8...   \n",
       "7   [[-7.096561243440529, -5.438960291853395, -5.6...   \n",
       "8   [[-7.0, -4.533333333333332, -6.04, -5.38333333...   \n",
       "9   [[-7.046643613936923, -5.114429729215835, -5.7...   \n",
       "10  [[-8.04075961779099, -6.707909064484587, -7.52...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.991698615663445, -6.411408445763892, -6.89...   \n",
       "1   [-7.0, -7.048, -6.731999999999999, -7.0, -6.05...   \n",
       "2   [-6.856584666666668, -6.708258492278, -6.61847...   \n",
       "3   [-6.621170816630338, -6.267014705290754, -6.74...   \n",
       "4   [-5.763516193627824, -5.763099762649212, -5.77...   \n",
       "5   [-6.708071, -6.613443, -7.3051972, -6.545186, ...   \n",
       "6   [-6.963620000000001, -6.729140000000001, -6.78...   \n",
       "7   [-7.162350714307841, -5.444344040572174, -5.56...   \n",
       "8   [-6.9093333333333335, -5.18, -6.23199999999999...   \n",
       "9   [-7.0170324713951615, -5.139884039360652, -5.5...   \n",
       "10  [-7.95503555488837, -6.607626681466693, -7.269...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.14585691905540257, 0.10495600928578822, 0.1...  \n",
       "1   [0.0, 0.5596570378365665, 0.5359999999999999, ...  \n",
       "2   [0.05192408182893296, 0.09590561162345373, 0.1...  \n",
       "3   [0.12209059489006517, 0.10126695056081805, 0.1...  \n",
       "4   [0.013481632314794649, 0.012934910665411936, 0...  \n",
       "5   [0.14307745, 0.08720191, 0.26316768, 0.1302703...  \n",
       "6   [0.006400046874828443, 0.054015057160018184, 0...  \n",
       "7   [0.0582278485483556, 0.10941785363993842, 0.04...  \n",
       "8   [0.04533333333333331, 0.32550132274863536, 0.2...  \n",
       "9   [0.025014925909915168, 0.028926368389684987, 0...  \n",
       "10  [0.14483896732725646, 0.1662590256059486, 0.13...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a730e380-c5cb-4b69-9a92-75f282d347fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ala_tBu_',\n",
       " 'Me_Ala_indol_2_yl_',\n",
       " 'Me_Abu_morpholino_',\n",
       " 'meD',\n",
       " 'Asp_Ph_2_NH2__',\n",
       " 'Glu_3R_Me_',\n",
       " 'Phe_CHF2_',\n",
       " 'Me_Phe_4_Cl_',\n",
       " 'Bn_4_OH__Gly',\n",
       " 'Bu_Gly',\n",
       " 'EtOEt_Gly',\n",
       " 'PhEt_Gly',\n",
       " 'isoamyl_Gly',\n",
       " '2_pyridylmethyl_Gly',\n",
       " 'Me_Hph',\n",
       " 'Hph_2_Cl_',\n",
       " 'Hph_3_Cl_',\n",
       " 'Hph_4_Cl_',\n",
       " 'Hse_Et_',\n",
       " 'Hyp_Et_',\n",
       " 'dK',\n",
       " 'meK',\n",
       " 'Me_dK',\n",
       " 'Lys_Cbz_',\n",
       " 'Lys_iPr_',\n",
       " 'Lys_Me_',\n",
       " 'Me_Lys_Me_',\n",
       " 'dLeu_3R_OH_',\n",
       " 'dN',\n",
       " 'Nle_CHF2_',\n",
       " 'Nle_OH_',\n",
       " 'Orn',\n",
       " '4Pal',\n",
       " 'dPip',\n",
       " 'Gln_Mes_',\n",
       " 'Ser_Bn_',\n",
       " 'Ser_EtNMe2_',\n",
       " 'Ser_EtOH_',\n",
       " 'Ser_isoamyl_',\n",
       " 'dSer_Me_',\n",
       " 'Ser_Ph_2_Cl__',\n",
       " 'Ser_Ph_3_Cl__',\n",
       " 'Ser_Pr_',\n",
       " 'Me_Ser_isoamyl_',\n",
       " 'Me_Ser_Pr_',\n",
       " 'dT',\n",
       " 'Me_Tza',\n",
       " '_N__O_Val',\n",
       " 'meW',\n",
       " 'Me_dW',\n",
       " 'Trp_6_Br_',\n",
       " 'Tyr_CHF2_',\n",
       " 'dTyr_bR_OMe_',\n",
       " '_N__O_Tyr',\n",
       " 'Mono3',\n",
       " 'Mono4',\n",
       " 'Mono5',\n",
       " 'Mono15',\n",
       " 'Mono17',\n",
       " 'Mono18',\n",
       " 'Mono19',\n",
       " 'Mono20',\n",
       " 'Mono23',\n",
       " 'Mono24',\n",
       " 'Mono25',\n",
       " 'Mono32',\n",
       " 'Mono33',\n",
       " 'Mono36',\n",
       " 'Mono48',\n",
       " 'Mono49',\n",
       " 'Mono50',\n",
       " 'Mono51',\n",
       " 'Mono52',\n",
       " 'Mono53',\n",
       " 'Mono54',\n",
       " 'Mono55',\n",
       " 'Mono56',\n",
       " 'Mono57',\n",
       " 'Mono58',\n",
       " 'Mono59',\n",
       " 'Mono60',\n",
       " 'Mono61',\n",
       " 'Mono62',\n",
       " 'Mono63',\n",
       " 'Mono64',\n",
       " 'Mono65',\n",
       " 'Mono66',\n",
       " 'Mono70',\n",
       " 'Mono75',\n",
       " 'Mono106',\n",
       " 'Mono107',\n",
       " 'deca_',\n",
       " 'Mono21_',\n",
       " 'Mono22_',\n",
       " 'Thr_O__S_',\n",
       " 'Ac3c',\n",
       " 'Abu_5_Tet_',\n",
       " 'Gly_allyl_',\n",
       " '_pyrro',\n",
       " 'Aze',\n",
       " 'Bal_d3_Me_',\n",
       " 'Me_Bal_d3_Me_',\n",
       " 'Bal_d3_EtPh_',\n",
       " 'meH',\n",
       " 'Phe_3_Cl_',\n",
       " 'Phe_3_F_',\n",
       " 'Phe_4_Cl_',\n",
       " 'Mono113',\n",
       " 'Ser_tBuOH_',\n",
       " 'Val_3_OH_',\n",
       " 'Mono114',\n",
       " 'Ac5c',\n",
       " 'Hph_4_CF3_3_5_diF_',\n",
       " 'Hph_4_Me_',\n",
       " 'Phe_3_5_diCl_',\n",
       " 'Hph_4_CF3_3_Cl_',\n",
       " 'Me_Phe_4_Me_',\n",
       " 'Hph_4_tBu_',\n",
       " 'Hph_3_4_diCl_',\n",
       " 'Hch',\n",
       " 'Phe_3_Cl_5_F_',\n",
       " 'Me_Gly_cPent_',\n",
       " 'Phe_3_CF3_',\n",
       " 'Et_Phe_4_Me_',\n",
       " 'Hph_4_CF3_',\n",
       " '_nme2',\n",
       " 'Me_Chg',\n",
       " 'Et_Leu',\n",
       " 'Me_Ser_Me_',\n",
       " 'Me_Hse_Me_',\n",
       " 'Gly_cPr_',\n",
       " 'Me_Gly_cPr_',\n",
       " 'Gly_cBu_',\n",
       " 'Me_Gly_cBu_',\n",
       " 'Gly_cPent_',\n",
       " 'Ala_cPr_',\n",
       " 'Ala_cBu_',\n",
       " 'Ala_cPent_',\n",
       " 'Me_Nva_F2_',\n",
       " '_mor',\n",
       " '_aze',\n",
       " 'Mono123',\n",
       " 'Triple',\n",
       " 'Conjugated',\n",
       " 'No_bond',\n",
       " 'Is_In_Ring']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9189f80-ec3c-47b0-abc3-be50d1538281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      -6.74\n",
       "4      -5.54\n",
       "        ... \n",
       "1387   -4.50\n",
       "1388   -4.80\n",
       "1389   -6.38\n",
       "1390   -7.80\n",
       "1391   -4.90\n",
       "Name: Permeability, Length: 1392, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.iloc[0]['Y Test actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5106107-6bb5-498d-ae27-178367d88a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-7.05377698, -6.47287063, -7.01247687, ..., -6.51824957,\n",
       "        -7.28763952, -5.20882713]),\n",
       " array([-6.99388582, -6.44469643, -6.89785042, ..., -6.63432063,\n",
       "        -7.40562944, -4.88128099]),\n",
       " array([-6.90343197, -6.36440712, -6.85006668, ..., -6.44529051,\n",
       "        -7.20895817, -5.16867784]),\n",
       " array([-6.7864048 , -6.2344915 , -6.60284052, ..., -6.46675722,\n",
       "        -6.9922974 , -5.2819053 ]),\n",
       " array([-7.22099351, -6.54057655, -7.12462562, ..., -6.39770284,\n",
       "        -6.89359372, -5.15860885])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LGBM\n",
    "prediction_df.iloc[0]['Test prediction folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0829cf92-4235-43d2-aca3-f22fde9408da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.99169862, -6.41140845, -6.89757202, ..., -6.49246415,\n",
       "       -7.15762365, -5.13986002])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.iloc[0]['Test Predictions Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eae75006-6b38-4193-a066-e8f847f60043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-7.09656124, -5.43896029, -5.63531842, ..., -6.74296175,\n",
       "        -5.41343869, -5.2602085 ]),\n",
       " array([-7.19334573, -5.24121322, -5.5532147 , ..., -6.69315839,\n",
       "        -6.61879627, -5.99895416]),\n",
       " array([-7.1106    , -5.54058297, -5.49003549, ..., -7.21      ,\n",
       "        -6.12696974, -5.02479292]),\n",
       " array([-7.15443592, -5.46171731, -5.56909788, ..., -6.79989033,\n",
       "        -5.87172276, -4.33066229]),\n",
       " array([-7.25681068, -5.5392464 , -5.56188773, ..., -6.66173606,\n",
       "        -5.78848423, -5.55013985])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear regression\n",
    "prediction_df.iloc[7]['Test prediction folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0f63c8f-f58b-42c1-85d5-3e43e5de71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.16235071, -5.44434404, -5.56191084, ..., -6.82154931,\n",
       "       -5.96388234, -5.23295154])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.iloc[7]['Test Predictions Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1cc15-8d51-4bc7-a374-39f52e61d3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30f00a-1cbe-490a-8f1d-be5d321c2065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1feb74-581d-42ae-b0e5-d68334c05045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf096795-11a3-4ff1-9c65-b30cc012c57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b17fd9d-71e0-4532-8862-c5f51c026244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        mse_test_folds = []\n",
    "        mae_test_folds = []\n",
    "        rmse_test_folds = []\n",
    "        r2_test_folds = []\n",
    "        pearson_test_folds = []\n",
    "        spearman_test_folds = []\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "            \n",
    "\n",
    "            mse_test_folds.append(mean_squared_error(y_test, predictions_test_fold))\n",
    "            mae_test_folds.append(mean_absolute_error(y_test, predictions_test_fold))\n",
    "            rmse_test_folds.append(np.sqrt(mse_test_folds[-1]))\n",
    "            r2_test_folds.append(r2_score(y_test, predictions_test_fold))\n",
    "            pearson_test, _ = pearsonr(y_test, predictions_test_fold)\n",
    "            spearman_test, _ = spearmanr(y_test, predictions_test_fold)\n",
    "            pearson_test_folds.append(pearson_test)\n",
    "            spearman_test_folds.append(spearman_test)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "        # Helper function to format mean Â± std string\n",
    "        def format_metric(metric_values):\n",
    "            mean_val = np.mean(metric_values)\n",
    "            std_val = np.std(metric_values)\n",
    "            return f\"{mean_val:.4f} Â± {std_val:.4f}\"\n",
    "\n",
    "        mse_test_str = format_metric(mse_test_folds)\n",
    "        mae_test_str = format_metric(mae_test_folds)\n",
    "        rmse_test_str = format_metric(rmse_test_folds)\n",
    "        r2_test_str = format_metric(r2_test_folds)\n",
    "        pearson_test_str = format_metric(pearson_test_folds)\n",
    "        spearman_test_str = format_metric(spearman_test_folds)\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Test': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "            'Test MSE folds': mse_test_folds,\n",
    "            'Test MAE folds': mae_test_folds,\n",
    "            'Test RMSE folds': rmse_test_folds,\n",
    "            'Test R2 folds': r2_test_folds,\n",
    "            'Test PCC folds': pearson_test_folds,\n",
    "            'Test SCC folds': spearman_test_folds,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': mse_test_str,\n",
    "            'Test MAE': mae_test_str,\n",
    "            'Test RMSE': rmse_test_str,\n",
    "            'Test R2': r2_test_str,\n",
    "            'Test Pearson Correlation': pearson_test_str,\n",
    "            'Test Spearman Correlation': spearman_test_str,\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "639a444d-681c-4139-8413-bb521d0b6734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 262)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 262)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1350\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1387\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score -5.739237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.2558 Â± 0.0026</td>\n",
       "      <td>0.3676 Â± 0.0018</td>\n",
       "      <td>0.5057 Â± 0.0025</td>\n",
       "      <td>0.5959 Â± 0.0040</td>\n",
       "      <td>0.7728 Â± 0.0028</td>\n",
       "      <td>0.7482 Â± 0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3923</td>\n",
       "      <td>0.4434</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.6279</td>\n",
       "      <td>0.3998 Â± 0.0120</td>\n",
       "      <td>0.4420 Â± 0.0068</td>\n",
       "      <td>0.6322 Â± 0.0095</td>\n",
       "      <td>0.3683 Â± 0.0189</td>\n",
       "      <td>0.6738 Â± 0.0091</td>\n",
       "      <td>0.6370 Â± 0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.2718 Â± 0.0067</td>\n",
       "      <td>0.3730 Â± 0.0027</td>\n",
       "      <td>0.5213 Â± 0.0064</td>\n",
       "      <td>0.5705 Â± 0.0106</td>\n",
       "      <td>0.7579 Â± 0.0063</td>\n",
       "      <td>0.7227 Â± 0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.4041</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.2887 Â± 0.0028</td>\n",
       "      <td>0.4036 Â± 0.0016</td>\n",
       "      <td>0.5373 Â± 0.0026</td>\n",
       "      <td>0.5438 Â± 0.0044</td>\n",
       "      <td>0.7454 Â± 0.0033</td>\n",
       "      <td>0.7137 Â± 0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.5561</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.4796 Â± 0.0120</td>\n",
       "      <td>0.5537 Â± 0.0103</td>\n",
       "      <td>0.6925 Â± 0.0087</td>\n",
       "      <td>0.2421 Â± 0.0190</td>\n",
       "      <td>0.5617 Â± 0.0155</td>\n",
       "      <td>0.5431 Â± 0.0226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.2375 Â± 0.0044</td>\n",
       "      <td>0.3507 Â± 0.0036</td>\n",
       "      <td>0.4873 Â± 0.0045</td>\n",
       "      <td>0.6247 Â± 0.0069</td>\n",
       "      <td>0.7906 Â± 0.0043</td>\n",
       "      <td>0.7580 Â± 0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.2854 Â± 0.0087</td>\n",
       "      <td>0.3831 Â± 0.0046</td>\n",
       "      <td>0.5342 Â± 0.0082</td>\n",
       "      <td>0.5490 Â± 0.0137</td>\n",
       "      <td>0.7503 Â± 0.0071</td>\n",
       "      <td>0.7100 Â± 0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4313</td>\n",
       "      <td>0.4481</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.3075</td>\n",
       "      <td>0.6039</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.4002 Â± 0.0377</td>\n",
       "      <td>0.4450 Â± 0.0081</td>\n",
       "      <td>0.6319 Â± 0.0292</td>\n",
       "      <td>0.3676 Â± 0.0596</td>\n",
       "      <td>0.6305 Â± 0.0283</td>\n",
       "      <td>0.6779 Â± 0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.3639 Â± 0.0084</td>\n",
       "      <td>0.4379 Â± 0.0061</td>\n",
       "      <td>0.6032 Â± 0.0070</td>\n",
       "      <td>0.4250 Â± 0.0133</td>\n",
       "      <td>0.6684 Â± 0.0087</td>\n",
       "      <td>0.6375 Â± 0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.3921</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.3034 Â± 0.0035</td>\n",
       "      <td>0.3921 Â± 0.0034</td>\n",
       "      <td>0.5508 Â± 0.0032</td>\n",
       "      <td>0.5205 Â± 0.0056</td>\n",
       "      <td>0.7245 Â± 0.0041</td>\n",
       "      <td>0.7068 Â± 0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>7.8435</td>\n",
       "      <td>0.7099</td>\n",
       "      <td>2.8006</td>\n",
       "      <td>-11.5938</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.3480 Â± 0.0165</td>\n",
       "      <td>0.4098 Â± 0.0041</td>\n",
       "      <td>0.5897 Â± 0.0140</td>\n",
       "      <td>0.4501 Â± 0.0261</td>\n",
       "      <td>0.7006 Â± 0.0137</td>\n",
       "      <td>0.7216 Â± 0.0058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2456                0.3656   \n",
       "DecisionTreeRegressor                    0.3923                0.4434   \n",
       "RandomForestRegressor                    0.2654                0.3765   \n",
       "GradientBoostingRegressor                0.2882                0.4041   \n",
       "AdaBoostRegressor                        0.4798                0.5561   \n",
       "XGBRegressor                             0.2257                0.3464   \n",
       "ExtraTreesRegressor                      0.2768                0.3816   \n",
       "LinearRegression                         0.4313                0.4481   \n",
       "KNeighborsRegressor                      0.3464                0.4335   \n",
       "SVR                                      0.3020                0.3921   \n",
       "MLPRegressor                             7.8435                0.7099   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4955               0.6057   \n",
       "DecisionTreeRegressor                     0.6264               0.3701   \n",
       "RandomForestRegressor                     0.5152               0.5739   \n",
       "GradientBoostingRegressor                 0.5368               0.5373   \n",
       "AdaBoostRegressor                         0.6927               0.2297   \n",
       "XGBRegressor                              0.4750               0.6377   \n",
       "ExtraTreesRegressor                       0.5261               0.5556   \n",
       "LinearRegression                          0.6567               0.3075   \n",
       "KNeighborsRegressor                       0.5885               0.4438   \n",
       "SVR                                       0.5496               0.5150   \n",
       "MLPRegressor                              2.8006             -11.5938   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7796                0.7363   \n",
       "DecisionTreeRegressor                    0.6697                0.6279   \n",
       "RandomForestRegressor                    0.7588                0.7128   \n",
       "GradientBoostingRegressor                0.7403                0.6942   \n",
       "AdaBoostRegressor                        0.5549                0.4856   \n",
       "XGBRegressor                             0.7987                0.7547   \n",
       "ExtraTreesRegressor                      0.7514                0.7076   \n",
       "LinearRegression                         0.6039                0.6568   \n",
       "KNeighborsRegressor                      0.6772                0.6366   \n",
       "SVR                                      0.7215                0.6982   \n",
       "MLPRegressor                             0.1631                0.6848   \n",
       "\n",
       "                                  Test MSE         Test MAE        Test RMSE  \\\n",
       "LGBMRegressor              0.2558 Â± 0.0026  0.3676 Â± 0.0018  0.5057 Â± 0.0025   \n",
       "DecisionTreeRegressor      0.3998 Â± 0.0120  0.4420 Â± 0.0068  0.6322 Â± 0.0095   \n",
       "RandomForestRegressor      0.2718 Â± 0.0067  0.3730 Â± 0.0027  0.5213 Â± 0.0064   \n",
       "GradientBoostingRegressor  0.2887 Â± 0.0028  0.4036 Â± 0.0016  0.5373 Â± 0.0026   \n",
       "AdaBoostRegressor          0.4796 Â± 0.0120  0.5537 Â± 0.0103  0.6925 Â± 0.0087   \n",
       "XGBRegressor               0.2375 Â± 0.0044  0.3507 Â± 0.0036  0.4873 Â± 0.0045   \n",
       "ExtraTreesRegressor        0.2854 Â± 0.0087  0.3831 Â± 0.0046  0.5342 Â± 0.0082   \n",
       "LinearRegression           0.4002 Â± 0.0377  0.4450 Â± 0.0081  0.6319 Â± 0.0292   \n",
       "KNeighborsRegressor        0.3639 Â± 0.0084  0.4379 Â± 0.0061  0.6032 Â± 0.0070   \n",
       "SVR                        0.3034 Â± 0.0035  0.3921 Â± 0.0034  0.5508 Â± 0.0032   \n",
       "MLPRegressor               0.3480 Â± 0.0165  0.4098 Â± 0.0041  0.5897 Â± 0.0140   \n",
       "\n",
       "                                   Test R2 Test Pearson Correlation  \\\n",
       "LGBMRegressor              0.5959 Â± 0.0040          0.7728 Â± 0.0028   \n",
       "DecisionTreeRegressor      0.3683 Â± 0.0189          0.6738 Â± 0.0091   \n",
       "RandomForestRegressor      0.5705 Â± 0.0106          0.7579 Â± 0.0063   \n",
       "GradientBoostingRegressor  0.5438 Â± 0.0044          0.7454 Â± 0.0033   \n",
       "AdaBoostRegressor          0.2421 Â± 0.0190          0.5617 Â± 0.0155   \n",
       "XGBRegressor               0.6247 Â± 0.0069          0.7906 Â± 0.0043   \n",
       "ExtraTreesRegressor        0.5490 Â± 0.0137          0.7503 Â± 0.0071   \n",
       "LinearRegression           0.3676 Â± 0.0596          0.6305 Â± 0.0283   \n",
       "KNeighborsRegressor        0.4250 Â± 0.0133          0.6684 Â± 0.0087   \n",
       "SVR                        0.5205 Â± 0.0056          0.7245 Â± 0.0041   \n",
       "MLPRegressor               0.4501 Â± 0.0261          0.7006 Â± 0.0137   \n",
       "\n",
       "                          Test Spearman Correlation  \n",
       "LGBMRegressor                       0.7482 Â± 0.0043  \n",
       "DecisionTreeRegressor               0.6370 Â± 0.0087  \n",
       "RandomForestRegressor               0.7227 Â± 0.0058  \n",
       "GradientBoostingRegressor           0.7137 Â± 0.0043  \n",
       "AdaBoostRegressor                   0.5431 Â± 0.0226  \n",
       "XGBRegressor                        0.7580 Â± 0.0057  \n",
       "ExtraTreesRegressor                 0.7100 Â± 0.0074  \n",
       "LinearRegression                    0.6779 Â± 0.0031  \n",
       "KNeighborsRegressor                 0.6375 Â± 0.0086  \n",
       "SVR                                 0.7068 Â± 0.0034  \n",
       "MLPRegressor                        0.7216 Â± 0.0058  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_train = clean_feature_names(X_train)\n",
    "X_train, const_col = remove_constant_columns(X_train)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_test = clean_feature_names(X_test)\n",
    "X_test = X_test.drop(const_col,axis=1)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d1ce459-fc92-4eea-905e-74089a291774",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Test</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "      <th>Test MSE folds</th>\n",
       "      <th>Test MAE folds</th>\n",
       "      <th>Test RMSE folds</th>\n",
       "      <th>Test R2 folds</th>\n",
       "      <th>Test PCC folds</th>\n",
       "      <th>Test SCC folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.053776975089306, -6.472870625624551, -7.0...</td>\n",
       "      <td>[-6.991698615663445, -6.411408445763892, -6.89...</td>\n",
       "      <td>[0.14585691905540257, 0.10495600928578822, 0.1...</td>\n",
       "      <td>[0.25749449953304926, 0.2526025574936686, 0.25...</td>\n",
       "      <td>[0.3693024990998288, 0.3655825321746018, 0.367...</td>\n",
       "      <td>[0.5074391584545376, 0.5025958192162651, 0.506...</td>\n",
       "      <td>[0.5931053271378839, 0.6008356093745292, 0.595...</td>\n",
       "      <td>[0.7711017867505152, 0.7765789773273701, 0.772...</td>\n",
       "      <td>[0.7487237042680333, 0.7533817333028223, 0.749...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -8.0, -7.0, -7.0, -6.24, -5.15, -6.85,...</td>\n",
       "      <td>[-7.0, -7.048, -6.731999999999999, -7.0, -6.05...</td>\n",
       "      <td>[0.0, 0.5596570378365665, 0.5359999999999999, ...</td>\n",
       "      <td>[0.4022647110009843, 0.40266591148537617, 0.40...</td>\n",
       "      <td>[0.4441470510342425, 0.4427447753945707, 0.438...</td>\n",
       "      <td>[0.6342434162062578, 0.6345596201188476, 0.633...</td>\n",
       "      <td>[0.36433839059264617, 0.36370441068183335, 0.3...</td>\n",
       "      <td>[0.6706803452601046, 0.6726502650215294, 0.675...</td>\n",
       "      <td>[0.6218421858454376, 0.6378608036165951, 0.640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.904400000000001, -6.696482461390001, -6.7...</td>\n",
       "      <td>[-6.856584666666667, -6.708258492278, -6.61847...</td>\n",
       "      <td>[0.05192408182893306, 0.09590561162345398, 0.1...</td>\n",
       "      <td>[0.2813030689439093, 0.26111452648631195, 0.26...</td>\n",
       "      <td>[0.37760110018524495, 0.36931799291672046, 0.3...</td>\n",
       "      <td>[0.5303801174100602, 0.5109936657986202, 0.518...</td>\n",
       "      <td>[0.5554828533401339, 0.5873849343311598, 0.574...</td>\n",
       "      <td>[0.7485183329234384, 0.7674603145351845, 0.761...</td>\n",
       "      <td>[0.7164362723306894, 0.7328499773266577, 0.724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.7004713117236046, -6.320734974959236, -6....</td>\n",
       "      <td>[-6.621170816630338, -6.267014705290754, -6.74...</td>\n",
       "      <td>[0.12209059489006517, 0.10126695056081805, 0.1...</td>\n",
       "      <td>[0.29387751905763826, 0.28628672384241655, 0.2...</td>\n",
       "      <td>[0.406071795260299, 0.40212956800493316, 0.403...</td>\n",
       "      <td>[0.5421047122628969, 0.5350576827244111, 0.536...</td>\n",
       "      <td>[0.5356126162099226, 0.547607645779339, 0.5450...</td>\n",
       "      <td>[0.7400125762979344, 0.7499783654708734, 0.744...</td>\n",
       "      <td>[0.7103144015198812, 0.7215225542774073, 0.710...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.76579539559827, -5.76579539559827, -5.765...</td>\n",
       "      <td>[-5.763516193627824, -5.763099762649212, -5.77...</td>\n",
       "      <td>[0.013481632314794649, 0.012934910665411936, 0...</td>\n",
       "      <td>[0.4833331406322164, 0.47632274795055485, 0.49...</td>\n",
       "      <td>[0.5535954655636331, 0.5539336257502787, 0.567...</td>\n",
       "      <td>[0.6952216485641226, 0.6901613926833019, 0.704...</td>\n",
       "      <td>[0.2362334710154732, 0.24731134429825197, 0.21...</td>\n",
       "      <td>[0.5349037620112272, 0.5786370300195084, 0.554...</td>\n",
       "      <td>[0.5867663371393864, 0.5344030821729185, 0.521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.596901, -6.454024, -7.3800654, -6.5661736...</td>\n",
       "      <td>[-6.708071, -6.613443, -7.3051972, -6.545186, ...</td>\n",
       "      <td>[0.14307745, 0.08720191, 0.26316768, 0.1302703...</td>\n",
       "      <td>[0.23614515352220944, 0.23215694951370533, 0.2...</td>\n",
       "      <td>[0.34766199900274636, 0.34804309811688156, 0.3...</td>\n",
       "      <td>[0.4859476859932656, 0.4818266799521435, 0.491...</td>\n",
       "      <td>[0.626841718309944, 0.6331439071655912, 0.6186...</td>\n",
       "      <td>[0.7919731399565366, 0.7958195923948379, 0.786...</td>\n",
       "      <td>[0.7622964527933916, 0.7656273736139149, 0.758...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.965500000000002, -6.693000000000001, -6.8...</td>\n",
       "      <td>[-6.963620000000001, -6.729140000000001, -6.78...</td>\n",
       "      <td>[0.006400046874828443, 0.054015057160018067, 0...</td>\n",
       "      <td>[0.29035641543528795, 0.268507211910031, 0.286...</td>\n",
       "      <td>[0.38446977201797833, 0.3752100175350928, 0.38...</td>\n",
       "      <td>[0.5388473025220484, 0.5181768152957357, 0.535...</td>\n",
       "      <td>[0.541176689652765, 0.5757029592889293, 0.5476...</td>\n",
       "      <td>[0.7457623904968043, 0.76390163757286, 0.75113...</td>\n",
       "      <td>[0.7038885470430697, 0.7184600868405062, 0.719...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.096561243440529, -5.438960291853395, -5.6...</td>\n",
       "      <td>[-7.162350714307841, -5.444344040572174, -5.56...</td>\n",
       "      <td>[0.0582278485483556, 0.10941785363993842, 0.04...</td>\n",
       "      <td>[0.40800648771748604, 0.4694447631925365, 0.36...</td>\n",
       "      <td>[0.44460981659818644, 0.4605201904830304, 0.43...</td>\n",
       "      <td>[0.6387538553445185, 0.6851603923115641, 0.606...</td>\n",
       "      <td>[0.35526519344495944, 0.25817998562123023, 0.4...</td>\n",
       "      <td>[0.6227760468179098, 0.5794189308309932, 0.655...</td>\n",
       "      <td>[0.6795196496635527, 0.6736425538393991, 0.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.533333333333332, -6.04, -5.38333333...</td>\n",
       "      <td>[-6.9093333333333335, -5.18, -6.23199999999999...</td>\n",
       "      <td>[0.04533333333333331, 0.32550132274863536, 0.2...</td>\n",
       "      <td>[0.3751935753249752, 0.3498073467579668, 0.361...</td>\n",
       "      <td>[0.4462702014954103, 0.4282700536198516, 0.434...</td>\n",
       "      <td>[0.6125304688952014, 0.5914451341907945, 0.600...</td>\n",
       "      <td>[0.4071163952291371, 0.4472318974503796, 0.429...</td>\n",
       "      <td>[0.6555706316991783, 0.6812849280004103, 0.673...</td>\n",
       "      <td>[0.6260751805702771, 0.651736728972367, 0.6411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.046643613936923, -5.114429729215835, -5.7...</td>\n",
       "      <td>[-7.0170324713951615, -5.139884039360652, -5.5...</td>\n",
       "      <td>[0.025014925909915168, 0.028926368389684987, 0...</td>\n",
       "      <td>[0.30326053065402364, 0.29937422825286675, 0.3...</td>\n",
       "      <td>[0.3911359910292487, 0.38730514290234747, 0.39...</td>\n",
       "      <td>[0.5506909574834361, 0.5471510104649966, 0.553...</td>\n",
       "      <td>[0.5207855133362838, 0.5269266765340594, 0.515...</td>\n",
       "      <td>[0.7252035911074748, 0.7287885485529068, 0.720...</td>\n",
       "      <td>[0.7081107084563254, 0.7120511832099063, 0.705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-8.04075961779099, -6.707909064484587, -7.52...</td>\n",
       "      <td>[-7.95503555488837, -6.607626681466693, -7.269...</td>\n",
       "      <td>[0.14483896732725646, 0.1662590256059486, 0.13...</td>\n",
       "      <td>[0.3313529932953808, 0.3732581052180205, 0.328...</td>\n",
       "      <td>[0.4055213089491126, 0.41456500457700096, 0.40...</td>\n",
       "      <td>[0.5756326895646049, 0.6109485291070111, 0.573...</td>\n",
       "      <td>[0.47639360043299817, 0.41017483910825636, 0.4...</td>\n",
       "      <td>[0.7136912994169193, 0.6821090879716332, 0.718...</td>\n",
       "      <td>[0.7223750185510817, 0.7116683920585688, 0.729...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                               Y Test  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.053776975089306, -6.472870625624551, -7.0...   \n",
       "1   [[-7.0, -8.0, -7.0, -7.0, -6.24, -5.15, -6.85,...   \n",
       "2   [[-6.904400000000001, -6.696482461390001, -6.7...   \n",
       "3   [[-6.7004713117236046, -6.320734974959236, -6....   \n",
       "4   [[-5.76579539559827, -5.76579539559827, -5.765...   \n",
       "5   [[-6.596901, -6.454024, -7.3800654, -6.5661736...   \n",
       "6   [[-6.965500000000002, -6.693000000000001, -6.8...   \n",
       "7   [[-7.096561243440529, -5.438960291853395, -5.6...   \n",
       "8   [[-7.0, -4.533333333333332, -6.04, -5.38333333...   \n",
       "9   [[-7.046643613936923, -5.114429729215835, -5.7...   \n",
       "10  [[-8.04075961779099, -6.707909064484587, -7.52...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.991698615663445, -6.411408445763892, -6.89...   \n",
       "1   [-7.0, -7.048, -6.731999999999999, -7.0, -6.05...   \n",
       "2   [-6.856584666666667, -6.708258492278, -6.61847...   \n",
       "3   [-6.621170816630338, -6.267014705290754, -6.74...   \n",
       "4   [-5.763516193627824, -5.763099762649212, -5.77...   \n",
       "5   [-6.708071, -6.613443, -7.3051972, -6.545186, ...   \n",
       "6   [-6.963620000000001, -6.729140000000001, -6.78...   \n",
       "7   [-7.162350714307841, -5.444344040572174, -5.56...   \n",
       "8   [-6.9093333333333335, -5.18, -6.23199999999999...   \n",
       "9   [-7.0170324713951615, -5.139884039360652, -5.5...   \n",
       "10  [-7.95503555488837, -6.607626681466693, -7.269...   \n",
       "\n",
       "                                 Test Predictions Std  \\\n",
       "0   [0.14585691905540257, 0.10495600928578822, 0.1...   \n",
       "1   [0.0, 0.5596570378365665, 0.5359999999999999, ...   \n",
       "2   [0.05192408182893306, 0.09590561162345398, 0.1...   \n",
       "3   [0.12209059489006517, 0.10126695056081805, 0.1...   \n",
       "4   [0.013481632314794649, 0.012934910665411936, 0...   \n",
       "5   [0.14307745, 0.08720191, 0.26316768, 0.1302703...   \n",
       "6   [0.006400046874828443, 0.054015057160018067, 0...   \n",
       "7   [0.0582278485483556, 0.10941785363993842, 0.04...   \n",
       "8   [0.04533333333333331, 0.32550132274863536, 0.2...   \n",
       "9   [0.025014925909915168, 0.028926368389684987, 0...   \n",
       "10  [0.14483896732725646, 0.1662590256059486, 0.13...   \n",
       "\n",
       "                                       Test MSE folds  \\\n",
       "0   [0.25749449953304926, 0.2526025574936686, 0.25...   \n",
       "1   [0.4022647110009843, 0.40266591148537617, 0.40...   \n",
       "2   [0.2813030689439093, 0.26111452648631195, 0.26...   \n",
       "3   [0.29387751905763826, 0.28628672384241655, 0.2...   \n",
       "4   [0.4833331406322164, 0.47632274795055485, 0.49...   \n",
       "5   [0.23614515352220944, 0.23215694951370533, 0.2...   \n",
       "6   [0.29035641543528795, 0.268507211910031, 0.286...   \n",
       "7   [0.40800648771748604, 0.4694447631925365, 0.36...   \n",
       "8   [0.3751935753249752, 0.3498073467579668, 0.361...   \n",
       "9   [0.30326053065402364, 0.29937422825286675, 0.3...   \n",
       "10  [0.3313529932953808, 0.3732581052180205, 0.328...   \n",
       "\n",
       "                                       Test MAE folds  \\\n",
       "0   [0.3693024990998288, 0.3655825321746018, 0.367...   \n",
       "1   [0.4441470510342425, 0.4427447753945707, 0.438...   \n",
       "2   [0.37760110018524495, 0.36931799291672046, 0.3...   \n",
       "3   [0.406071795260299, 0.40212956800493316, 0.403...   \n",
       "4   [0.5535954655636331, 0.5539336257502787, 0.567...   \n",
       "5   [0.34766199900274636, 0.34804309811688156, 0.3...   \n",
       "6   [0.38446977201797833, 0.3752100175350928, 0.38...   \n",
       "7   [0.44460981659818644, 0.4605201904830304, 0.43...   \n",
       "8   [0.4462702014954103, 0.4282700536198516, 0.434...   \n",
       "9   [0.3911359910292487, 0.38730514290234747, 0.39...   \n",
       "10  [0.4055213089491126, 0.41456500457700096, 0.40...   \n",
       "\n",
       "                                      Test RMSE folds  \\\n",
       "0   [0.5074391584545376, 0.5025958192162651, 0.506...   \n",
       "1   [0.6342434162062578, 0.6345596201188476, 0.633...   \n",
       "2   [0.5303801174100602, 0.5109936657986202, 0.518...   \n",
       "3   [0.5421047122628969, 0.5350576827244111, 0.536...   \n",
       "4   [0.6952216485641226, 0.6901613926833019, 0.704...   \n",
       "5   [0.4859476859932656, 0.4818266799521435, 0.491...   \n",
       "6   [0.5388473025220484, 0.5181768152957357, 0.535...   \n",
       "7   [0.6387538553445185, 0.6851603923115641, 0.606...   \n",
       "8   [0.6125304688952014, 0.5914451341907945, 0.600...   \n",
       "9   [0.5506909574834361, 0.5471510104649966, 0.553...   \n",
       "10  [0.5756326895646049, 0.6109485291070111, 0.573...   \n",
       "\n",
       "                                        Test R2 folds  \\\n",
       "0   [0.5931053271378839, 0.6008356093745292, 0.595...   \n",
       "1   [0.36433839059264617, 0.36370441068183335, 0.3...   \n",
       "2   [0.5554828533401339, 0.5873849343311598, 0.574...   \n",
       "3   [0.5356126162099226, 0.547607645779339, 0.5450...   \n",
       "4   [0.2362334710154732, 0.24731134429825197, 0.21...   \n",
       "5   [0.626841718309944, 0.6331439071655912, 0.6186...   \n",
       "6   [0.541176689652765, 0.5757029592889293, 0.5476...   \n",
       "7   [0.35526519344495944, 0.25817998562123023, 0.4...   \n",
       "8   [0.4071163952291371, 0.4472318974503796, 0.429...   \n",
       "9   [0.5207855133362838, 0.5269266765340594, 0.515...   \n",
       "10  [0.47639360043299817, 0.41017483910825636, 0.4...   \n",
       "\n",
       "                                       Test PCC folds  \\\n",
       "0   [0.7711017867505152, 0.7765789773273701, 0.772...   \n",
       "1   [0.6706803452601046, 0.6726502650215294, 0.675...   \n",
       "2   [0.7485183329234384, 0.7674603145351845, 0.761...   \n",
       "3   [0.7400125762979344, 0.7499783654708734, 0.744...   \n",
       "4   [0.5349037620112272, 0.5786370300195084, 0.554...   \n",
       "5   [0.7919731399565366, 0.7958195923948379, 0.786...   \n",
       "6   [0.7457623904968043, 0.76390163757286, 0.75113...   \n",
       "7   [0.6227760468179098, 0.5794189308309932, 0.655...   \n",
       "8   [0.6555706316991783, 0.6812849280004103, 0.673...   \n",
       "9   [0.7252035911074748, 0.7287885485529068, 0.720...   \n",
       "10  [0.7136912994169193, 0.6821090879716332, 0.718...   \n",
       "\n",
       "                                       Test SCC folds  \n",
       "0   [0.7487237042680333, 0.7533817333028223, 0.749...  \n",
       "1   [0.6218421858454376, 0.6378608036165951, 0.640...  \n",
       "2   [0.7164362723306894, 0.7328499773266577, 0.724...  \n",
       "3   [0.7103144015198812, 0.7215225542774073, 0.710...  \n",
       "4   [0.5867663371393864, 0.5344030821729185, 0.521...  \n",
       "5   [0.7622964527933916, 0.7656273736139149, 0.758...  \n",
       "6   [0.7038885470430697, 0.7184600868405062, 0.719...  \n",
       "7   [0.6795196496635527, 0.6736425538393991, 0.679...  \n",
       "8   [0.6260751805702771, 0.651736728972367, 0.6411...  \n",
       "9   [0.7081107084563254, 0.7120511832099063, 0.705...  \n",
       "10  [0.7223750185510817, 0.7116683920585688, 0.729...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d7e755-569f-4480-99f4-a4e5e121fcf2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.626841718309944"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,prediction_df.iloc[5]['Test prediction folds'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd08cfbe-a4cc-4fa7-9bc5-c943833786bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6331439071655912"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,prediction_df.iloc[5]['Test prediction folds'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f2cf568-2892-4de5-8c7a-bfd8fa92c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.618685622548827"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,prediction_df.iloc[5]['Test prediction folds'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "355c5de0-f6d8-4789-9a08-7888890e395e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6301400020155099"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,prediction_df.iloc[5]['Test prediction folds'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b7dc3fe-98dc-462a-8da5-25043dd1c38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6148014793013263"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,prediction_df.iloc[5]['Test prediction folds'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ca8392-0368-41b4-9d4f-21e5217190a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.626841718309944,\n",
       " 0.6331439071655912,\n",
       " 0.618685622548827,\n",
       " 0.6301400020155099,\n",
       " 0.6148014793013263]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.iloc[5]['Test R2 folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "531ba6c3-cbad-4fbc-920b-8d3c7905b4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6247225458682397"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prediction_df.iloc[5]['Test R2 folds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65fd0988-7cb9-46fa-aa1f-aafa6f8bab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-6.596901 , -6.454024 , -7.3800654, ..., -6.996824 , -7.1583815,\n",
       "        -4.9488564], dtype=float32),\n",
       " array([-6.8292785, -6.6557565, -7.0362616, ..., -6.8795815, -7.23661  ,\n",
       "        -4.9434943], dtype=float32),\n",
       " array([-6.6868086, -6.5923004, -7.6477904, ..., -6.9417286, -7.797114 ,\n",
       "        -5.1967216], dtype=float32),\n",
       " array([-6.907063 , -6.7027225, -6.9664016, ..., -6.921767 , -6.841078 ,\n",
       "        -5.1967645], dtype=float32),\n",
       " array([-6.5203056, -6.6624136, -7.4954653, ..., -6.1670094, -7.6066008,\n",
       "        -5.045636 ], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.iloc[5]['Test prediction folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31fd1c7c-b8e1-4e9a-9262-f46684c3d1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.708071 , -6.613443 , -7.3051972, ..., -6.7813826, -7.327956 ,\n",
       "       -5.0662947], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prediction_df.iloc[5]['Test prediction folds'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0eccf920-de4c-4c33-9a0f-6ba6c0097f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480607939538405"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,np.mean(prediction_df.iloc[5]['Test prediction folds'], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4869981a-6fc2-4588-8748-0fe65050fcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480607939538405"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,prediction_df.iloc[5]['Test Predictions Mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd5fea-c8f4-4021-94aa-a952d29f183c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225fc81-b739-4e54-ad96-c83fb83be8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d31d5601-2e9e-494b-bb65-af68ad84f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6f64c94-6ef3-451e-9314-f25c37dfc4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 262)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 262)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.743515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1350\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1387\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6041158401656442\n",
      "0.5245745104269488\n",
      "0.5957014291688538\n",
      "0.549335220979188\n",
      "0.2602755400335861\n",
      "0.6480607939538405\n",
      "0.5911926927173082\n",
      "0.41110888755155295\n",
      "0.4741669710813472\n",
      "0.527933577985747\n",
      "0.5153453716980363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>0.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3923</td>\n",
       "      <td>0.4434</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.6279</td>\n",
       "      <td>0.3009</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>0.6909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.7380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.4041</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.4014</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.5493</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.5561</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.4681</td>\n",
       "      <td>0.5487</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.8053</td>\n",
       "      <td>0.7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>0.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.6244</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.6831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.3328</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.6645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.3921</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.2987</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.7095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4174</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.6716</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.3067</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.5153</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2456                0.3656   \n",
       "DecisionTreeRegressor                    0.3923                0.4434   \n",
       "RandomForestRegressor                    0.2654                0.3765   \n",
       "GradientBoostingRegressor                0.2882                0.4041   \n",
       "AdaBoostRegressor                        0.4798                0.5561   \n",
       "XGBRegressor                             0.2257                0.3464   \n",
       "ExtraTreesRegressor                      0.2768                0.3816   \n",
       "LinearRegression                         0.3899                0.4426   \n",
       "KNeighborsRegressor                      0.3464                0.4335   \n",
       "SVR                                      0.3020                0.3921   \n",
       "MLPRegressor                             0.3750                0.4174   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4955               0.6057   \n",
       "DecisionTreeRegressor                     0.6264               0.3701   \n",
       "RandomForestRegressor                     0.5152               0.5739   \n",
       "GradientBoostingRegressor                 0.5368               0.5373   \n",
       "AdaBoostRegressor                         0.6927               0.2297   \n",
       "XGBRegressor                              0.4750               0.6377   \n",
       "ExtraTreesRegressor                       0.5261               0.5556   \n",
       "LinearRegression                          0.6244               0.3739   \n",
       "KNeighborsRegressor                       0.5885               0.4438   \n",
       "SVR                                       0.5496               0.5150   \n",
       "MLPRegressor                              0.6124               0.3979   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7796                0.7363   \n",
       "DecisionTreeRegressor                    0.6697                0.6279   \n",
       "RandomForestRegressor                    0.7588                0.7128   \n",
       "GradientBoostingRegressor                0.7403                0.6942   \n",
       "AdaBoostRegressor                        0.5549                0.4856   \n",
       "XGBRegressor                             0.7987                0.7547   \n",
       "ExtraTreesRegressor                      0.7514                0.7076   \n",
       "LinearRegression                         0.6337                0.6568   \n",
       "KNeighborsRegressor                      0.6772                0.6366   \n",
       "SVR                                      0.7215                0.6982   \n",
       "MLPRegressor                             0.6716                0.6850   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2505   0.3642    0.5005  0.6041   \n",
       "DecisionTreeRegressor       0.3009   0.3918    0.5485  0.5246   \n",
       "RandomForestRegressor       0.2559   0.3624    0.5058  0.5957   \n",
       "GradientBoostingRegressor   0.2852   0.4014    0.5340  0.5493   \n",
       "AdaBoostRegressor           0.4681   0.5487    0.6842  0.2603   \n",
       "XGBRegressor                0.2227   0.3395    0.4719  0.6481   \n",
       "ExtraTreesRegressor         0.2587   0.3666    0.5086  0.5912   \n",
       "LinearRegression            0.3727   0.4380    0.6105  0.4111   \n",
       "KNeighborsRegressor         0.3328   0.4204    0.5769  0.4742   \n",
       "SVR                         0.2987   0.3896    0.5466  0.5279   \n",
       "MLPRegressor                0.3067   0.3942    0.5538  0.5153   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7787                    0.7532  \n",
       "DecisionTreeRegressor                       0.7384                    0.6909  \n",
       "RandomForestRegressor                       0.7725                    0.7380  \n",
       "GradientBoostingRegressor                   0.7505                    0.7188  \n",
       "AdaBoostRegressor                           0.5825                    0.5489  \n",
       "XGBRegressor                                0.8053                    0.7721  \n",
       "ExtraTreesRegressor                         0.7722                    0.7293  \n",
       "LinearRegression                            0.6514                    0.6831  \n",
       "KNeighborsRegressor                         0.6945                    0.6645  \n",
       "SVR                                         0.7299                    0.7095  \n",
       "MLPRegressor                                0.7302                    0.7352  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_train = clean_feature_names(X_train)\n",
    "X_train, const_col = remove_constant_columns(X_train)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_test = clean_feature_names(X_test)\n",
    "X_test = X_test.drop(const_col,axis=1)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9884f4c-d3e5-4fc7-a503-8934427ff7a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.658856691033044, -6.949840742667949, -5.77...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.053776975089306, -6.472870625624551, -7.0...</td>\n",
       "      <td>[-6.991698615663445, -6.411408445763892, -6.89...</td>\n",
       "      <td>[0.14585691905540257, 0.10495600928578822, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-8.0, -7.0, -5.15, -4.85, -5.85, -5.09, -5.09...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -8.0, -7.0, -7.0, -6.24, -5.15, -6.85,...</td>\n",
       "      <td>[-7.0, -7.048, -6.731999999999999, -7.0, -6.05...</td>\n",
       "      <td>[0.0, 0.5596570378365665, 0.5359999999999999, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.646585714285715, -6.779699999999996, -6.07...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.904399999999999, -6.696482461390001, -6.7...</td>\n",
       "      <td>[-6.856584666666667, -6.708258492278, -6.61847...</td>\n",
       "      <td>[0.05192408182893273, 0.09590561162345379, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.42764231529753, -6.65592018174737, -5.5782...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.7004713117236046, -6.320734974959236, -6....</td>\n",
       "      <td>[-6.621170816630338, -6.267014705290754, -6.74...</td>\n",
       "      <td>[0.12209059489006517, 0.10126695056081805, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.798135090265214, -5.798135090265214, -5.79...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.76579539559827, -5.76579539559827, -5.765...</td>\n",
       "      <td>[-5.763516193627824, -5.763099762649212, -5.77...</td>\n",
       "      <td>[0.013481632314794649, 0.012934910665411936, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.742195, -6.990505, -5.996362, -5.2777576, ...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.596901, -6.454024, -7.3800654, -6.5661736...</td>\n",
       "      <td>[-6.708071, -6.613443, -7.3051972, -6.545186, ...</td>\n",
       "      <td>[0.14307745, 0.08720191, 0.26316768, 0.1302703...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.8077000000000005, -6.925599999999999, -5.7...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.965500000000002, -6.693000000000001, -6.8...</td>\n",
       "      <td>[-6.963620000000001, -6.729140000000001, -6.78...</td>\n",
       "      <td>[0.00640004687482879, 0.054015057160018067, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.847762903472198, -6.978361273968966, -5.18...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.096561243440529, -5.438960291853395, -5.6...</td>\n",
       "      <td>[-7.162350714307841, -5.444344040572174, -5.56...</td>\n",
       "      <td>[0.0582278485483556, 0.10941785363993842, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-4.76, -7.0, -5.853333333333333, -4.926666666...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.533333333333332, -6.04, -5.38333333...</td>\n",
       "      <td>[-6.9093333333333335, -5.18, -6.23199999999999...</td>\n",
       "      <td>[0.04533333333333331, 0.32550132274863536, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.2767587783303975, -6.9897419865102215, -4....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.046643613936923, -5.114429729215835, -5.7...</td>\n",
       "      <td>[-7.0170324713951615, -5.139884039360652, -5.5...</td>\n",
       "      <td>[0.025014925909915168, 0.028926368389684987, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.9689641569803005, -7.509578742986041, -5.4...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-8.04075961779099, -6.707909064484587, -7.52...</td>\n",
       "      <td>[-7.95503555488837, -6.607626681466693, -7.269...</td>\n",
       "      <td>[0.14483896732725646, 0.1662590256059486, 0.13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.658856691033044, -6.949840742667949, -5.77...   \n",
       "1   [-8.0, -7.0, -5.15, -4.85, -5.85, -5.09, -5.09...   \n",
       "2   [-6.646585714285715, -6.779699999999996, -6.07...   \n",
       "3   [-6.42764231529753, -6.65592018174737, -5.5782...   \n",
       "4   [-5.798135090265214, -5.798135090265214, -5.79...   \n",
       "5   [-6.742195, -6.990505, -5.996362, -5.2777576, ...   \n",
       "6   [-6.8077000000000005, -6.925599999999999, -5.7...   \n",
       "7   [-5.847762903472198, -6.978361273968966, -5.18...   \n",
       "8   [-4.76, -7.0, -5.853333333333333, -4.926666666...   \n",
       "9   [-5.2767587783303975, -6.9897419865102215, -4....   \n",
       "10  [-6.9689641569803005, -7.509578742986041, -5.4...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.053776975089306, -6.472870625624551, -7.0...   \n",
       "1   [[-7.0, -8.0, -7.0, -7.0, -6.24, -5.15, -6.85,...   \n",
       "2   [[-6.904399999999999, -6.696482461390001, -6.7...   \n",
       "3   [[-6.7004713117236046, -6.320734974959236, -6....   \n",
       "4   [[-5.76579539559827, -5.76579539559827, -5.765...   \n",
       "5   [[-6.596901, -6.454024, -7.3800654, -6.5661736...   \n",
       "6   [[-6.965500000000002, -6.693000000000001, -6.8...   \n",
       "7   [[-7.096561243440529, -5.438960291853395, -5.6...   \n",
       "8   [[-7.0, -4.533333333333332, -6.04, -5.38333333...   \n",
       "9   [[-7.046643613936923, -5.114429729215835, -5.7...   \n",
       "10  [[-8.04075961779099, -6.707909064484587, -7.52...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.991698615663445, -6.411408445763892, -6.89...   \n",
       "1   [-7.0, -7.048, -6.731999999999999, -7.0, -6.05...   \n",
       "2   [-6.856584666666667, -6.708258492278, -6.61847...   \n",
       "3   [-6.621170816630338, -6.267014705290754, -6.74...   \n",
       "4   [-5.763516193627824, -5.763099762649212, -5.77...   \n",
       "5   [-6.708071, -6.613443, -7.3051972, -6.545186, ...   \n",
       "6   [-6.963620000000001, -6.729140000000001, -6.78...   \n",
       "7   [-7.162350714307841, -5.444344040572174, -5.56...   \n",
       "8   [-6.9093333333333335, -5.18, -6.23199999999999...   \n",
       "9   [-7.0170324713951615, -5.139884039360652, -5.5...   \n",
       "10  [-7.95503555488837, -6.607626681466693, -7.269...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.14585691905540257, 0.10495600928578822, 0.1...  \n",
       "1   [0.0, 0.5596570378365665, 0.5359999999999999, ...  \n",
       "2   [0.05192408182893273, 0.09590561162345379, 0.1...  \n",
       "3   [0.12209059489006517, 0.10126695056081805, 0.1...  \n",
       "4   [0.013481632314794649, 0.012934910665411936, 0...  \n",
       "5   [0.14307745, 0.08720191, 0.26316768, 0.1302703...  \n",
       "6   [0.00640004687482879, 0.054015057160018067, 0....  \n",
       "7   [0.0582278485483556, 0.10941785363993842, 0.04...  \n",
       "8   [0.04533333333333331, 0.32550132274863536, 0.2...  \n",
       "9   [0.025014925909915168, 0.028926368389684987, 0...  \n",
       "10  [0.14483896732725646, 0.1662590256059486, 0.13...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f77ddc6d-0d5e-4bf7-bc51-b0d3ba1a14b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.708071 , -6.613443 , -7.3051972, ..., -6.7813826, -7.327956 ,\n",
       "       -5.0662947], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prediction_df.iloc[5]['Test prediction folds'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bafc944d-7a30-4865-a3fe-0d87da8b2eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480607939538405"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,np.mean(prediction_df.iloc[5]['Test prediction folds'], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8139b7bb-5f68-4d93-a81e-a034e954a802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480607939538405"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,prediction_df.iloc[5]['Test Predictions Mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "916f6164-b336-408d-aae8-d40d2c0ba603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Permeability</th>\n",
       "      <th>A</th>\n",
       "      <th>dA</th>\n",
       "      <th>meA</th>\n",
       "      <th>Me_dA</th>\n",
       "      <th>Ala(tBu)</th>\n",
       "      <th>Ala(indol-2-yl)</th>\n",
       "      <th>dAla(indol-2-yl)</th>\n",
       "      <th>...</th>\n",
       "      <th>Degree_O</th>\n",
       "      <th>Single</th>\n",
       "      <th>Double</th>\n",
       "      <th>Triple</th>\n",
       "      <th>Aromatic</th>\n",
       "      <th>Conjugated</th>\n",
       "      <th>No-bond</th>\n",
       "      <th>Overall_Formal_Charge</th>\n",
       "      <th>Is_Aromatic</th>\n",
       "      <th>Is_In_Ring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>908</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>923</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](C)N(C)C(=O)[C@H](...</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](Cc2ccccc2)N(C)C(=...</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>587</td>\n",
       "      <td>CC(C)C[C@@H]1NC(=O)[C@H](Cc2c[nH]cn2)NC(=O)[C@...</td>\n",
       "      <td>-6.74</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>921</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...</td>\n",
       "      <td>-5.54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>2481</td>\n",
       "      <td>CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2ccccc...</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>2485</td>\n",
       "      <td>CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@@H](Cc2cccc...</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>5604</td>\n",
       "      <td>CC(C)CN1CC(=O)N[C@@H](Cc2ccccc2)C(=O)NCCCCC(=O...</td>\n",
       "      <td>-6.38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>2513</td>\n",
       "      <td>C[C@H]1NCCCCCCNC(=O)[C@H](Cc2ccc(O)cc2)NC(=O)[...</td>\n",
       "      <td>-7.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>2468</td>\n",
       "      <td>CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1392 rows Ã— 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                             SMILES  Permeability  \\\n",
       "0      908  CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...         -7.00   \n",
       "1      923  CC[C@H](C)[C@@H]1NC(=O)[C@H](C)N(C)C(=O)[C@H](...         -7.00   \n",
       "2      897  CC[C@H](C)[C@@H]1NC(=O)[C@H](Cc2ccccc2)N(C)C(=...         -7.00   \n",
       "3      587  CC(C)C[C@@H]1NC(=O)[C@H](Cc2c[nH]cn2)NC(=O)[C@...         -6.74   \n",
       "4      921  CC[C@H](C)[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[...         -5.54   \n",
       "...    ...                                                ...           ...   \n",
       "1387  2481  CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2ccccc...         -4.50   \n",
       "1388  2485  CC(C)C[C@H]1NC(=O)[C@H](C)NC(=O)[C@@H](Cc2cccc...         -4.80   \n",
       "1389  5604  CC(C)CN1CC(=O)N[C@@H](Cc2ccccc2)C(=O)NCCCCC(=O...         -6.38   \n",
       "1390  2513  C[C@H]1NCCCCCCNC(=O)[C@H](Cc2ccc(O)cc2)NC(=O)[...         -7.80   \n",
       "1391  2468  CC(C)C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@H](Cc2cccc...         -4.90   \n",
       "\n",
       "             A   dA       meA     Me_dA  Ala(tBu)  Ala(indol-2-yl)  \\\n",
       "0     0.000000  0.0  0.133333  0.000000       0.0              0.0   \n",
       "1     0.000000  0.0  0.133333  0.066667       0.0              0.0   \n",
       "2     0.000000  0.0  0.133333  0.000000       0.0              0.0   \n",
       "3     0.071429  0.0  0.000000  0.000000       0.0              0.0   \n",
       "4     0.000000  0.0  0.133333  0.066667       0.0              0.0   \n",
       "...        ...  ...       ...       ...       ...              ...   \n",
       "1387  0.333333  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1388  0.333333  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1389  0.250000  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1390  0.000000  0.0  0.000000  0.000000       0.0              0.0   \n",
       "1391  0.333333  0.0  0.000000  0.000000       0.0              0.0   \n",
       "\n",
       "      dAla(indol-2-yl)  ...  Degree_O  Single  Double  Triple  Aromatic  \\\n",
       "0                  0.0  ...         1      97      15       0        18   \n",
       "1                  0.0  ...         2      99      15       0        12   \n",
       "2                  0.0  ...         1      93      15       0        18   \n",
       "3                  0.0  ...         1      85      14       0        29   \n",
       "4                  0.0  ...         1      95      15       0        12   \n",
       "...                ...  ...       ...     ...     ...     ...       ...   \n",
       "1387               0.0  ...         1      23       3       0         6   \n",
       "1388               0.0  ...         1      23       3       0         6   \n",
       "1389               0.0  ...         1      22       4       0         6   \n",
       "1390               0.0  ...         1      24       3       0         6   \n",
       "1391               0.0  ...         1      20       3       0         6   \n",
       "\n",
       "      Conjugated  No-bond  Overall_Formal_Charge  Is_Aromatic  Is_In_Ring  \n",
       "0              0        0                    166            1           1  \n",
       "1              0        0                    157            1           1  \n",
       "2              0        0                    159            1           1  \n",
       "3              0        0                    157            1           1  \n",
       "4              0        0                    156            1           1  \n",
       "...          ...      ...                    ...          ...         ...  \n",
       "1387           0        0                     35            1           1  \n",
       "1388           0        0                     35            1           1  \n",
       "1389           0        0                     40            1           1  \n",
       "1390           0        0                     39            1           1  \n",
       "1391           0        0                     35            1           1  \n",
       "\n",
       "[1392 rows x 411 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atomic + monomeric_composition based features\n",
    "df1 = pd.read_csv('Monomer_features/Train_mon_comp.csv')\n",
    "df2 = pd.read_csv('Atomic_features/Train_all_atomic_desc.csv')\n",
    "df_train = pd.merge(df1, df2, on=['ID', 'SMILES', 'Permeability'], how='inner')\n",
    "df_train\n",
    "df1 = pd.read_csv('Monomer_features/Test_mon_comp.csv')\n",
    "df2 = pd.read_csv('Atomic_features/Test_all_atomic_desc.csv')\n",
    "df_test = pd.merge(df1, df2, on=['ID', 'SMILES', 'Permeability'], how='inner')\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459fbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e32dc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def train_and_test_predict_with_tuning(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "   \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        best_params = None\n",
    "\n",
    "        # hyperparameter tuning \n",
    "        if model_name in param_grids and param_grids[model_name]:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model, \n",
    "                param_grid=param_grids[model_name], \n",
    "                cv=kf,\n",
    "                scoring='neg_mean_squared_error', \n",
    "                n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            print(model_name)\n",
    "            print(\": best params\",best_params)\n",
    "        else:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            best_params = {}\n",
    "            print(model_name, ':Used Default params')\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)  \n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "            'Best Parameters': best_params\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57b00d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "        'ExtraTreesRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None,1,5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'LGBMRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'num_leaves': [31, 50, 100]\n",
    "        },\n",
    "        'DecisionTreeRegressor': {\n",
    "            'max_depth': [None, 10, 20, 50, 100],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'RandomForestRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None, 1, 5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'GradientBoostingRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7, 10]\n",
    "        },\n",
    "        'AdaBoostRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.1, 1.0]\n",
    "        },\n",
    "        'SVR': {\n",
    "            'C': [0.001, 0.1, 1, 10],\n",
    "            'epsilon': [0.1, 0.2, 0.5],\n",
    "            'gamma': [0.001, 0.1, 1, 10]\n",
    "        },\n",
    "        'KNeighborsRegressor': {\n",
    "            'n_neighbors': [3, 5, 10],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        },\n",
    "        'MLPRegressor': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'learning_rate': ['constant', 'adaptive'],\n",
    "            'max_iter': [100,200, 400]\n",
    "}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91af1be8-6a18-4934-907a-df56c2e22497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 262)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 262)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "LGBMRegressor : Default params {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': 'regression', 'random_state': 101, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1465\n",
      "[LightGBM] [Info] Number of data points in the train set: 5568, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -5.742906\n",
      "LGBMRegressor\n",
      ": best params {'learning_rate': 0.05, 'n_estimators': 400, 'num_leaves': 31}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1350\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1387\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6438556107544664\n",
      "DecisionTreeRegressor : Default params {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 101, 'splitter': 'best'}\n",
      "DecisionTreeRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 10}\n",
      "0.5817321708393555\n",
      "RandomForestRegressor : Default params {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n",
      "RandomForestRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "0.6127554184138053\n",
      "GradientBoostingRegressor : Default params {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 101, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "GradientBoostingRegressor\n",
      ": best params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}\n",
      "0.6442898417994838\n",
      "AdaBoostRegressor : Default params {'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 101}\n",
      "AdaBoostRegressor\n",
      ": best params {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.3147044202143394\n",
      "XGBRegressor : Default params {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 101, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "XGBRegressor :Used Default params\n",
      "0.6480607939538405\n",
      "ExtraTreesRegressor : Default params {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n",
      "ExtraTreesRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.6298133081942938\n",
      "LinearRegression : Default params {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
      "LinearRegression :Used Default params\n",
      "0.41110888755155295\n",
      "KNeighborsRegressor : Default params {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "KNeighborsRegressor\n",
      ": best params {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.4738748950409122\n",
      "SVR : Default params {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "SVR\n",
      ": best params {'C': 10, 'epsilon': 0.2, 'gamma': 0.001}\n",
      "0.5434136056552017\n",
      "MLPRegressor : Default params {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 101, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "MLPRegressor\n",
      ": best params {'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 200}\n",
      "0.522075264603334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.4747</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.7748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.4137</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2468</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.6038</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.2451</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.6128</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>0.7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.4748</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.4337</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.3147</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.8053</td>\n",
       "      <td>0.7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.7911</td>\n",
       "      <td>0.7463</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.3531</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.7940</td>\n",
       "      <td>0.7565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4313</td>\n",
       "      <td>0.4481</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.3075</td>\n",
       "      <td>0.6039</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.6831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3311</td>\n",
       "      <td>0.4255</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.6499</td>\n",
       "      <td>0.3329</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.4739</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.6629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.2854</td>\n",
       "      <td>0.3848</td>\n",
       "      <td>0.5342</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.7371</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.3851</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.7127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>1.3931</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>1.1803</td>\n",
       "      <td>-1.2369</td>\n",
       "      <td>0.4042</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.7265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2232                0.3432   \n",
       "DecisionTreeRegressor                    0.3330                0.4137   \n",
       "RandomForestRegressor                    0.2468                0.3646   \n",
       "GradientBoostingRegressor                0.2255                0.3469   \n",
       "AdaBoostRegressor                        0.4333                0.5004   \n",
       "XGBRegressor                             0.2257                0.3464   \n",
       "ExtraTreesRegressor                      0.2336                0.3557   \n",
       "LinearRegression                         0.4313                0.4481   \n",
       "KNeighborsRegressor                      0.3311                0.4255   \n",
       "SVR                                      0.2854                0.3848   \n",
       "MLPRegressor                             1.3931                0.5018   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4724               0.6416   \n",
       "DecisionTreeRegressor                     0.5771               0.4653   \n",
       "RandomForestRegressor                     0.4968               0.6038   \n",
       "GradientBoostingRegressor                 0.4748               0.6380   \n",
       "AdaBoostRegressor                         0.6583               0.3043   \n",
       "XGBRegressor                              0.4750               0.6377   \n",
       "ExtraTreesRegressor                       0.4833               0.6249   \n",
       "LinearRegression                          0.6567               0.3075   \n",
       "KNeighborsRegressor                       0.5754               0.4683   \n",
       "SVR                                       0.5342               0.5417   \n",
       "MLPRegressor                              1.1803              -1.2369   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8010                0.7597   \n",
       "DecisionTreeRegressor                    0.7030                0.6588   \n",
       "RandomForestRegressor                    0.7771                0.7338   \n",
       "GradientBoostingRegressor                0.7988                0.7580   \n",
       "AdaBoostRegressor                        0.5528                0.4393   \n",
       "XGBRegressor                             0.7987                0.7547   \n",
       "ExtraTreesRegressor                      0.7911                0.7463   \n",
       "LinearRegression                         0.6039                0.6568   \n",
       "KNeighborsRegressor                      0.6869                0.6499   \n",
       "SVR                                      0.7371                0.7031   \n",
       "MLPRegressor                             0.4042                0.7036   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2254   0.3406    0.4747  0.6439   \n",
       "DecisionTreeRegressor       0.2647   0.3705    0.5145  0.5817   \n",
       "RandomForestRegressor       0.2451   0.3582    0.4950  0.6128   \n",
       "GradientBoostingRegressor   0.2251   0.3430    0.4745  0.6443   \n",
       "AdaBoostRegressor           0.4337   0.5046    0.6585  0.3147   \n",
       "XGBRegressor                0.2227   0.3395    0.4719  0.6481   \n",
       "ExtraTreesRegressor         0.2343   0.3531    0.4840  0.6298   \n",
       "LinearRegression            0.3727   0.4380    0.6105  0.4111   \n",
       "KNeighborsRegressor         0.3329   0.4205    0.5770  0.4739   \n",
       "SVR                         0.2889   0.3851    0.5375  0.5434   \n",
       "MLPRegressor                0.3024   0.3924    0.5499  0.5221   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8025                    0.7748  \n",
       "DecisionTreeRegressor                       0.7645                    0.7218  \n",
       "RandomForestRegressor                       0.7829                    0.7518  \n",
       "GradientBoostingRegressor                   0.8029                    0.7693  \n",
       "AdaBoostRegressor                           0.5624                    0.5842  \n",
       "XGBRegressor                                0.8053                    0.7721  \n",
       "ExtraTreesRegressor                         0.7940                    0.7565  \n",
       "LinearRegression                            0.6514                    0.6831  \n",
       "KNeighborsRegressor                         0.6905                    0.6629  \n",
       "SVR                                         0.7380                    0.7127  \n",
       "MLPRegressor                                0.7304                    0.7265  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_train = clean_feature_names(X_train)\n",
    "X_train, const_col = remove_constant_columns(X_train)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_test = clean_feature_names(X_test)\n",
    "X_test = X_test.drop(const_col,axis=1)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(objective='reg:squarederror',random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "\n",
    "result_df, prediction_df = train_and_test_predict_with_tuning(models, param_grids, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "957bfb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.817866261888496, -7.137931914876334, -5.84...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.162042678459291, -6.632231262119943, -7.21...</td>\n",
       "      <td>[0.16348363939659113, 0.18819895725168487, 0.1...</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 400, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.5, -6.91, -6.145714285714286, -4.935, -6.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.991000000000001, -7.0503333333333345, -6.7...</td>\n",
       "      <td>[0.002905932629026918, 0.3295795301086926, 0.2...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.6731120624630424, -6.77669287048659, -6.03...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.840542426420598, -6.661657907110151, -6.61...</td>\n",
       "      <td>[0.03511300318449715, 0.10450245657358637, 0.1...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.933956402733556, -7.417083917270874, -5.84...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.023203952777467, -6.689588218207044, -7.34...</td>\n",
       "      <td>[0.11651566568524581, 0.14537379738421946, 0.2...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.7208223238949945, -5.770533661161989, -5.7...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-5.728374099340698, -5.727809713594145, -5.75...</td>\n",
       "      <td>[0.0064370506631836535, 0.006295110751366476, ...</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.742195, -6.990505, -5.996362, -5.2777576, ...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.708071, -6.613443, -7.3051972, -6.545186, ...</td>\n",
       "      <td>[0.14307745, 0.08720191, 0.26316768, 0.1302703...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.718260356645456, -6.840379939028495, -5.73...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.9292457917709855, -6.678886810525709, -6.5...</td>\n",
       "      <td>[0.02737726458589667, 0.1086417150641323, 0.08...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.847762903472198, -6.978361273968966, -5.18...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.162350714307841, -5.444344040572174, -5.56...</td>\n",
       "      <td>[0.0582278485483556, 0.10941785363993842, 0.04...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-4.682, -6.7780000000000005, -5.322, -4.93999...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.8995999999999995, -5.0496, -6.4824, -5.428...</td>\n",
       "      <td>[0.06479999999999962, 0.1920141661440635, 0.09...</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.377493057196427, -6.97376881883095, -4.854...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.125511785364933, -5.144874651063345, -5.52...</td>\n",
       "      <td>[0.05562096334793436, 0.0595969220811658, 0.06...</td>\n",
       "      <td>{'C': 10, 'epsilon': 0.2, 'gamma': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.907802675588462, -7.138415321870504, -5.33...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.621434484777443, -6.725378763520207, -7.41...</td>\n",
       "      <td>[0.10598608677177651, 0.12560232468916388, 0.1...</td>\n",
       "      <td>{'hidden_layer_sizes': (50, 50), 'learning_rat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.817866261888496, -7.137931914876334, -5.84...   \n",
       "1   [-7.5, -6.91, -6.145714285714286, -4.935, -6.1...   \n",
       "2   [-6.6731120624630424, -6.77669287048659, -6.03...   \n",
       "3   [-6.933956402733556, -7.417083917270874, -5.84...   \n",
       "4   [-5.7208223238949945, -5.770533661161989, -5.7...   \n",
       "5   [-6.742195, -6.990505, -5.996362, -5.2777576, ...   \n",
       "6   [-6.718260356645456, -6.840379939028495, -5.73...   \n",
       "7   [-5.847762903472198, -6.978361273968966, -5.18...   \n",
       "8   [-4.682, -6.7780000000000005, -5.322, -4.93999...   \n",
       "9   [-5.377493057196427, -6.97376881883095, -4.854...   \n",
       "10  [-6.907802675588462, -7.138415321870504, -5.33...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.162042678459291, -6.632231262119943, -7.21...   \n",
       "1   [-6.991000000000001, -7.0503333333333345, -6.7...   \n",
       "2   [-6.840542426420598, -6.661657907110151, -6.61...   \n",
       "3   [-7.023203952777467, -6.689588218207044, -7.34...   \n",
       "4   [-5.728374099340698, -5.727809713594145, -5.75...   \n",
       "5   [-6.708071, -6.613443, -7.3051972, -6.545186, ...   \n",
       "6   [-6.9292457917709855, -6.678886810525709, -6.5...   \n",
       "7   [-7.162350714307841, -5.444344040572174, -5.56...   \n",
       "8   [-6.8995999999999995, -5.0496, -6.4824, -5.428...   \n",
       "9   [-7.125511785364933, -5.144874651063345, -5.52...   \n",
       "10  [-7.621434484777443, -6.725378763520207, -7.41...   \n",
       "\n",
       "                                 Test Predictions Std  \\\n",
       "0   [0.16348363939659113, 0.18819895725168487, 0.1...   \n",
       "1   [0.002905932629026918, 0.3295795301086926, 0.2...   \n",
       "2   [0.03511300318449715, 0.10450245657358637, 0.1...   \n",
       "3   [0.11651566568524581, 0.14537379738421946, 0.2...   \n",
       "4   [0.0064370506631836535, 0.006295110751366476, ...   \n",
       "5   [0.14307745, 0.08720191, 0.26316768, 0.1302703...   \n",
       "6   [0.02737726458589667, 0.1086417150641323, 0.08...   \n",
       "7   [0.0582278485483556, 0.10941785363993842, 0.04...   \n",
       "8   [0.06479999999999962, 0.1920141661440635, 0.09...   \n",
       "9   [0.05562096334793436, 0.0595969220811658, 0.06...   \n",
       "10  [0.10598608677177651, 0.12560232468916388, 0.1...   \n",
       "\n",
       "                                      Best Parameters  \n",
       "0   {'learning_rate': 0.05, 'n_estimators': 400, '...  \n",
       "1          {'max_depth': 20, 'min_samples_split': 10}  \n",
       "2   {'max_depth': 20, 'min_samples_split': 5, 'n_e...  \n",
       "3   {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...  \n",
       "4        {'learning_rate': 0.01, 'n_estimators': 100}  \n",
       "5                                                  {}  \n",
       "6   {'max_depth': 20, 'min_samples_split': 10, 'n_...  \n",
       "7                                                  {}  \n",
       "8            {'n_neighbors': 5, 'weights': 'uniform'}  \n",
       "9           {'C': 10, 'epsilon': 0.2, 'gamma': 0.001}  \n",
       "10  {'hidden_layer_sizes': (50, 50), 'learning_rat...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0df980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('atomic_results/Results_all_atomic_desc_and_mono_comp_with_HPT.csv')\n",
    "prediction_df.to_csv('atomic_results/Prediction_data_all_atomic_desc_and_mono_comp_with_HPT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f443d073-e46d-4515-a0bc-2dd5c02d7abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c434ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 23)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 23)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "LGBMRegressor : Default params {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': 'regression', 'random_state': 101, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 826\n",
      "[LightGBM] [Info] Number of data points in the train set: 5568, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.742906\n",
      "LGBMRegressor\n",
      ": best params {'learning_rate': 0.1, 'n_estimators': 400, 'num_leaves': 31}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 783\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5530273262971743\n",
      "DecisionTreeRegressor : Default params {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 101, 'splitter': 'best'}\n",
      "DecisionTreeRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 10}\n",
      "0.5179712358791413\n",
      "RandomForestRegressor : Default params {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n",
      "RandomForestRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "0.5486008004049479\n",
      "GradientBoostingRegressor : Default params {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 101, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "GradientBoostingRegressor\n",
      ": best params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "0.5515437887847663\n",
      "AdaBoostRegressor : Default params {'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 101}\n",
      "AdaBoostRegressor\n",
      ": best params {'learning_rate': 0.01, 'n_estimators': 200}\n",
      "0.2324223253789628\n",
      "XGBRegressor : Default params {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 101, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "XGBRegressor :Used Default params\n",
      "0.5494187212067152\n",
      "ExtraTreesRegressor : Default params {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n",
      "ExtraTreesRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 400}\n",
      "0.550243417177547\n",
      "LinearRegression : Default params {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
      "LinearRegression :Used Default params\n",
      "0.22656464503079965\n",
      "KNeighborsRegressor : Default params {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "KNeighborsRegressor\n",
      ": best params {'n_neighbors': 10, 'weights': 'distance'}\n",
      "0.48399356558070006\n",
      "SVR : Default params {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "SVR\n",
      ": best params {'C': 10, 'epsilon': 0.2, 'gamma': 1}\n",
      "0.5244155156424537\n",
      "MLPRegressor : Default params {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 101, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor\n",
      ": best params {'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44949495890294255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>0.7446</td>\n",
       "      <td>0.7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3442</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.5867</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2821</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.5312</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.7411</td>\n",
       "      <td>0.7221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.3851</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.5545</td>\n",
       "      <td>0.7446</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>0.5327</td>\n",
       "      <td>0.5515</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.5305</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2836</td>\n",
       "      <td>0.3826</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.5494</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2702</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>0.5662</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.3877</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.7238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.4710</td>\n",
       "      <td>0.4781</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.2266</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.4913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3112</td>\n",
       "      <td>0.4016</td>\n",
       "      <td>0.5579</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.6767</td>\n",
       "      <td>0.3265</td>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.6883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3031</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.5244</td>\n",
       "      <td>0.7266</td>\n",
       "      <td>0.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>0.5836</td>\n",
       "      <td>0.4531</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.4311</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.6610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2812                0.3844   \n",
       "DecisionTreeRegressor                    0.3442                0.4087   \n",
       "RandomForestRegressor                    0.2821                0.3850   \n",
       "GradientBoostingRegressor                0.2775                0.3851   \n",
       "AdaBoostRegressor                        0.4726                0.5305   \n",
       "XGBRegressor                             0.2836                0.3826   \n",
       "ExtraTreesRegressor                      0.2702                0.3792   \n",
       "LinearRegression                         0.4848                0.5261   \n",
       "KNeighborsRegressor                      0.3112                0.4016   \n",
       "SVR                                      0.3031                0.3917   \n",
       "MLPRegressor                             0.3406                0.4260   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.5302               0.5486   \n",
       "DecisionTreeRegressor                     0.5867               0.4474   \n",
       "RandomForestRegressor                     0.5312               0.5470   \n",
       "GradientBoostingRegressor                 0.5268               0.5545   \n",
       "AdaBoostRegressor                         0.6875               0.2411   \n",
       "XGBRegressor                              0.5325               0.5447   \n",
       "ExtraTreesRegressor                       0.5198               0.5662   \n",
       "LinearRegression                          0.6963               0.2216   \n",
       "KNeighborsRegressor                       0.5579               0.5003   \n",
       "SVR                                       0.5506               0.5133   \n",
       "MLPRegressor                              0.5836               0.4531   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7417                0.7018   \n",
       "DecisionTreeRegressor                    0.6846                0.6681   \n",
       "RandomForestRegressor                    0.7397                0.7051   \n",
       "GradientBoostingRegressor                0.7446                0.7025   \n",
       "AdaBoostRegressor                        0.4954                0.4349   \n",
       "XGBRegressor                             0.7396                0.7046   \n",
       "ExtraTreesRegressor                      0.7525                0.7164   \n",
       "LinearRegression                         0.4710                0.4781   \n",
       "KNeighborsRegressor                      0.7128                0.6767   \n",
       "SVR                                      0.7185                0.6920   \n",
       "MLPRegressor                             0.6750                0.6584   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2829   0.3850    0.5318  0.5530   \n",
       "DecisionTreeRegressor       0.3050   0.3995    0.5523  0.5180   \n",
       "RandomForestRegressor       0.2857   0.3866    0.5345  0.5486   \n",
       "GradientBoostingRegressor   0.2838   0.3874    0.5327  0.5515   \n",
       "AdaBoostRegressor           0.4857   0.5395    0.6970  0.2324   \n",
       "XGBRegressor                0.2851   0.3833    0.5340  0.5494   \n",
       "ExtraTreesRegressor         0.2846   0.3877    0.5335  0.5502   \n",
       "LinearRegression            0.4895   0.5267    0.6996  0.2266   \n",
       "KNeighborsRegressor         0.3265   0.4051    0.5714  0.4840   \n",
       "SVR                         0.3010   0.3948    0.5486  0.5244   \n",
       "MLPRegressor                0.3484   0.4311    0.5902  0.4495   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7446                    0.7240  \n",
       "DecisionTreeRegressor                       0.7228                    0.7073  \n",
       "RandomForestRegressor                       0.7411                    0.7221  \n",
       "GradientBoostingRegressor                   0.7429                    0.7227  \n",
       "AdaBoostRegressor                           0.4855                    0.5137  \n",
       "XGBRegressor                                0.7426                    0.7237  \n",
       "ExtraTreesRegressor                         0.7420                    0.7238  \n",
       "LinearRegression                            0.4767                    0.4913  \n",
       "KNeighborsRegressor                         0.7018                    0.6883  \n",
       "SVR                                         0.7266                    0.7135  \n",
       "MLPRegressor                                0.6708                    0.6610  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atomic descriptors\n",
    "df_train = pd.read_csv('Atomic_features/Train_all_atomic_desc.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('Atomic_features/Test_all_atomic_desc.csv')\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models_degree = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict_with_tuning(models, param_grids, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09a8643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('atomic_results/Results_all_atomic_desc_with_HPT.csv')\n",
    "prediction_df.to_csv('atomic_results/Prediction_data_all_atomic_desc_with_HPT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c68a134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.265791613932967, -7.3557504535674845, -6.5...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.106041947223659, -6.809055754094911, -6.69...</td>\n",
       "      <td>[0.07542260238518948, 0.09346301987587483, 0.1...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 400, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-5.995000000000001, -6.99, -6.279999999999999...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.996, -6.526222222222222, -6.484, -6.721000...</td>\n",
       "      <td>[0.004898979485566252, 0.42420519726037764, 0....</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.56264261904762, -6.952133482142858, -6.378...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.945640992243869, -6.634083020202018, -6.74...</td>\n",
       "      <td>[0.02913598232735361, 0.10005692730556243, 0.0...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-5.972378010025126, -7.00341994239865, -6.240...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.0447297099781085, -6.719699428321012, -6.5...</td>\n",
       "      <td>[0.08610692692626387, 0.16856260581893254, 0.2...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.330750747106483, -5.653247422680414, -5.23...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-5.679952412756883, -5.2983773340508105, -5.5...</td>\n",
       "      <td>[0.030452640313360643, 0.018661615664841272, 0...</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.369783, -7.138793, -6.2215147, -5.1384716,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.8326797, -6.6089973, -6.7012877, -6.077459...</td>\n",
       "      <td>[0.1327724, 0.19248006, 0.099578865, 0.3078653...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.663466646825389, -6.923384146825396, -6.10...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.969946396825394, -6.640271549603168, -6.49...</td>\n",
       "      <td>[0.006007764501206538, 0.22005739700162202, 0....</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.127934954999589, -6.787257203614937, -5.56...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.57357645783934, -3.930882232119134, -4.836...</td>\n",
       "      <td>[0.06058044276649575, 0.039914685448258484, 0....</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.317353170651615, -6.957369374354451, -5.86...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.969276168025876, -6.245583741929467, -5.85...</td>\n",
       "      <td>[0.028033002827688506, 0.4834593258446868, 0.0...</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.249897911401852, -6.848998070187065, -6.35...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-6.4504672745053515, -6.7115146555090375, -6....</td>\n",
       "      <td>[0.05074646033404196, 0.16872994871226235, 0.5...</td>\n",
       "      <td>{'C': 10, 'epsilon': 0.2, 'gamma': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.2640482587553175, -6.955521271886795, -5.5...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[-7.262634863662875, -6.222265211952516, -6.18...</td>\n",
       "      <td>[0.13242689633281107, 0.4135190456541527, 0.13...</td>\n",
       "      <td>{'hidden_layer_sizes': (50, 50), 'learning_rat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.265791613932967, -7.3557504535674845, -6.5...   \n",
       "1   [-5.995000000000001, -6.99, -6.279999999999999...   \n",
       "2   [-6.56264261904762, -6.952133482142858, -6.378...   \n",
       "3   [-5.972378010025126, -7.00341994239865, -6.240...   \n",
       "4   [-5.330750747106483, -5.653247422680414, -5.23...   \n",
       "5   [-6.369783, -7.138793, -6.2215147, -5.1384716,...   \n",
       "6   [-6.663466646825389, -6.923384146825396, -6.10...   \n",
       "7   [-4.127934954999589, -6.787257203614937, -5.56...   \n",
       "8   [-5.317353170651615, -6.957369374354451, -5.86...   \n",
       "9   [-6.249897911401852, -6.848998070187065, -6.35...   \n",
       "10  [-6.2640482587553175, -6.955521271886795, -5.5...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.106041947223659, -6.809055754094911, -6.69...   \n",
       "1   [-6.996, -6.526222222222222, -6.484, -6.721000...   \n",
       "2   [-6.945640992243869, -6.634083020202018, -6.74...   \n",
       "3   [-7.0447297099781085, -6.719699428321012, -6.5...   \n",
       "4   [-5.679952412756883, -5.2983773340508105, -5.5...   \n",
       "5   [-6.8326797, -6.6089973, -6.7012877, -6.077459...   \n",
       "6   [-6.969946396825394, -6.640271549603168, -6.49...   \n",
       "7   [-6.57357645783934, -3.930882232119134, -4.836...   \n",
       "8   [-6.969276168025876, -6.245583741929467, -5.85...   \n",
       "9   [-6.4504672745053515, -6.7115146555090375, -6....   \n",
       "10  [-7.262634863662875, -6.222265211952516, -6.18...   \n",
       "\n",
       "                                 Test Predictions Std  \\\n",
       "0   [0.07542260238518948, 0.09346301987587483, 0.1...   \n",
       "1   [0.004898979485566252, 0.42420519726037764, 0....   \n",
       "2   [0.02913598232735361, 0.10005692730556243, 0.0...   \n",
       "3   [0.08610692692626387, 0.16856260581893254, 0.2...   \n",
       "4   [0.030452640313360643, 0.018661615664841272, 0...   \n",
       "5   [0.1327724, 0.19248006, 0.099578865, 0.3078653...   \n",
       "6   [0.006007764501206538, 0.22005739700162202, 0....   \n",
       "7   [0.06058044276649575, 0.039914685448258484, 0....   \n",
       "8   [0.028033002827688506, 0.4834593258446868, 0.0...   \n",
       "9   [0.05074646033404196, 0.16872994871226235, 0.5...   \n",
       "10  [0.13242689633281107, 0.4135190456541527, 0.13...   \n",
       "\n",
       "                                      Best Parameters  \n",
       "0   {'learning_rate': 0.1, 'n_estimators': 400, 'n...  \n",
       "1          {'max_depth': 20, 'min_samples_split': 10}  \n",
       "2   {'max_depth': 20, 'min_samples_split': 5, 'n_e...  \n",
       "3   {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...  \n",
       "4        {'learning_rate': 0.01, 'n_estimators': 200}  \n",
       "5                                                  {}  \n",
       "6   {'max_depth': 20, 'min_samples_split': 10, 'n_...  \n",
       "7                                                  {}  \n",
       "8          {'n_neighbors': 10, 'weights': 'distance'}  \n",
       "9               {'C': 10, 'epsilon': 0.2, 'gamma': 1}  \n",
       "10  {'hidden_layer_sizes': (50, 50), 'learning_rat...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2f992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80bcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d11fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
