{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d681a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "# from lightgbm.lgb import LGBMRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3d8b17-7adf-404c-8cb8-34c3a7092b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdbdf6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 20188)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 20188)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17668\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 4093\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17848\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 4154\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18081\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 4210\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17869\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 4155\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17889\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 4163\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6565012319413122\n",
      "0.6014340223377769\n",
      "0.6423816187318974\n",
      "0.5923695145609673\n",
      "0.33628714962565287\n",
      "0.6601801013166775\n",
      "0.6382874159943122\n",
      "0.3151820129606966\n",
      "0.5348108635388771\n",
      "0.5583814207644493\n",
      "0.5022483178727019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.6523</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.7776</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.3848</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.5099</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.7756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>0.4702</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.7753</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>0.4757</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.5049</td>\n",
       "      <td>0.5908</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.3728</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.7571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4559</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.5941</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.3363</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.6197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.3374</td>\n",
       "      <td>0.4614</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.7752</td>\n",
       "      <td>0.2289</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>0.7926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.6070</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.4419</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.6290</td>\n",
       "      <td>0.6754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.4093</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.2944</td>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.5348</td>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.7346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.2802</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.5501</td>\n",
       "      <td>0.7446</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>0.7694</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5384</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.7176</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2166                0.3418   \n",
       "DecisionTreeRegressor                    0.3053                0.3848   \n",
       "RandomForestRegressor                    0.2210                0.3445   \n",
       "GradientBoostingRegressor                0.2549                0.3738   \n",
       "AdaBoostRegressor                        0.4559                0.5432   \n",
       "XGBRegressor                             0.2129                0.3374   \n",
       "ExtraTreesRegressor                      0.2199                0.3434   \n",
       "LinearRegression                         0.6070                0.4885   \n",
       "KNeighborsRegressor                      0.3169                0.4093   \n",
       "SVR                                      0.2802                0.3776   \n",
       "MLPRegressor                             0.5920                0.5536   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4654               0.6523   \n",
       "DecisionTreeRegressor                     0.5525               0.5099   \n",
       "RandomForestRegressor                     0.4702               0.6451   \n",
       "GradientBoostingRegressor                 0.5049               0.5908   \n",
       "AdaBoostRegressor                         0.6752               0.2681   \n",
       "XGBRegressor                              0.4614               0.6582   \n",
       "ExtraTreesRegressor                       0.4689               0.6469   \n",
       "LinearRegression                          0.7791               0.0254   \n",
       "KNeighborsRegressor                       0.5629               0.4912   \n",
       "SVR                                       0.5293               0.5501   \n",
       "MLPRegressor                              0.7694               0.0495   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8087                0.7776   \n",
       "DecisionTreeRegressor                    0.7351                0.7215   \n",
       "RandomForestRegressor                    0.8032                0.7753   \n",
       "GradientBoostingRegressor                0.7747                0.7402   \n",
       "AdaBoostRegressor                        0.5941                0.5686   \n",
       "XGBRegressor                             0.8115                0.7813   \n",
       "ExtraTreesRegressor                      0.8047                0.7752   \n",
       "LinearRegression                         0.5634                0.6441   \n",
       "KNeighborsRegressor                      0.7131                0.6872   \n",
       "SVR                                      0.7446                0.7279   \n",
       "MLPRegressor                             0.5468                0.5384   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2174   0.3404    0.4662  0.6565   \n",
       "DecisionTreeRegressor       0.2522   0.3489    0.5022  0.6014   \n",
       "RandomForestRegressor       0.2263   0.3424    0.4757  0.6424   \n",
       "GradientBoostingRegressor   0.2580   0.3728    0.5079  0.5924   \n",
       "AdaBoostRegressor           0.4200   0.5214    0.6481  0.3363   \n",
       "XGBRegressor                0.2150   0.3330    0.4637  0.6602   \n",
       "ExtraTreesRegressor         0.2289   0.3379    0.4784  0.6383   \n",
       "LinearRegression            0.4334   0.4419    0.6583  0.3152   \n",
       "KNeighborsRegressor         0.2944   0.3864    0.5426  0.5348   \n",
       "SVR                         0.2795   0.3725    0.5286  0.5584   \n",
       "MLPRegressor                0.3150   0.3932    0.5612  0.5022   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8124                    0.8000  \n",
       "DecisionTreeRegressor                       0.7778                    0.7756  \n",
       "RandomForestRegressor                       0.8019                    0.7905  \n",
       "GradientBoostingRegressor                   0.7764                    0.7571  \n",
       "AdaBoostRegressor                           0.6457                    0.6197  \n",
       "XGBRegressor                                0.8127                    0.7967  \n",
       "ExtraTreesRegressor                         0.7993                    0.7926  \n",
       "LinearRegression                            0.6290                    0.6754  \n",
       "KNeighborsRegressor                         0.7372                    0.7346  \n",
       "SVR                                         0.7501                    0.7500  \n",
       "MLPRegressor                                0.7176                    0.7193  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/All_fingerprints_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/All_fingerprints_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb30ca5-4f93-48aa-bf5b-c7f772e02a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.723532325095607, -6.757128308474924, -6.11...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.025019269942802, -6.132890118021946, -6.8...</td>\n",
       "      <td>[-7.02602636807954, -6.259715784974982, -6.862...</td>\n",
       "      <td>[0.030522988836645018, 0.11372157756993759, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-6.96, -7.0, -6.244999999999999, -5.05, -5.15...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.24, -7.0, -7.0, -5.82, -7.0, -6.85,...</td>\n",
       "      <td>[-7.0, -6.17, -6.736, -6.784000000000001, -5.9...</td>\n",
       "      <td>[0.0, 0.1400000000000002, 0.5280000000000001, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.645700000000001, -6.8139, -6.1496416666666...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8477, -6.355033333333336, -6.853650000000...</td>\n",
       "      <td>[-6.885160000000001, -6.363293333333336, -6.78...</td>\n",
       "      <td>[0.06119926796947837, 0.07587743450240447, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.834707610411482, -6.780458603379971, -5.94...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.014800255424059, -6.354714096498743, -6.5...</td>\n",
       "      <td>[-7.081008707549399, -6.094698571665337, -6.62...</td>\n",
       "      <td>[0.1409827103098058, 0.2119767294302283, 0.150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.703940298507472, -5.967714653831089, -5.65...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.801543859649126, -5.703940298507472, -5.8...</td>\n",
       "      <td>[-5.8356372499046785, -5.673631414828848, -5.8...</td>\n",
       "      <td>[0.04212357213313098, 0.09297574324594704, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-7.035523, -6.8859987, -6.4079747, -5.390928,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.879666, -6.3244767, -6.7222857, -6.899798...</td>\n",
       "      <td>[-6.944411, -6.289349, -6.9273634, -6.7366242,...</td>\n",
       "      <td>[0.11411563, 0.11128185, 0.25650784, 0.3348497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.8808000000000025, -6.8926000000000025, -6....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9411000000000005, -6.614100000000003, -6....</td>\n",
       "      <td>[-6.93304, -6.536130000000002, -6.853319999999...</td>\n",
       "      <td>[0.03675685514295252, 0.1769068331071474, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.184666015309894, -3.9, -5.462597510763377,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-9.469087112897139, -6.217165338319693, -10....</td>\n",
       "      <td>[-7.529922643134244, -4.5520748361292265, -9.4...</td>\n",
       "      <td>[1.617090346638004, 0.8839149990555397, 0.6897...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.633333333333333, -6.113333333333333, -5.62...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.293333333333334, -5.786666666666666...</td>\n",
       "      <td>[-6.9093333333333335, -5.173333333333334, -6.0...</td>\n",
       "      <td>[0.04533333333333331, 0.29806039656418654, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.068647309352145, -6.479146229893767, -4.98...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.6575983988830085, -5.650275727322878, -5....</td>\n",
       "      <td>[-6.787339039858615, -5.647180199957969, -5.99...</td>\n",
       "      <td>[0.07004657008641471, 0.1387517159060542, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-8.416355700511831, -6.870640121477944, -6.19...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.832583338399469, -6.981299970221912, -7.4...</td>\n",
       "      <td>[-7.748776714299893, -6.507413722578052, -6.99...</td>\n",
       "      <td>[0.2047119717624179, 0.40041785007023534, 0.59...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.723532325095607, -6.757128308474924, -6.11...   \n",
       "1   [-6.96, -7.0, -6.244999999999999, -5.05, -5.15...   \n",
       "2   [-6.645700000000001, -6.8139, -6.1496416666666...   \n",
       "3   [-6.834707610411482, -6.780458603379971, -5.94...   \n",
       "4   [-5.703940298507472, -5.967714653831089, -5.65...   \n",
       "5   [-7.035523, -6.8859987, -6.4079747, -5.390928,...   \n",
       "6   [-6.8808000000000025, -6.8926000000000025, -6....   \n",
       "7   [-4.184666015309894, -3.9, -5.462597510763377,...   \n",
       "8   [-5.633333333333333, -6.113333333333333, -5.62...   \n",
       "9   [-6.068647309352145, -6.479146229893767, -4.98...   \n",
       "10  [-8.416355700511831, -6.870640121477944, -6.19...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.025019269942802, -6.132890118021946, -6.8...   \n",
       "1   [[-7.0, -6.24, -7.0, -7.0, -5.82, -7.0, -6.85,...   \n",
       "2   [[-6.8477, -6.355033333333336, -6.853650000000...   \n",
       "3   [[-7.014800255424059, -6.354714096498743, -6.5...   \n",
       "4   [[-5.801543859649126, -5.703940298507472, -5.8...   \n",
       "5   [[-6.879666, -6.3244767, -6.7222857, -6.899798...   \n",
       "6   [[-6.9411000000000005, -6.614100000000003, -6....   \n",
       "7   [[-9.469087112897139, -6.217165338319693, -10....   \n",
       "8   [[-7.0, -5.293333333333334, -5.786666666666666...   \n",
       "9   [[-6.6575983988830085, -5.650275727322878, -5....   \n",
       "10  [[-7.832583338399469, -6.981299970221912, -7.4...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.02602636807954, -6.259715784974982, -6.862...   \n",
       "1   [-7.0, -6.17, -6.736, -6.784000000000001, -5.9...   \n",
       "2   [-6.885160000000001, -6.363293333333336, -6.78...   \n",
       "3   [-7.081008707549399, -6.094698571665337, -6.62...   \n",
       "4   [-5.8356372499046785, -5.673631414828848, -5.8...   \n",
       "5   [-6.944411, -6.289349, -6.9273634, -6.7366242,...   \n",
       "6   [-6.93304, -6.536130000000002, -6.853319999999...   \n",
       "7   [-7.529922643134244, -4.5520748361292265, -9.4...   \n",
       "8   [-6.9093333333333335, -5.173333333333334, -6.0...   \n",
       "9   [-6.787339039858615, -5.647180199957969, -5.99...   \n",
       "10  [-7.748776714299893, -6.507413722578052, -6.99...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.030522988836645018, 0.11372157756993759, 0....  \n",
       "1   [0.0, 0.1400000000000002, 0.5280000000000001, ...  \n",
       "2   [0.06119926796947837, 0.07587743450240447, 0.1...  \n",
       "3   [0.1409827103098058, 0.2119767294302283, 0.150...  \n",
       "4   [0.04212357213313098, 0.09297574324594704, 0.1...  \n",
       "5   [0.11411563, 0.11128185, 0.25650784, 0.3348497...  \n",
       "6   [0.03675685514295252, 0.1769068331071474, 0.11...  \n",
       "7   [1.617090346638004, 0.8839149990555397, 0.6897...  \n",
       "8   [0.04533333333333331, 0.29806039656418654, 0.3...  \n",
       "9   [0.07004657008641471, 0.1387517159060542, 0.10...  \n",
       "10  [0.2047119717624179, 0.40041785007023534, 0.59...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614aa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_All_fingerprints_fp.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_All_fingerprints_fp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ce19d1-8bcd-4677-a280-33549642f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of constant columns\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    \n",
    "    df_cleaned = df.drop(columns=constant_columns)\n",
    "    \n",
    "    return df_cleaned, constant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff3296ad-60f6-4e96-bf6d-f1adf9bcc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low variance column removal\n",
    "def remove_low_variance_columns(df, threshold=0.005):\n",
    "    df = df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "    variances = df.var()\n",
    "    \n",
    "    low_variance_columns = variances[variances < threshold].index.tolist()\n",
    "    \n",
    "    df_cleaned = df.drop(columns=low_variance_columns)\n",
    "    \n",
    "    return df_cleaned, low_variance_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88a4b8b0-5ee1-464d-83ce-ded3a185a2ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 6820)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 6820)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 86.239655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17668\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 4093\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 92.098963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17848\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 4154\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 98.372225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18081\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 4210\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 93.228368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17869\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 4155\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 91.406778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17889\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 4163\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6565012319413122\n",
      "0.6048690647029007\n",
      "0.6421215939183402\n",
      "0.5920687012153145\n",
      "0.32522325119271456\n",
      "0.6601801013166775\n",
      "0.6378808948263233\n",
      "0.315182012960584\n",
      "0.5348108635388771\n",
      "0.5583900445590063\n",
      "0.5227448392957262\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.6523</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.7776</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3058</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.7336</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.7769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>0.4702</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.7752</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.7903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2546</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.5081</td>\n",
       "      <td>0.5921</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4593</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.6085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.3374</td>\n",
       "      <td>0.4614</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.4687</td>\n",
       "      <td>0.6473</td>\n",
       "      <td>0.8049</td>\n",
       "      <td>0.7753</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.3384</td>\n",
       "      <td>0.4787</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.7913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.6070</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.4419</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.6290</td>\n",
       "      <td>0.6754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.4093</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.2944</td>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.5348</td>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.7346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.2802</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.5501</td>\n",
       "      <td>0.7446</td>\n",
       "      <td>0.7280</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.5149</td>\n",
       "      <td>0.5173</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.6181</td>\n",
       "      <td>0.6068</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2166                0.3418   \n",
       "DecisionTreeRegressor                    0.3058                0.3857   \n",
       "RandomForestRegressor                    0.2211                0.3447   \n",
       "GradientBoostingRegressor                0.2546                0.3737   \n",
       "AdaBoostRegressor                        0.4593                0.5484   \n",
       "XGBRegressor                             0.2129                0.3374   \n",
       "ExtraTreesRegressor                      0.2196                0.3431   \n",
       "LinearRegression                         0.6070                0.4885   \n",
       "KNeighborsRegressor                      0.3169                0.4093   \n",
       "SVR                                      0.2802                0.3776   \n",
       "MLPRegressor                             0.5149                0.5173   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4654               0.6523   \n",
       "DecisionTreeRegressor                     0.5530               0.5090   \n",
       "RandomForestRegressor                     0.4702               0.6450   \n",
       "GradientBoostingRegressor                 0.5046               0.5912   \n",
       "AdaBoostRegressor                         0.6777               0.2625   \n",
       "XGBRegressor                              0.4614               0.6582   \n",
       "ExtraTreesRegressor                       0.4687               0.6473   \n",
       "LinearRegression                          0.7791               0.0254   \n",
       "KNeighborsRegressor                       0.5629               0.4912   \n",
       "SVR                                       0.5293               0.5501   \n",
       "MLPRegressor                              0.7175               0.1733   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8087                0.7776   \n",
       "DecisionTreeRegressor                    0.7336                0.7183   \n",
       "RandomForestRegressor                    0.8032                0.7752   \n",
       "GradientBoostingRegressor                0.7750                0.7402   \n",
       "AdaBoostRegressor                        0.5952                0.5562   \n",
       "XGBRegressor                             0.8115                0.7813   \n",
       "ExtraTreesRegressor                      0.8049                0.7753   \n",
       "LinearRegression                         0.5634                0.6441   \n",
       "KNeighborsRegressor                      0.7131                0.6872   \n",
       "SVR                                      0.7446                0.7280   \n",
       "MLPRegressor                             0.6181                0.6068   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2174   0.3404    0.4662  0.6565   \n",
       "DecisionTreeRegressor       0.2501   0.3481    0.5001  0.6049   \n",
       "RandomForestRegressor       0.2265   0.3423    0.4759  0.6421   \n",
       "GradientBoostingRegressor   0.2582   0.3727    0.5081  0.5921   \n",
       "AdaBoostRegressor           0.4270   0.5293    0.6535  0.3252   \n",
       "XGBRegressor                0.2150   0.3330    0.4637  0.6602   \n",
       "ExtraTreesRegressor         0.2292   0.3384    0.4787  0.6379   \n",
       "LinearRegression            0.4334   0.4419    0.6583  0.3152   \n",
       "KNeighborsRegressor         0.2944   0.3864    0.5426  0.5348   \n",
       "SVR                         0.2795   0.3725    0.5286  0.5584   \n",
       "MLPRegressor                0.3020   0.3904    0.5496  0.5227   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8124                    0.8000  \n",
       "DecisionTreeRegressor                       0.7800                    0.7769  \n",
       "RandomForestRegressor                       0.8017                    0.7903  \n",
       "GradientBoostingRegressor                   0.7762                    0.7575  \n",
       "AdaBoostRegressor                           0.6410                    0.6085  \n",
       "XGBRegressor                                0.8127                    0.7967  \n",
       "ExtraTreesRegressor                         0.7991                    0.7913  \n",
       "LinearRegression                            0.6290                    0.6754  \n",
       "KNeighborsRegressor                         0.7372                    0.7346  \n",
       "SVR                                         0.7501                    0.7500  \n",
       "MLPRegressor                                0.7440                    0.7420  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All fingerprints constant removal\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/All_fingerprints_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_train, const_col = remove_constant_columns(X_train)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/All_fingerprints_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ff3a826-581a-4562-9624-af2103f93907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.723532325095607, -6.757128308474924, -6.11...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.025019269942802, -6.132890118021946, -6.8...</td>\n",
       "      <td>[-7.02602636807954, -6.259715784974982, -6.862...</td>\n",
       "      <td>[0.030522988836645018, 0.11372157756993759, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.0, -6.96, -6.244999999999999, -5.05, -5.15...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.24, -7.0, -5.89, -6.24, -7.0, -6.85...</td>\n",
       "      <td>[-6.992, -6.328, -6.728, -6.26, -5.934, -6.886...</td>\n",
       "      <td>[0.016000000000000014, 0.35812846856959024, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.669400000000003, -6.829200000000002, -6.20...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.839600000000001, -6.315100000000004, -6.8...</td>\n",
       "      <td>[-6.859360000000001, -6.341393333333335, -6.77...</td>\n",
       "      <td>[0.05744759699064883, 0.06991268014061906, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.834707610411482, -6.780458603379971, -5.94...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.014800255424059, -6.354714096498744, -6.5...</td>\n",
       "      <td>[-7.095369312619124, -6.0946985716653375, -6.6...</td>\n",
       "      <td>[0.1653608132690947, 0.21197672943022805, 0.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-6.09392156862745, -5.928226797350341, -5.740...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.992080200501258, -6.09392156862745, -5.93...</td>\n",
       "      <td>[-5.8763893250350465, -5.749057965919758, -5.8...</td>\n",
       "      <td>[0.06688163443042254, 0.19197065180204043, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-7.035523, -6.8859987, -6.4079747, -5.390928,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.879666, -6.3244767, -6.7222857, -6.899798...</td>\n",
       "      <td>[-6.944411, -6.289349, -6.9273634, -6.7366242,...</td>\n",
       "      <td>[0.11411563, 0.11128185, 0.25650784, 0.3348497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.874499999999999, -6.838150000000001, -6.09...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.981599999999999, -6.595000000000002, -6.9...</td>\n",
       "      <td>[-6.945400000000001, -6.542400000000002, -6.91...</td>\n",
       "      <td>[0.04719563539142124, 0.12452805306436107, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.184666015311104, -3.9, -5.462597510763344,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-9.469087112895288, -6.217165338320154, -10....</td>\n",
       "      <td>[-7.52992264313348, -4.552074836128948, -9.441...</td>\n",
       "      <td>[1.6170903466378592, 0.8839149990556785, 0.689...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.633333333333333, -6.113333333333333, -5.62...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.293333333333334, -5.786666666666666...</td>\n",
       "      <td>[-6.9093333333333335, -5.173333333333334, -6.0...</td>\n",
       "      <td>[0.04533333333333331, 0.29806039656418654, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.068738157365336, -6.479147174669174, -4.98...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.657570972953301, -5.650214246750718, -5.9...</td>\n",
       "      <td>[-6.787374427454907, -5.647125611832698, -5.99...</td>\n",
       "      <td>[0.07009217631071249, 0.13875249812984033, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-7.732109351906967, -3.9, -5.395550502632941,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-4.60055814834766, -6.2701587472233875, -6.6...</td>\n",
       "      <td>[-7.064698493344269, -6.274149287623851, -6.36...</td>\n",
       "      <td>[1.2634762068481489, 0.8083857492435733, 0.641...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.723532325095607, -6.757128308474924, -6.11...   \n",
       "1   [-7.0, -6.96, -6.244999999999999, -5.05, -5.15...   \n",
       "2   [-6.669400000000003, -6.829200000000002, -6.20...   \n",
       "3   [-6.834707610411482, -6.780458603379971, -5.94...   \n",
       "4   [-6.09392156862745, -5.928226797350341, -5.740...   \n",
       "5   [-7.035523, -6.8859987, -6.4079747, -5.390928,...   \n",
       "6   [-6.874499999999999, -6.838150000000001, -6.09...   \n",
       "7   [-4.184666015311104, -3.9, -5.462597510763344,...   \n",
       "8   [-5.633333333333333, -6.113333333333333, -5.62...   \n",
       "9   [-6.068738157365336, -6.479147174669174, -4.98...   \n",
       "10  [-7.732109351906967, -3.9, -5.395550502632941,...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.025019269942802, -6.132890118021946, -6.8...   \n",
       "1   [[-7.0, -6.24, -7.0, -5.89, -6.24, -7.0, -6.85...   \n",
       "2   [[-6.839600000000001, -6.315100000000004, -6.8...   \n",
       "3   [[-7.014800255424059, -6.354714096498744, -6.5...   \n",
       "4   [[-5.992080200501258, -6.09392156862745, -5.93...   \n",
       "5   [[-6.879666, -6.3244767, -6.7222857, -6.899798...   \n",
       "6   [[-6.981599999999999, -6.595000000000002, -6.9...   \n",
       "7   [[-9.469087112895288, -6.217165338320154, -10....   \n",
       "8   [[-7.0, -5.293333333333334, -5.786666666666666...   \n",
       "9   [[-6.657570972953301, -5.650214246750718, -5.9...   \n",
       "10  [[-4.60055814834766, -6.2701587472233875, -6.6...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.02602636807954, -6.259715784974982, -6.862...   \n",
       "1   [-6.992, -6.328, -6.728, -6.26, -5.934, -6.886...   \n",
       "2   [-6.859360000000001, -6.341393333333335, -6.77...   \n",
       "3   [-7.095369312619124, -6.0946985716653375, -6.6...   \n",
       "4   [-5.8763893250350465, -5.749057965919758, -5.8...   \n",
       "5   [-6.944411, -6.289349, -6.9273634, -6.7366242,...   \n",
       "6   [-6.945400000000001, -6.542400000000002, -6.91...   \n",
       "7   [-7.52992264313348, -4.552074836128948, -9.441...   \n",
       "8   [-6.9093333333333335, -5.173333333333334, -6.0...   \n",
       "9   [-6.787374427454907, -5.647125611832698, -5.99...   \n",
       "10  [-7.064698493344269, -6.274149287623851, -6.36...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.030522988836645018, 0.11372157756993759, 0....  \n",
       "1   [0.016000000000000014, 0.35812846856959024, 0....  \n",
       "2   [0.05744759699064883, 0.06991268014061906, 0.1...  \n",
       "3   [0.1653608132690947, 0.21197672943022805, 0.17...  \n",
       "4   [0.06688163443042254, 0.19197065180204043, 0.1...  \n",
       "5   [0.11411563, 0.11128185, 0.25650784, 0.3348497...  \n",
       "6   [0.04719563539142124, 0.12452805306436107, 0.0...  \n",
       "7   [1.6170903466378592, 0.8839149990556785, 0.689...  \n",
       "8   [0.04533333333333331, 0.29806039656418654, 0.3...  \n",
       "9   [0.07009217631071249, 0.13875249812984033, 0.1...  \n",
       "10  [1.2634762068481489, 0.8083857492435733, 0.641...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d89079fb-fe6a-4120-95b8-548b9848a4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Morgan_fp_1', 'Morgan_fp_2', 'Morgan_fp_5', 'Morgan_fp_7',\n",
       "       'Morgan_fp_11', 'Morgan_fp_12', 'Morgan_fp_13', 'Morgan_fp_14',\n",
       "       'Morgan_fp_18', 'Morgan_fp_19',\n",
       "       ...\n",
       "       'SubFPC295', 'SubFPC296', 'SubFPC297', 'SubFPC298', 'SubFPC299',\n",
       "       'SubFPC300', 'SubFPC301', 'SubFPC302', 'SubFPC303', 'SubFPC307'],\n",
       "      dtype='object', length=6820)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2b230e5-68d7-4b1b-9ea2-082368fa93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_All_const_rem_fingerprints.csv')\n",
    "prediction_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_All_const_rem_fingerprints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e151ec60-d76f-4528-acdc-a684cab42ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 2048)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 2048)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 12.134623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1314\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 12.129180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1332\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 444\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 11.076980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1341\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 10.043386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1338\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 446\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 11.400563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1341\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5847880802498059\n",
      "0.566236053961185\n",
      "0.6056903898607388\n",
      "0.49982034480625415\n",
      "0.27071050473571734\n",
      "0.6068114244281089\n",
      "0.5748772011787885\n",
      "0.4482114552400498\n",
      "0.5068329329407931\n",
      "0.5373985313034693\n",
      "0.542451721739408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.3764</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.5784</td>\n",
       "      <td>0.7616</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.3762</td>\n",
       "      <td>0.5126</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.7669</td>\n",
       "      <td>0.7480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3357</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.2745</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>0.5662</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2484</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.7689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3076</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.5626</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.6994</td>\n",
       "      <td>0.2147</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.6793</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.5623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.6068</td>\n",
       "      <td>0.7793</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.3608</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.6068</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>0.7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.3947</td>\n",
       "      <td>0.5658</td>\n",
       "      <td>0.4859</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.7040</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.5749</td>\n",
       "      <td>0.7616</td>\n",
       "      <td>0.7630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.6213</td>\n",
       "      <td>0.3802</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>0.6906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3391</td>\n",
       "      <td>0.4229</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.4555</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.3951</td>\n",
       "      <td>0.5587</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>0.7233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.5139</td>\n",
       "      <td>0.7198</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.2927</td>\n",
       "      <td>0.3834</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.7295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>0.5982</td>\n",
       "      <td>0.4255</td>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>0.7494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2626                0.3764   \n",
       "DecisionTreeRegressor                    0.3357                0.3992   \n",
       "RandomForestRegressor                    0.2484                0.3649   \n",
       "GradientBoostingRegressor                0.3076                0.4107   \n",
       "AdaBoostRegressor                        0.4891                0.5599   \n",
       "XGBRegressor                             0.2449                0.3626   \n",
       "ExtraTreesRegressor                      0.3202                0.3947   \n",
       "LinearRegression                         0.3860                0.4349   \n",
       "KNeighborsRegressor                      0.3391                0.4229   \n",
       "SVR                                      0.3028                0.3941   \n",
       "MLPRegressor                             0.3578                0.4143   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.5124               0.5784   \n",
       "DecisionTreeRegressor                     0.5794               0.4611   \n",
       "RandomForestRegressor                     0.4984               0.6012   \n",
       "GradientBoostingRegressor                 0.5547               0.5060   \n",
       "AdaBoostRegressor                         0.6994               0.2147   \n",
       "XGBRegressor                              0.4949               0.6068   \n",
       "ExtraTreesRegressor                       0.5658               0.4859   \n",
       "LinearRegression                          0.6213               0.3802   \n",
       "KNeighborsRegressor                       0.5823               0.4555   \n",
       "SVR                                       0.5502               0.5139   \n",
       "MLPRegressor                              0.5982               0.4255   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7616                0.7391   \n",
       "DecisionTreeRegressor                    0.7055                0.6982   \n",
       "RandomForestRegressor                    0.7755                0.7531   \n",
       "GradientBoostingRegressor                0.7167                0.6880   \n",
       "AdaBoostRegressor                        0.5377                0.5077   \n",
       "XGBRegressor                             0.7793                0.7501   \n",
       "ExtraTreesRegressor                      0.7155                0.7040   \n",
       "LinearRegression                         0.6491                0.6659   \n",
       "KNeighborsRegressor                      0.6885                0.6678   \n",
       "SVR                                      0.7198                0.7010   \n",
       "MLPRegressor                             0.6890                0.6962   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2628   0.3762    0.5126  0.5848   \n",
       "DecisionTreeRegressor       0.2745   0.3668    0.5239  0.5662   \n",
       "RandomForestRegressor       0.2495   0.3600    0.4995  0.6057   \n",
       "GradientBoostingRegressor   0.3165   0.4154    0.5626  0.4998   \n",
       "AdaBoostRegressor           0.4615   0.5426    0.6793  0.2707   \n",
       "XGBRegressor                0.2488   0.3608    0.4988  0.6068   \n",
       "ExtraTreesRegressor         0.2690   0.3643    0.5187  0.5749   \n",
       "LinearRegression            0.3492   0.4182    0.5909  0.4482   \n",
       "KNeighborsRegressor         0.3121   0.3951    0.5587  0.5068   \n",
       "SVR                         0.2927   0.3834    0.5411  0.5374   \n",
       "MLPRegressor                0.2895   0.3773    0.5381  0.5425   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7669                    0.7480  \n",
       "DecisionTreeRegressor                       0.7566                    0.7579  \n",
       "RandomForestRegressor                       0.7784                    0.7689  \n",
       "GradientBoostingRegressor                   0.7133                    0.6994  \n",
       "AdaBoostRegressor                           0.5873                    0.5623  \n",
       "XGBRegressor                                0.7791                    0.7700  \n",
       "ExtraTreesRegressor                         0.7616                    0.7630  \n",
       "LinearRegression                            0.6781                    0.6906  \n",
       "KNeighborsRegressor                         0.7195                    0.7233  \n",
       "SVR                                         0.7358                    0.7295  \n",
       "MLPRegressor                                0.7421                    0.7494  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Morgan fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/morgan_fp_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/morgan_fp_test.csv')\n",
    "X_test = df_test.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_morgan_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_morgan_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14e4c284-bf65-4cc6-a04c-08938133385f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.190319007163, -6.718037755521681, -5.03932...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.830677855994803, -6.211924608378423, -6.7...</td>\n",
       "      <td>[-6.901668170436784, -5.9541336042575566, -6.6...</td>\n",
       "      <td>[0.06515699863454225, 0.20047925485507848, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-4.74, -6.96, -6.244999999999999, -4.6, -5.15...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.89, -7.0, -6.1762500000000005, -5.3...</td>\n",
       "      <td>[-6.9319999999999995, -5.809, -7.0, -6.1198076...</td>\n",
       "      <td>[0.13599999999999995, 0.8360047846753033, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-5.830900000000003, -6.801200000000002, -5.72...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.815499999999998, -6.330100000000004, -6.8...</td>\n",
       "      <td>[-6.794, -6.038314333333334, -6.73889999999999...</td>\n",
       "      <td>[0.06246160420610471, 0.20606979308423143, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.030942209162285, -6.71097942841647, -5.050...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.7944894415330035, -5.761297620685506, -6....</td>\n",
       "      <td>[-6.91414210056994, -5.649887917323126, -6.194...</td>\n",
       "      <td>[0.211799414970668, 0.11671699407950403, 0.203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.420085531005007, -5.6748803819546865, -5.6...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.6444754852570505, -5.404039423379018, -5....</td>\n",
       "      <td>[-5.612450773743555, -5.487947238284226, -5.70...</td>\n",
       "      <td>[0.06469839638262588, 0.06108324217503584, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-5.6834197, -6.7127576, -5.787127, -4.926085,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0361915, -6.325289, -7.7694483, -6.632345...</td>\n",
       "      <td>[-7.047, -6.2467294, -7.2835402, -6.8017426, -...</td>\n",
       "      <td>[0.29608455, 0.26674294, 0.39136094, 0.3842641...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-4.9710000000000045, -6.9868000000000015, -6....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.88999999999999, -7.0, -6.1142588827...</td>\n",
       "      <td>[-6.94356, -6.058909999999995, -6.979600000000...</td>\n",
       "      <td>[0.11288000000000019, 0.4816452557640336, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-6.3965947344629575, -5.379095452248684, -5.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-8.396759804506443, -5.724038085901541, -7.1...</td>\n",
       "      <td>[-8.736919145735147, -5.011474211239254, -6.36...</td>\n",
       "      <td>[1.8329213392801977, 0.4174016309455181, 1.712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.633333333333333, -5.650000000000001, -5.64...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.3999999999999995, -5.38, -6.2266666666666...</td>\n",
       "      <td>[-6.789333333333333, -4.868666666666667, -6.20...</td>\n",
       "      <td>[0.1946666666666669, 0.27924978862023225, 0.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.863830515598096, -6.011731763145798, -4.92...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.016751774444159, -5.586055809139273, -5.9...</td>\n",
       "      <td>[-6.0838399422311324, -5.459675200464696, -5.9...</td>\n",
       "      <td>[0.05302493339319797, 0.07383541476259833, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.069259572924671, -4.595036197380988, -5.12...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.095315801279356, -6.127461892770688, -7.3...</td>\n",
       "      <td>[-7.102813970550052, -5.601805782756427, -7.16...</td>\n",
       "      <td>[0.5528924400025598, 0.2996272170810428, 0.696...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.190319007163, -6.718037755521681, -5.03932...   \n",
       "1   [-4.74, -6.96, -6.244999999999999, -4.6, -5.15...   \n",
       "2   [-5.830900000000003, -6.801200000000002, -5.72...   \n",
       "3   [-6.030942209162285, -6.71097942841647, -5.050...   \n",
       "4   [-5.420085531005007, -5.6748803819546865, -5.6...   \n",
       "5   [-5.6834197, -6.7127576, -5.787127, -4.926085,...   \n",
       "6   [-4.9710000000000045, -6.9868000000000015, -6....   \n",
       "7   [-6.3965947344629575, -5.379095452248684, -5.1...   \n",
       "8   [-5.633333333333333, -5.650000000000001, -5.64...   \n",
       "9   [-5.863830515598096, -6.011731763145798, -4.92...   \n",
       "10  [-6.069259572924671, -4.595036197380988, -5.12...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.830677855994803, -6.211924608378423, -6.7...   \n",
       "1   [[-7.0, -5.89, -7.0, -6.1762500000000005, -5.3...   \n",
       "2   [[-6.815499999999998, -6.330100000000004, -6.8...   \n",
       "3   [[-6.7944894415330035, -5.761297620685506, -6....   \n",
       "4   [[-5.6444754852570505, -5.404039423379018, -5....   \n",
       "5   [[-7.0361915, -6.325289, -7.7694483, -6.632345...   \n",
       "6   [[-7.0, -5.88999999999999, -7.0, -6.1142588827...   \n",
       "7   [[-8.396759804506443, -5.724038085901541, -7.1...   \n",
       "8   [[-6.3999999999999995, -5.38, -6.2266666666666...   \n",
       "9   [[-6.016751774444159, -5.586055809139273, -5.9...   \n",
       "10  [[-6.095315801279356, -6.127461892770688, -7.3...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.901668170436784, -5.9541336042575566, -6.6...   \n",
       "1   [-6.9319999999999995, -5.809, -7.0, -6.1198076...   \n",
       "2   [-6.794, -6.038314333333334, -6.73889999999999...   \n",
       "3   [-6.91414210056994, -5.649887917323126, -6.194...   \n",
       "4   [-5.612450773743555, -5.487947238284226, -5.70...   \n",
       "5   [-7.047, -6.2467294, -7.2835402, -6.8017426, -...   \n",
       "6   [-6.94356, -6.058909999999995, -6.979600000000...   \n",
       "7   [-8.736919145735147, -5.011474211239254, -6.36...   \n",
       "8   [-6.789333333333333, -4.868666666666667, -6.20...   \n",
       "9   [-6.0838399422311324, -5.459675200464696, -5.9...   \n",
       "10  [-7.102813970550052, -5.601805782756427, -7.16...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.06515699863454225, 0.20047925485507848, 0.1...  \n",
       "1   [0.13599999999999995, 0.8360047846753033, 0.0,...  \n",
       "2   [0.06246160420610471, 0.20606979308423143, 0.0...  \n",
       "3   [0.211799414970668, 0.11671699407950403, 0.203...  \n",
       "4   [0.06469839638262588, 0.06108324217503584, 0.1...  \n",
       "5   [0.29608455, 0.26674294, 0.39136094, 0.3842641...  \n",
       "6   [0.11288000000000019, 0.4816452557640336, 0.04...  \n",
       "7   [1.8329213392801977, 0.4174016309455181, 1.712...  \n",
       "8   [0.1946666666666669, 0.27924978862023225, 0.24...  \n",
       "9   [0.05302493339319797, 0.07383541476259833, 0.0...  \n",
       "10  [0.5528924400025598, 0.2996272170810428, 0.696...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f4d0db9-bd28-46f6-988a-688ca7903b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morgan_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_Morgan_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_Morgan_fp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6acc57c-b340-4b96-aa22-a8fba12baf5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 2048)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 2048)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 11.512201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2049\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 10.975774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2072\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 453\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 10.048074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2088\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 455\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 12.324391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2078\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 454\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 10.332426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2075\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 455\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6331328980423767\n",
      "0.6015023251935138\n",
      "0.6226070872750971\n",
      "0.5498666761715091\n",
      "0.29727002567135163\n",
      "0.6470102814082778\n",
      "0.6358278899084587\n",
      "0.46508722388941004\n",
      "0.528287017546339\n",
      "0.5484907643296075\n",
      "0.5123686008514903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2349</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.6229</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.4818</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>0.7837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.5158</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.3502</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2296</td>\n",
       "      <td>0.3519</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.7946</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.7893</td>\n",
       "      <td>0.7841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.5283</td>\n",
       "      <td>0.5519</td>\n",
       "      <td>0.7492</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.3911</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4779</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.6913</td>\n",
       "      <td>0.2326</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.4447</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.6669</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.8044</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.3416</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.8046</td>\n",
       "      <td>0.7915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.3471</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>0.6402</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.2305</td>\n",
       "      <td>0.3416</td>\n",
       "      <td>0.4801</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>0.7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.4224</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.3385</td>\n",
       "      <td>0.4161</td>\n",
       "      <td>0.5818</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.7046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.4119</td>\n",
       "      <td>0.5646</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.7084</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>0.5283</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.3856</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.7282</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.3764</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>0.7398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3507</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.7542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2349                0.3560   \n",
       "DecisionTreeRegressor                    0.3016                0.3854   \n",
       "RandomForestRegressor                    0.2296                0.3519   \n",
       "GradientBoostingRegressor                0.2791                0.3916   \n",
       "AdaBoostRegressor                        0.4779                0.5531   \n",
       "XGBRegressor                             0.2199                0.3426   \n",
       "ExtraTreesRegressor                      0.2241                0.3471   \n",
       "LinearRegression                         0.3480                0.4224   \n",
       "KNeighborsRegressor                      0.3187                0.4119   \n",
       "SVR                                      0.2948                0.3856   \n",
       "MLPRegressor                             0.3507                0.4090   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4846               0.6229   \n",
       "DecisionTreeRegressor                     0.5492               0.5158   \n",
       "RandomForestRegressor                     0.4792               0.6313   \n",
       "GradientBoostingRegressor                 0.5283               0.5519   \n",
       "AdaBoostRegressor                         0.6913               0.2326   \n",
       "XGBRegressor                              0.4690               0.6469   \n",
       "ExtraTreesRegressor                       0.4734               0.6402   \n",
       "LinearRegression                          0.5900               0.4412   \n",
       "KNeighborsRegressor                       0.5646               0.4882   \n",
       "SVR                                       0.5429               0.5267   \n",
       "MLPRegressor                              0.5922               0.4370   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7903                0.7605   \n",
       "DecisionTreeRegressor                    0.7375                0.7210   \n",
       "RandomForestRegressor                    0.7946                0.7663   \n",
       "GradientBoostingRegressor                0.7492                0.7135   \n",
       "AdaBoostRegressor                        0.5649                0.5507   \n",
       "XGBRegressor                             0.8044                0.7774   \n",
       "ExtraTreesRegressor                      0.8005                0.7724   \n",
       "LinearRegression                         0.6727                0.6714   \n",
       "KNeighborsRegressor                      0.7084                0.6849   \n",
       "SVR                                      0.7282                0.7135   \n",
       "MLPRegressor                             0.7010                0.7081   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2322   0.3497    0.4818  0.6331   \n",
       "DecisionTreeRegressor       0.2522   0.3502    0.5022  0.6015   \n",
       "RandomForestRegressor       0.2388   0.3478    0.4887  0.6226   \n",
       "GradientBoostingRegressor   0.2849   0.3911    0.5337  0.5499   \n",
       "AdaBoostRegressor           0.4447   0.5331    0.6669  0.2973   \n",
       "XGBRegressor                0.2234   0.3416    0.4726  0.6470   \n",
       "ExtraTreesRegressor         0.2305   0.3416    0.4801  0.6358   \n",
       "LinearRegression            0.3385   0.4161    0.5818  0.4651   \n",
       "KNeighborsRegressor         0.2985   0.3899    0.5464  0.5283   \n",
       "SVR                         0.2857   0.3764    0.5345  0.5485   \n",
       "MLPRegressor                0.3086   0.3789    0.5555  0.5124   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7981                    0.7837  \n",
       "DecisionTreeRegressor                       0.7770                    0.7758  \n",
       "RandomForestRegressor                       0.7893                    0.7841  \n",
       "GradientBoostingRegressor                   0.7500                    0.7272  \n",
       "AdaBoostRegressor                           0.6130                    0.5960  \n",
       "XGBRegressor                                0.8046                    0.7915  \n",
       "ExtraTreesRegressor                         0.7976                    0.7894  \n",
       "LinearRegression                            0.6855                    0.7046  \n",
       "KNeighborsRegressor                         0.7331                    0.7331  \n",
       "SVR                                         0.7425                    0.7398  \n",
       "MLPRegressor                                0.7337                    0.7542  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Morgan count fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/count_morgan_fp_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/count_morgan_fp_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_morgan_count_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_morgan_count_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f99ea7a-e2ea-439b-9653-990258ccad47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.449185163697374, -6.596589019935487, -5.95...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.056119628542196, -6.096394503453853, -6.7...</td>\n",
       "      <td>[-7.017115840615927, -6.052887869020509, -6.73...</td>\n",
       "      <td>[0.08968130039351668, 0.26396027609363937, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-5.36, -5.77, -6.244999999999999, -5.05, -4.2...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.27, -7.0, -7.0, -6.24, -7.0, -6.85,...</td>\n",
       "      <td>[-7.0, -5.952, -6.868, -6.476000000000001, -5....</td>\n",
       "      <td>[0.0, 0.5911142021640152, 0.26400000000000007,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.099700000000002, -6.251600000000001, -6.13...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.705799999999999, -5.8228000000000035, -6....</td>\n",
       "      <td>[-6.813979999999999, -5.816485000000002, -6.76...</td>\n",
       "      <td>[0.07220718523803626, 0.2891633515852259, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.247998976200171, -6.328466421002222, -5.66...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.683679257615391, -5.718991021754435, -6.4...</td>\n",
       "      <td>[-6.923902195759925, -5.7316140316949395, -6.4...</td>\n",
       "      <td>[0.12967163152247468, 0.22189762746993172, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.628926396875004, -5.628926396875004, -5.64...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.670701618893616, -5.608007149539823, -5.6...</td>\n",
       "      <td>[-5.664471367414736, -5.5718437500836, -5.7671...</td>\n",
       "      <td>[0.05008250675800045, 0.0569005873715254, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.5082974, -6.6570473, -6.6209173, -5.598532...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.826899, -6.211263, -6.8936095, -7.1406193...</td>\n",
       "      <td>[-7.15606, -6.0492535, -7.0972013, -6.8656754,...</td>\n",
       "      <td>[0.20176062, 0.2768126, 0.22253177, 0.2013783,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-5.9293000000000005, -6.716400000000002, -6.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.902099999999999, -6.201400000000004, -6.7...</td>\n",
       "      <td>[-6.90134, -6.127810000000004, -6.782379999999...</td>\n",
       "      <td>[0.055375106320439196, 0.2751944265424015, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-6.290107798868079, -5.088392957610974, -4.83...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.17635510576849, -5.219679763498499, -7.92...</td>\n",
       "      <td>[-7.124173486876117, -5.162183623304773, -7.61...</td>\n",
       "      <td>[0.6173754068886426, 0.18405284167909028, 0.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.633333333333333, -5.650000000000001, -5.62...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.3999999999999995, -5.38, -6.2266666666666...</td>\n",
       "      <td>[-6.789333333333333, -4.868666666666667, -6.20...</td>\n",
       "      <td>[0.1946666666666669, 0.27924978862023225, 0.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.879302111430403, -5.967099556949184, -5.14...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.0146032130810045, -5.53883521583049, -5.9...</td>\n",
       "      <td>[-6.073979411009359, -5.4198879227094645, -5.9...</td>\n",
       "      <td>[0.04962852406456833, 0.08950116031302308, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.292377542023209, -6.458740913182588, -5.16...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.381056159110554, -5.753407412390226, -8.1...</td>\n",
       "      <td>[-7.6003343347656, -6.05831657373544, -7.14712...</td>\n",
       "      <td>[0.6276630534169254, 0.3845417703598066, 0.517...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.449185163697374, -6.596589019935487, -5.95...   \n",
       "1   [-5.36, -5.77, -6.244999999999999, -5.05, -4.2...   \n",
       "2   [-6.099700000000002, -6.251600000000001, -6.13...   \n",
       "3   [-6.247998976200171, -6.328466421002222, -5.66...   \n",
       "4   [-5.628926396875004, -5.628926396875004, -5.64...   \n",
       "5   [-6.5082974, -6.6570473, -6.6209173, -5.598532...   \n",
       "6   [-5.9293000000000005, -6.716400000000002, -6.1...   \n",
       "7   [-6.290107798868079, -5.088392957610974, -4.83...   \n",
       "8   [-5.633333333333333, -5.650000000000001, -5.62...   \n",
       "9   [-5.879302111430403, -5.967099556949184, -5.14...   \n",
       "10  [-6.292377542023209, -6.458740913182588, -5.16...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.056119628542196, -6.096394503453853, -6.7...   \n",
       "1   [[-7.0, -6.27, -7.0, -7.0, -6.24, -7.0, -6.85,...   \n",
       "2   [[-6.705799999999999, -5.8228000000000035, -6....   \n",
       "3   [[-6.683679257615391, -5.718991021754435, -6.4...   \n",
       "4   [[-5.670701618893616, -5.608007149539823, -5.6...   \n",
       "5   [[-6.826899, -6.211263, -6.8936095, -7.1406193...   \n",
       "6   [[-6.902099999999999, -6.201400000000004, -6.7...   \n",
       "7   [[-6.17635510576849, -5.219679763498499, -7.92...   \n",
       "8   [[-6.3999999999999995, -5.38, -6.2266666666666...   \n",
       "9   [[-6.0146032130810045, -5.53883521583049, -5.9...   \n",
       "10  [[-6.381056159110554, -5.753407412390226, -8.1...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.017115840615927, -6.052887869020509, -6.73...   \n",
       "1   [-7.0, -5.952, -6.868, -6.476000000000001, -5....   \n",
       "2   [-6.813979999999999, -5.816485000000002, -6.76...   \n",
       "3   [-6.923902195759925, -5.7316140316949395, -6.4...   \n",
       "4   [-5.664471367414736, -5.5718437500836, -5.7671...   \n",
       "5   [-7.15606, -6.0492535, -7.0972013, -6.8656754,...   \n",
       "6   [-6.90134, -6.127810000000004, -6.782379999999...   \n",
       "7   [-7.124173486876117, -5.162183623304773, -7.61...   \n",
       "8   [-6.789333333333333, -4.868666666666667, -6.20...   \n",
       "9   [-6.073979411009359, -5.4198879227094645, -5.9...   \n",
       "10  [-7.6003343347656, -6.05831657373544, -7.14712...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.08968130039351668, 0.26396027609363937, 0.0...  \n",
       "1   [0.0, 0.5911142021640152, 0.26400000000000007,...  \n",
       "2   [0.07220718523803626, 0.2891633515852259, 0.05...  \n",
       "3   [0.12967163152247468, 0.22189762746993172, 0.0...  \n",
       "4   [0.05008250675800045, 0.0569005873715254, 0.11...  \n",
       "5   [0.20176062, 0.2768126, 0.22253177, 0.2013783,...  \n",
       "6   [0.055375106320439196, 0.2751944265424015, 0.0...  \n",
       "7   [0.6173754068886426, 0.18405284167909028, 0.38...  \n",
       "8   [0.1946666666666669, 0.27924978862023225, 0.24...  \n",
       "9   [0.04962852406456833, 0.08950116031302308, 0.0...  \n",
       "10  [0.6276630534169254, 0.3845417703598066, 0.517...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a101e-05d9-4b0c-b0a7-27452dcf0c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56c7f528-126e-48bb-8d79-2c833984713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morgan_count_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_Count_Morgan_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_Count_Morgan_fp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97793322-9d91-4487-8256-bd4173ef8b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 780)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 780)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.735819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 282\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.968910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 303\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.571113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 318\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.733576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 309\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 103\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.465696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 306\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 102\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.2590738857913244\n",
      "0.2687049452713417\n",
      "0.2717447528142659\n",
      "0.2577640800077784\n",
      "0.1418741907693949\n",
      "0.2677117100501484\n",
      "0.26838482909621564\n",
      "0.22005736045649593\n",
      "-0.5823194869348636\n",
      "0.21234188307039048\n",
      "0.25539444347570506\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.2591</td>\n",
       "      <td>0.5097</td>\n",
       "      <td>0.4451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.4188</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.4717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.4657</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.4189</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.2717</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.4683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.5233</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.5104</td>\n",
       "      <td>0.4564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5591</td>\n",
       "      <td>0.5956</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>0.5896</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.4403</td>\n",
       "      <td>0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.4687</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.4169</td>\n",
       "      <td>0.4634</td>\n",
       "      <td>0.5194</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>0.4670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4686</td>\n",
       "      <td>0.5168</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.4702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>0.7057</td>\n",
       "      <td>0.2005</td>\n",
       "      <td>0.4487</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.4936</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.4263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>1.0221</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>1.0110</td>\n",
       "      <td>-0.6411</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>1.0013</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>-0.5823</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.5149</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>0.5165</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.4837</td>\n",
       "      <td>0.4462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.5283</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.5237</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.4518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.4726                0.5227   \n",
       "DecisionTreeRegressor                    0.4671                0.5164   \n",
       "RandomForestRegressor                    0.4657                0.5160   \n",
       "GradientBoostingRegressor                0.4719                0.5233   \n",
       "AdaBoostRegressor                        0.5591                0.5956   \n",
       "XGBRegressor                             0.4687                0.5172   \n",
       "ExtraTreesRegressor                      0.4686                0.5168   \n",
       "LinearRegression                         0.4980                0.5378   \n",
       "KNeighborsRegressor                      1.0221                0.7610   \n",
       "SVR                                      0.4984                0.5149   \n",
       "MLPRegressor                             0.4875                0.5283   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.6875               0.2411   \n",
       "DecisionTreeRegressor                     0.6835               0.2500   \n",
       "RandomForestRegressor                     0.6825               0.2522   \n",
       "GradientBoostingRegressor                 0.6870               0.2422   \n",
       "AdaBoostRegressor                         0.7477               0.1023   \n",
       "XGBRegressor                              0.6846               0.2475   \n",
       "ExtraTreesRegressor                       0.6845               0.2476   \n",
       "LinearRegression                          0.7057               0.2005   \n",
       "KNeighborsRegressor                       1.0110              -0.6411   \n",
       "SVR                                       0.7060               0.1998   \n",
       "MLPRegressor                              0.6982               0.2173   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.4912                0.4080   \n",
       "DecisionTreeRegressor                    0.5024                0.4188   \n",
       "RandomForestRegressor                    0.5036                0.4189   \n",
       "GradientBoostingRegressor                0.4926                0.4081   \n",
       "AdaBoostRegressor                        0.3975                0.3135   \n",
       "XGBRegressor                             0.4998                0.4169   \n",
       "ExtraTreesRegressor                      0.5003                0.4177   \n",
       "LinearRegression                         0.4487                0.3847   \n",
       "KNeighborsRegressor                      0.1001                0.0460   \n",
       "SVR                                      0.4685                0.3890   \n",
       "MLPRegressor                             0.4715                0.4017   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE  Test R2  \\\n",
       "LGBMRegressor               0.4689   0.5256    0.6847   0.2591   \n",
       "DecisionTreeRegressor       0.4628   0.5179    0.6803   0.2687   \n",
       "RandomForestRegressor       0.4609   0.5184    0.6789   0.2717   \n",
       "GradientBoostingRegressor   0.4697   0.5260    0.6854   0.2578   \n",
       "AdaBoostRegressor           0.5430   0.5896    0.7369   0.1419   \n",
       "XGBRegressor                0.4634   0.5194    0.6807   0.2677   \n",
       "ExtraTreesRegressor         0.4630   0.5184    0.6804   0.2684   \n",
       "LinearRegression            0.4936   0.5374    0.7025   0.2201   \n",
       "KNeighborsRegressor         1.0013   0.7524    1.0007  -0.5823   \n",
       "SVR                         0.4985   0.5165    0.7060   0.2123   \n",
       "MLPRegressor                0.4712   0.5237    0.6864   0.2554   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.5097                    0.4451  \n",
       "DecisionTreeRegressor                       0.5189                    0.4717  \n",
       "RandomForestRegressor                       0.5216                    0.4683  \n",
       "GradientBoostingRegressor                   0.5104                    0.4564  \n",
       "AdaBoostRegressor                           0.4403                    0.3780  \n",
       "XGBRegressor                                0.5178                    0.4670  \n",
       "ExtraTreesRegressor                         0.5186                    0.4702  \n",
       "LinearRegression                            0.4695                    0.4263  \n",
       "KNeighborsRegressor                         0.1097                    0.0597  \n",
       "SVR                                         0.4837                    0.4462  \n",
       "MLPRegressor                                0.5056                    0.4518  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AtomPairs2d fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/AtomPairs2D_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/AtomPairs2D_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_AtomPairs2D_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_AtomPairs2D_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27e000f4-dee5-4f7b-b9a7-39d079424b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-4.9086869084682085, -6.102272875476731, -4.9...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.102272875476731, -4.9086869084682085, -4....</td>\n",
       "      <td>[-6.201250970679353, -4.8980753335735185, -4.8...</td>\n",
       "      <td>[0.10658676709104507, 0.006126817587410635, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-4.9063112745098, -6.891818181818182, -4.9063...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.891818181818182, -4.9063112745098, -4.906...</td>\n",
       "      <td>[-6.905297702297702, -4.891983787248, -4.89198...</td>\n",
       "      <td>[0.029975904951973498, 0.007545921192803515, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-4.904347947744239, -6.897547414701313, -4.90...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.897547414701313, -4.904347947744239, -4.9...</td>\n",
       "      <td>[-6.907922054244575, -4.891921724700505, -4.89...</td>\n",
       "      <td>[0.02748085836576134, 0.00648588223071733, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-4.942770303007276, -6.38923752183285, -4.942...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.38923752183285, -4.942770303007276, -4.94...</td>\n",
       "      <td>[-6.443654054904175, -4.934503426654722, -4.93...</td>\n",
       "      <td>[0.10428035464208042, 0.006686660428874856, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.189037037037035, -5.595292353800221, -5.18...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.595292353800221, -5.189037037037035, -5.1...</td>\n",
       "      <td>[-5.476668145499879, -5.217025649232757, -5.21...</td>\n",
       "      <td>[0.07943032530477756, 0.03226372975112234, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-4.905953, -6.8887696, -4.905953, -4.905953, ...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8887696, -4.905953, -4.905953, -5.7109632...</td>\n",
       "      <td>[-6.903834, -4.8910723, -4.8910723, -5.7000566...</td>\n",
       "      <td>[0.02937797, 0.007928123, 0.007928123, 0.23334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-4.906311274509793, -6.8918181818181745, -4.9...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8918181818181745, -4.906311274509793, -4....</td>\n",
       "      <td>[-6.905297702297702, -4.891983787248001, -4.89...</td>\n",
       "      <td>[0.029975904951973303, 0.00754592119280148, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.981106872180091, -6.077775887965633, -4.98...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.077775887965633, -4.981106872180091, -4.9...</td>\n",
       "      <td>[-6.122504837623203, -4.9665795364759475, -4.9...</td>\n",
       "      <td>[0.10912193600715611, 0.007268269204355609, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-7.0, -6.986666666666667, -7.0, -7.0, -7.0, -...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -7.0, -7.0, -6.206666666...</td>\n",
       "      <td>[-6.984, -7.0, -7.0, -5.948666666666667, -7.0,...</td>\n",
       "      <td>[0.005333333333333456, 0.0, 0.0, 0.36911666328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.7003010070712685, -6.9000107340154155, -4....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9000107340154155, -4.7003010070712685, -4...</td>\n",
       "      <td>[-6.900020644181604, -4.697967948288505, -4.69...</td>\n",
       "      <td>[8.999915137827895e-05, 0.0041328897161808644,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-4.782222348281741, -6.296947102023128, -4.78...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.296947102023128, -4.782222348281741, -4.7...</td>\n",
       "      <td>[-6.441781804324178, -4.853912586676534, -4.85...</td>\n",
       "      <td>[0.3756294892363255, 0.044764993729167236, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-4.9086869084682085, -6.102272875476731, -4.9...   \n",
       "1   [-4.9063112745098, -6.891818181818182, -4.9063...   \n",
       "2   [-4.904347947744239, -6.897547414701313, -4.90...   \n",
       "3   [-4.942770303007276, -6.38923752183285, -4.942...   \n",
       "4   [-5.189037037037035, -5.595292353800221, -5.18...   \n",
       "5   [-4.905953, -6.8887696, -4.905953, -4.905953, ...   \n",
       "6   [-4.906311274509793, -6.8918181818181745, -4.9...   \n",
       "7   [-4.981106872180091, -6.077775887965633, -4.98...   \n",
       "8   [-7.0, -6.986666666666667, -7.0, -7.0, -7.0, -...   \n",
       "9   [-4.7003010070712685, -6.9000107340154155, -4....   \n",
       "10  [-4.782222348281741, -6.296947102023128, -4.78...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.102272875476731, -4.9086869084682085, -4....   \n",
       "1   [[-6.891818181818182, -4.9063112745098, -4.906...   \n",
       "2   [[-6.897547414701313, -4.904347947744239, -4.9...   \n",
       "3   [[-6.38923752183285, -4.942770303007276, -4.94...   \n",
       "4   [[-5.595292353800221, -5.189037037037035, -5.1...   \n",
       "5   [[-6.8887696, -4.905953, -4.905953, -5.7109632...   \n",
       "6   [[-6.8918181818181745, -4.906311274509793, -4....   \n",
       "7   [[-6.077775887965633, -4.981106872180091, -4.9...   \n",
       "8   [[-6.986666666666667, -7.0, -7.0, -6.206666666...   \n",
       "9   [[-6.9000107340154155, -4.7003010070712685, -4...   \n",
       "10  [[-6.296947102023128, -4.782222348281741, -4.7...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.201250970679353, -4.8980753335735185, -4.8...   \n",
       "1   [-6.905297702297702, -4.891983787248, -4.89198...   \n",
       "2   [-6.907922054244575, -4.891921724700505, -4.89...   \n",
       "3   [-6.443654054904175, -4.934503426654722, -4.93...   \n",
       "4   [-5.476668145499879, -5.217025649232757, -5.21...   \n",
       "5   [-6.903834, -4.8910723, -4.8910723, -5.7000566...   \n",
       "6   [-6.905297702297702, -4.891983787248001, -4.89...   \n",
       "7   [-6.122504837623203, -4.9665795364759475, -4.9...   \n",
       "8   [-6.984, -7.0, -7.0, -5.948666666666667, -7.0,...   \n",
       "9   [-6.900020644181604, -4.697967948288505, -4.69...   \n",
       "10  [-6.441781804324178, -4.853912586676534, -4.85...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.10658676709104507, 0.006126817587410635, 0....  \n",
       "1   [0.029975904951973498, 0.007545921192803515, 0...  \n",
       "2   [0.02748085836576134, 0.00648588223071733, 0.0...  \n",
       "3   [0.10428035464208042, 0.006686660428874856, 0....  \n",
       "4   [0.07943032530477756, 0.03226372975112234, 0.0...  \n",
       "5   [0.02937797, 0.007928123, 0.007928123, 0.23334...  \n",
       "6   [0.029975904951973303, 0.00754592119280148, 0....  \n",
       "7   [0.10912193600715611, 0.007268269204355609, 0....  \n",
       "8   [0.005333333333333456, 0.0, 0.0, 0.36911666328...  \n",
       "9   [8.999915137827895e-05, 0.0041328897161808644,...  \n",
       "10  [0.3756294892363255, 0.044764993729167236, 0.0...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13d5fabe-491d-4f53-a81d-d63d523017a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AtomPairs2D_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_AtomPairs2D_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_AtomPairs2D_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88e3181f-d028-46c2-b0be-a10cfe61dedc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 780)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 780)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.973961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2865\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.629845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2882\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 140\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.449534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2929\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 145\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.513178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2902\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.645905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2900\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 141\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6151277554180334\n",
      "0.5982834475644396\n",
      "0.6132631158625841\n",
      "0.5401086653531614\n",
      "0.22991534531108104\n",
      "0.6239633316408134\n",
      "0.6337718172776821\n",
      "0.3773476859356244\n",
      "0.5824833208786999\n",
      "0.4522484130407358\n",
      "0.5208920666546784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2382</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.2436</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>0.4935</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.3893</td>\n",
       "      <td>0.5694</td>\n",
       "      <td>0.4795</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.3524</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.7752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2342</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>0.4839</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.7649</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.4947</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.7791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.3954</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.7498</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.2910</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.4873</td>\n",
       "      <td>0.5716</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2346</td>\n",
       "      <td>0.3498</td>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.7639</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.3439</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.7829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.3461</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.8009</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>0.7847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4127</td>\n",
       "      <td>0.4729</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3373</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.6074</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.2751</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.5245</td>\n",
       "      <td>0.5583</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.3683</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.7547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.4119</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>0.4619</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.4162</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.6885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.5009</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>0.6984</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>0.3944</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.7279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2382                0.3571   \n",
       "DecisionTreeRegressor                    0.3242                0.3893   \n",
       "RandomForestRegressor                    0.2342                0.3512   \n",
       "GradientBoostingRegressor                0.2798                0.3954   \n",
       "AdaBoostRegressor                        0.5206                0.5902   \n",
       "XGBRegressor                             0.2346                0.3498   \n",
       "ExtraTreesRegressor                      0.2234                0.3461   \n",
       "LinearRegression                         0.4127                0.4729   \n",
       "KNeighborsRegressor                      0.2751                0.3804   \n",
       "SVR                                      0.3351                0.4119   \n",
       "MLPRegressor                             0.3108                0.4040   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4881               0.6175   \n",
       "DecisionTreeRegressor                     0.5694               0.4795   \n",
       "RandomForestRegressor                     0.4839               0.6240   \n",
       "GradientBoostingRegressor                 0.5290               0.5507   \n",
       "AdaBoostRegressor                         0.7215               0.1641   \n",
       "XGBRegressor                              0.4843               0.6233   \n",
       "ExtraTreesRegressor                       0.4727               0.6412   \n",
       "LinearRegression                          0.6424               0.3373   \n",
       "KNeighborsRegressor                       0.5245               0.5583   \n",
       "SVR                                       0.5789               0.4619   \n",
       "MLPRegressor                              0.5575               0.5009   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7874                0.7580   \n",
       "DecisionTreeRegressor                    0.7143                0.7161   \n",
       "RandomForestRegressor                    0.7899                0.7649   \n",
       "GradientBoostingRegressor                0.7498                0.7107   \n",
       "AdaBoostRegressor                        0.5374                0.4745   \n",
       "XGBRegressor                             0.7902                0.7639   \n",
       "ExtraTreesRegressor                      0.8009                0.7748   \n",
       "LinearRegression                         0.5846                0.6074   \n",
       "KNeighborsRegressor                      0.7538                0.7212   \n",
       "SVR                                      0.6875                0.6782   \n",
       "MLPRegressor                             0.7112                0.6984   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2436   0.3568    0.4935  0.6151   \n",
       "DecisionTreeRegressor       0.2542   0.3524    0.5042  0.5983   \n",
       "RandomForestRegressor       0.2447   0.3492    0.4947  0.6133   \n",
       "GradientBoostingRegressor   0.2910   0.3977    0.5395  0.5401   \n",
       "AdaBoostRegressor           0.4873   0.5716    0.6981  0.2299   \n",
       "XGBRegressor                0.2380   0.3439    0.4878  0.6240   \n",
       "ExtraTreesRegressor         0.2318   0.3426    0.4814  0.6338   \n",
       "LinearRegression            0.3940   0.4630    0.6277  0.3773   \n",
       "KNeighborsRegressor         0.2642   0.3683    0.5140  0.5825   \n",
       "SVR                         0.3466   0.4162    0.5888  0.4522   \n",
       "MLPRegressor                0.3032   0.3944    0.5506  0.5209   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7860                    0.7739  \n",
       "DecisionTreeRegressor                       0.7766                    0.7752  \n",
       "RandomForestRegressor                       0.7835                    0.7791  \n",
       "GradientBoostingRegressor                   0.7425                    0.7310  \n",
       "AdaBoostRegressor                           0.5885                    0.5179  \n",
       "XGBRegressor                                0.7906                    0.7829  \n",
       "ExtraTreesRegressor                         0.7966                    0.7847  \n",
       "LinearRegression                            0.6149                    0.6450  \n",
       "KNeighborsRegressor                         0.7674                    0.7547  \n",
       "SVR                                         0.6811                    0.6885  \n",
       "MLPRegressor                                0.7234                    0.7279  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AtomPairs2d Count fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/AtomPairs2DCount_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/AtomPairs2DCount_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_AtomPairs2DCount_fp , pred_df= train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_AtomPairs2DCount_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dd45fe5-079a-45c7-b73c-71ac0760ab92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.776166605845609, -6.961229630383343, -6.76...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.061584125883738, -6.776166605845609, -6.8...</td>\n",
       "      <td>[-7.085543113794145, -6.750700688177885, -6.83...</td>\n",
       "      <td>[0.06921389987843728, 0.03254166801992616, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-6.51, -7.0, -7.0, -5.05, -7.0, -5.05, -5.05,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.11, -7.0, -7.0, -6.11, -6.8, -6.85,...</td>\n",
       "      <td>[-6.962000000000001, -6.518000000000001, -7.0,...</td>\n",
       "      <td>[0.058103356185335936, 0.39640383449204913, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.8196, -6.9311, -6.837433333333334, -5.3637...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9185, -6.748300000000001, -6.939900000000...</td>\n",
       "      <td>[-6.924170000000001, -6.724100000000002, -6.92...</td>\n",
       "      <td>[0.023132868391100958, 0.07852151297574445, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.758107393407671, -6.848592545320579, -6.61...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.204544935589532, -6.627400163868768, -6.9...</td>\n",
       "      <td>[-7.233705996106201, -6.644991246699744, -6.83...</td>\n",
       "      <td>[0.12057279321492244, 0.08712158720539408, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-6.020984126984135, -6.016307649232414, -6.01...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.158888888888891, -6.185599999999999, -6.1...</td>\n",
       "      <td>[-6.2060298891208845, -6.200845391967694, -6.2...</td>\n",
       "      <td>[0.22918834427835977, 0.22192059621590743, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.817171, -7.015907, -6.890958, -5.4465914, ...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.190226, -6.550555, -7.0217266, -6.8290143...</td>\n",
       "      <td>[-7.000787, -6.688304, -6.9831047, -6.4883804,...</td>\n",
       "      <td>[0.19644047, 0.097358644, 0.026843786, 0.20188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.734900000000001, -6.9430499999999995, -6.7...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9799, -6.625000000000003, -6.974499999999...</td>\n",
       "      <td>[-6.952000000000001, -6.7403400000000016, -6.9...</td>\n",
       "      <td>[0.025896949627321118, 0.1077930535795317, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.730253913531768, -5.609661702595346, -5.32...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.577591587074083, -4.999496207947311, -5.7...</td>\n",
       "      <td>[-6.5755122470628695, -4.992418580737516, -5.6...</td>\n",
       "      <td>[0.06021195738358451, 0.07789941311010345, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-6.746666666666667, -7.0, -6.05, -4.96, -4.88...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -6.746666666666667, -7.0...</td>\n",
       "      <td>[-6.989333333333333, -6.797333333333334, -7.0,...</td>\n",
       "      <td>[0.005333333333333102, 0.10133333333333318, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-7.089332828171322, -6.896461791744283, -6.00...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.028224887085463, -6.606094902467699, -6.6...</td>\n",
       "      <td>[-7.055541082649976, -6.5812216790095075, -6.5...</td>\n",
       "      <td>[0.02947272774284844, 0.051579172886891414, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.786635361318021, -7.2543852721621915, -5.9...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-8.182960924514582, -5.9431151518304794, -6....</td>\n",
       "      <td>[-8.506389722366517, -6.167840246365897, -6.65...</td>\n",
       "      <td>[0.18641236610174314, 0.22759092019567959, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.776166605845609, -6.961229630383343, -6.76...   \n",
       "1   [-6.51, -7.0, -7.0, -5.05, -7.0, -5.05, -5.05,...   \n",
       "2   [-6.8196, -6.9311, -6.837433333333334, -5.3637...   \n",
       "3   [-6.758107393407671, -6.848592545320579, -6.61...   \n",
       "4   [-6.020984126984135, -6.016307649232414, -6.01...   \n",
       "5   [-6.817171, -7.015907, -6.890958, -5.4465914, ...   \n",
       "6   [-6.734900000000001, -6.9430499999999995, -6.7...   \n",
       "7   [-5.730253913531768, -5.609661702595346, -5.32...   \n",
       "8   [-6.746666666666667, -7.0, -6.05, -4.96, -4.88...   \n",
       "9   [-7.089332828171322, -6.896461791744283, -6.00...   \n",
       "10  [-6.786635361318021, -7.2543852721621915, -5.9...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.061584125883738, -6.776166605845609, -6.8...   \n",
       "1   [[-7.0, -6.11, -7.0, -7.0, -6.11, -6.8, -6.85,...   \n",
       "2   [[-6.9185, -6.748300000000001, -6.939900000000...   \n",
       "3   [[-7.204544935589532, -6.627400163868768, -6.9...   \n",
       "4   [[-6.158888888888891, -6.185599999999999, -6.1...   \n",
       "5   [[-7.190226, -6.550555, -7.0217266, -6.8290143...   \n",
       "6   [[-6.9799, -6.625000000000003, -6.974499999999...   \n",
       "7   [[-6.577591587074083, -4.999496207947311, -5.7...   \n",
       "8   [[-6.986666666666667, -6.746666666666667, -7.0...   \n",
       "9   [[-7.028224887085463, -6.606094902467699, -6.6...   \n",
       "10  [[-8.182960924514582, -5.9431151518304794, -6....   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.085543113794145, -6.750700688177885, -6.83...   \n",
       "1   [-6.962000000000001, -6.518000000000001, -7.0,...   \n",
       "2   [-6.924170000000001, -6.724100000000002, -6.92...   \n",
       "3   [-7.233705996106201, -6.644991246699744, -6.83...   \n",
       "4   [-6.2060298891208845, -6.200845391967694, -6.2...   \n",
       "5   [-7.000787, -6.688304, -6.9831047, -6.4883804,...   \n",
       "6   [-6.952000000000001, -6.7403400000000016, -6.9...   \n",
       "7   [-6.5755122470628695, -4.992418580737516, -5.6...   \n",
       "8   [-6.989333333333333, -6.797333333333334, -7.0,...   \n",
       "9   [-7.055541082649976, -6.5812216790095075, -6.5...   \n",
       "10  [-8.506389722366517, -6.167840246365897, -6.65...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.06921389987843728, 0.03254166801992616, 0.0...  \n",
       "1   [0.058103356185335936, 0.39640383449204913, 0....  \n",
       "2   [0.023132868391100958, 0.07852151297574445, 0....  \n",
       "3   [0.12057279321492244, 0.08712158720539408, 0.0...  \n",
       "4   [0.22918834427835977, 0.22192059621590743, 0.2...  \n",
       "5   [0.19644047, 0.097358644, 0.026843786, 0.20188...  \n",
       "6   [0.025896949627321118, 0.1077930535795317, 0.0...  \n",
       "7   [0.06021195738358451, 0.07789941311010345, 0.0...  \n",
       "8   [0.005333333333333102, 0.10133333333333318, 0....  \n",
       "9   [0.02947272774284844, 0.051579172886891414, 0....  \n",
       "10  [0.18641236610174314, 0.22759092019567959, 0.2...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4429bda4-7e4b-4173-9df7-bccabc4a4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AtomPairs2DCount_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_AtomPairs2D_Count_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_df_AtomPairs2D_Count_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6a46d4-b1ec-4a98-b71f-e7c8f3fbd076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 79)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 79)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.411576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.495367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 48\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.777236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.465508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.19056437465565101\n",
      "0.19052032362538718\n",
      "0.1983543668072466\n",
      "0.2333818047272037\n",
      "0.014448233831855894\n",
      "0.19500175717369872\n",
      "0.19131997487852392\n",
      "0.19764046943304114\n",
      "-0.6404187095649789\n",
      "0.1922728301526081\n",
      "0.22917943246770034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.4991</td>\n",
       "      <td>0.5412</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.3539</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.3684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4801</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.4466</td>\n",
       "      <td>0.3938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.4764</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.6902</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0.4859</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>0.7123</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.3955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.3987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.7897</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.4801</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>0.5094</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.3953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.5287</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.3768</td>\n",
       "      <td>0.5118</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>0.3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.4403</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.5494</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.4452</td>\n",
       "      <td>0.3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>1.0381</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>1.0189</td>\n",
       "      <td>-0.6668</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>1.0381</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>1.0189</td>\n",
       "      <td>-0.6404</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>-0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.3698</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.5297</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.4661</td>\n",
       "      <td>0.3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.4644</td>\n",
       "      <td>0.3783</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.6984</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.4801</td>\n",
       "      <td>0.3983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.4991                0.5412   \n",
       "DecisionTreeRegressor                    0.4801                0.5286   \n",
       "RandomForestRegressor                    0.4764                0.5282   \n",
       "GradientBoostingRegressor                0.4844                0.5341   \n",
       "AdaBoostRegressor                        0.6364                0.6432   \n",
       "XGBRegressor                             0.4811                0.5290   \n",
       "ExtraTreesRegressor                      0.4803                0.5287   \n",
       "LinearRegression                         0.5023                0.5424   \n",
       "KNeighborsRegressor                      1.0381                0.7543   \n",
       "SVR                                      0.5034                0.5206   \n",
       "MLPRegressor                             0.4910                0.5372   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.7064               0.1987   \n",
       "DecisionTreeRegressor                     0.6929               0.2291   \n",
       "RandomForestRegressor                     0.6902               0.2351   \n",
       "GradientBoostingRegressor                 0.6960               0.2222   \n",
       "AdaBoostRegressor                         0.7977              -0.0218   \n",
       "XGBRegressor                              0.6936               0.2275   \n",
       "ExtraTreesRegressor                       0.6930               0.2288   \n",
       "LinearRegression                          0.7087               0.1935   \n",
       "KNeighborsRegressor                       1.0189              -0.6668   \n",
       "SVR                                       0.7095               0.1916   \n",
       "MLPRegressor                              0.7007               0.2116   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.4459                0.3539   \n",
       "DecisionTreeRegressor                    0.4819                0.3767   \n",
       "RandomForestRegressor                    0.4859                0.3771   \n",
       "GradientBoostingRegressor                0.4714                0.3706   \n",
       "AdaBoostRegressor                        0.3299                0.2879   \n",
       "XGBRegressor                             0.4801                0.3781   \n",
       "ExtraTreesRegressor                      0.4816                0.3768   \n",
       "LinearRegression                         0.4403                0.3510   \n",
       "KNeighborsRegressor                      0.0616               -0.0051   \n",
       "SVR                                      0.4638                0.3698   \n",
       "MLPRegressor                             0.4644                0.3783   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE  Test R2  \\\n",
       "LGBMRegressor               0.5122   0.5527    0.7157   0.1906   \n",
       "DecisionTreeRegressor       0.5123   0.5452    0.7157   0.1905   \n",
       "RandomForestRegressor       0.5073   0.5443    0.7123   0.1984   \n",
       "GradientBoostingRegressor   0.4851   0.5405    0.6965   0.2334   \n",
       "AdaBoostRegressor           0.6237   0.6423    0.7897   0.0144   \n",
       "XGBRegressor                0.5094   0.5444    0.7137   0.1950   \n",
       "ExtraTreesRegressor         0.5118   0.5448    0.7154   0.1913   \n",
       "LinearRegression            0.5078   0.5494    0.7126   0.1976   \n",
       "KNeighborsRegressor         1.0381   0.7533    1.0189  -0.6404   \n",
       "SVR                         0.5112   0.5297    0.7149   0.1923   \n",
       "MLPRegressor                0.4878   0.5408    0.6984   0.2292   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.4375                    0.3684  \n",
       "DecisionTreeRegressor                       0.4466                    0.3938  \n",
       "RandomForestRegressor                       0.4522                    0.3955  \n",
       "GradientBoostingRegressor                   0.4836                    0.3987  \n",
       "AdaBoostRegressor                           0.3643                    0.3780  \n",
       "XGBRegressor                                0.4502                    0.3953  \n",
       "ExtraTreesRegressor                         0.4473                    0.3940  \n",
       "LinearRegression                            0.4452                    0.3724  \n",
       "KNeighborsRegressor                         0.0303                   -0.0355  \n",
       "SVR                                         0.4661                    0.3884  \n",
       "MLPRegressor                                0.4801                    0.3983  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EState fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/EState_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/EState_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_estate_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_estate_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae723d61-dc4d-43c4-b8aa-24852dd3d7c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-4.7257515416316584, -6.166855400211246, -5.2...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.166855400211246, -4.7257515416316584, -5....</td>\n",
       "      <td>[-6.339492670798963, -4.787478843320073, -5.17...</td>\n",
       "      <td>[0.10211072329341182, 0.031286363442289376, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-4.677142857142858, -6.387333333333332, -5.13...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.387333333333332, -4.677142857142858, -5.1...</td>\n",
       "      <td>[-6.452906725146198, -4.750804141523365, -5.10...</td>\n",
       "      <td>[0.05644788211127124, 0.037324128282113095, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-4.682808658584028, -6.350122042329398, -5.12...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.350122042329398, -4.682808658584028, -5.1...</td>\n",
       "      <td>[-6.439855177418162, -4.752358232880523, -5.10...</td>\n",
       "      <td>[0.06421896488370266, 0.035835586931385444, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-4.734528154931525, -6.303856554812297, -5.17...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.303856554812297, -4.734528154931525, -5.1...</td>\n",
       "      <td>[-6.40606307495891, -4.812889473467336, -5.153...</td>\n",
       "      <td>[0.08041007231346635, 0.041570310672311823, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.113022727272723, -5.9350834728218125, -5.8...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.9350834728218125, -5.113022727272723, -5....</td>\n",
       "      <td>[-6.003012729360843, -5.42484121932522, -5.845...</td>\n",
       "      <td>[0.09127246542793117, 0.28479966711645976, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-4.67768, -6.38528, -5.1340313, -5.1340313, -...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.38528, -4.67768, -5.1340313, -5.06476, -5...</td>\n",
       "      <td>[-6.4520493, -4.7515783, -5.10966, -5.4020844,...</td>\n",
       "      <td>[0.056535397, 0.037432015, 0.015893554, 0.2128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-4.677142857142868, -6.387333333333341, -5.13...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.387333333333341, -4.677142857142868, -5.1...</td>\n",
       "      <td>[-6.452906725146202, -4.750804141523371, -5.10...</td>\n",
       "      <td>[0.0564478821112736, 0.037324128282111645, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.735702715986039, -5.985935610486654, -5.18...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.985935610486654, -4.735702715986039, -5.1...</td>\n",
       "      <td>[-6.154884885188663, -4.7845373577075145, -5.1...</td>\n",
       "      <td>[0.09248167881925906, 0.02851715256928644, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.603333333333333, -6.986666666666667, -7.0,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -5.603333333333333, -7.0...</td>\n",
       "      <td>[-6.984, -6.708666666666668, -7.0, -5.17866666...</td>\n",
       "      <td>[0.005333333333333456, 0.5531549913400807, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.580073596142576, -6.900183296007555, -4.82...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.900183296007555, -4.580073596142576, -4.8...</td>\n",
       "      <td>[-6.899878411008752, -4.612073429558651, -4.80...</td>\n",
       "      <td>[0.00031373434068456956, 0.01934696595562291, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-4.723037669315358, -6.41269385438095, -5.146...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.41269385438095, -4.723037669315358, -5.14...</td>\n",
       "      <td>[-6.477883177024813, -4.8017053627982085, -5.1...</td>\n",
       "      <td>[0.07963896699749518, 0.049518383450751303, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-4.7257515416316584, -6.166855400211246, -5.2...   \n",
       "1   [-4.677142857142858, -6.387333333333332, -5.13...   \n",
       "2   [-4.682808658584028, -6.350122042329398, -5.12...   \n",
       "3   [-4.734528154931525, -6.303856554812297, -5.17...   \n",
       "4   [-5.113022727272723, -5.9350834728218125, -5.8...   \n",
       "5   [-4.67768, -6.38528, -5.1340313, -5.1340313, -...   \n",
       "6   [-4.677142857142868, -6.387333333333341, -5.13...   \n",
       "7   [-4.735702715986039, -5.985935610486654, -5.18...   \n",
       "8   [-5.603333333333333, -6.986666666666667, -7.0,...   \n",
       "9   [-4.580073596142576, -6.900183296007555, -4.82...   \n",
       "10  [-4.723037669315358, -6.41269385438095, -5.146...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.166855400211246, -4.7257515416316584, -5....   \n",
       "1   [[-6.387333333333332, -4.677142857142858, -5.1...   \n",
       "2   [[-6.350122042329398, -4.682808658584028, -5.1...   \n",
       "3   [[-6.303856554812297, -4.734528154931525, -5.1...   \n",
       "4   [[-5.9350834728218125, -5.113022727272723, -5....   \n",
       "5   [[-6.38528, -4.67768, -5.1340313, -5.06476, -5...   \n",
       "6   [[-6.387333333333341, -4.677142857142868, -5.1...   \n",
       "7   [[-5.985935610486654, -4.735702715986039, -5.1...   \n",
       "8   [[-6.986666666666667, -5.603333333333333, -7.0...   \n",
       "9   [[-6.900183296007555, -4.580073596142576, -4.8...   \n",
       "10  [[-6.41269385438095, -4.723037669315358, -5.14...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.339492670798963, -4.787478843320073, -5.17...   \n",
       "1   [-6.452906725146198, -4.750804141523365, -5.10...   \n",
       "2   [-6.439855177418162, -4.752358232880523, -5.10...   \n",
       "3   [-6.40606307495891, -4.812889473467336, -5.153...   \n",
       "4   [-6.003012729360843, -5.42484121932522, -5.845...   \n",
       "5   [-6.4520493, -4.7515783, -5.10966, -5.4020844,...   \n",
       "6   [-6.452906725146202, -4.750804141523371, -5.10...   \n",
       "7   [-6.154884885188663, -4.7845373577075145, -5.1...   \n",
       "8   [-6.984, -6.708666666666668, -7.0, -5.17866666...   \n",
       "9   [-6.899878411008752, -4.612073429558651, -4.80...   \n",
       "10  [-6.477883177024813, -4.8017053627982085, -5.1...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.10211072329341182, 0.031286363442289376, 0....  \n",
       "1   [0.05644788211127124, 0.037324128282113095, 0....  \n",
       "2   [0.06421896488370266, 0.035835586931385444, 0....  \n",
       "3   [0.08041007231346635, 0.041570310672311823, 0....  \n",
       "4   [0.09127246542793117, 0.28479966711645976, 0.0...  \n",
       "5   [0.056535397, 0.037432015, 0.015893554, 0.2128...  \n",
       "6   [0.0564478821112736, 0.037324128282111645, 0.0...  \n",
       "7   [0.09248167881925906, 0.02851715256928644, 0.0...  \n",
       "8   [0.005333333333333456, 0.5531549913400807, 0.0...  \n",
       "9   [0.00031373434068456956, 0.01934696595562291, ...  \n",
       "10  [0.07963896699749518, 0.049518383450751303, 0....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e753ba0b-1924-4449-bba7-db44ba8fedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estate_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_EState_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_EState_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e47a84-0389-45c9-9c1c-97ccac74d97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 1024)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 1024)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 15.013151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2274\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 758\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2271\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 757\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 762\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2262\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 754\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2268\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 756\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.4154263008337604\n",
      "0.3903123115577257\n",
      "0.42629829349496895\n",
      "0.37466638592124246\n",
      "-0.0017213234243231845\n",
      "0.4303019880332203\n",
      "0.39634166290079464\n",
      "0.31653536039810093\n",
      "0.30883644855898196\n",
      "0.377777949574553\n",
      "0.3456688566345082\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3678</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.5904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4212</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.5403</td>\n",
       "      <td>0.3858</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.3593</td>\n",
       "      <td>0.4511</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>0.3631</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.4263</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.5945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.4769</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.6174</td>\n",
       "      <td>0.5289</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.6291</td>\n",
       "      <td>0.3747</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.5564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.6498</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>0.8061</td>\n",
       "      <td>-0.0434</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.6339</td>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.3962</td>\n",
       "      <td>0.4374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.3616</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>0.4193</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.3605</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.5946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>0.3820</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>0.6181</td>\n",
       "      <td>0.3963</td>\n",
       "      <td>0.6346</td>\n",
       "      <td>0.5847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.7176</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.5220</td>\n",
       "      <td>0.5230</td>\n",
       "      <td>0.4325</td>\n",
       "      <td>0.4818</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>0.5509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.5603</td>\n",
       "      <td>0.4793</td>\n",
       "      <td>0.4374</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.6614</td>\n",
       "      <td>0.3088</td>\n",
       "      <td>0.5931</td>\n",
       "      <td>0.5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.3618</td>\n",
       "      <td>0.6104</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.6244</td>\n",
       "      <td>0.5773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.2782</td>\n",
       "      <td>0.5631</td>\n",
       "      <td>0.5203</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.3457</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.5575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.3678                0.4612   \n",
       "DecisionTreeRegressor                    0.4212                0.4736   \n",
       "RandomForestRegressor                    0.3593                0.4511   \n",
       "GradientBoostingRegressor                0.3875                0.4769   \n",
       "AdaBoostRegressor                        0.6498                0.6542   \n",
       "XGBRegressor                             0.3616                0.4525   \n",
       "ExtraTreesRegressor                      0.4148                0.4723   \n",
       "LinearRegression                         0.5150                0.5090   \n",
       "KNeighborsRegressor                      0.4640                0.5059   \n",
       "SVR                                      0.3975                0.4630   \n",
       "MLPRegressor                             0.4495                0.5046   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.6065               0.4094   \n",
       "DecisionTreeRegressor                     0.6490               0.3238   \n",
       "RandomForestRegressor                     0.5994               0.4231   \n",
       "GradientBoostingRegressor                 0.6225               0.3779   \n",
       "AdaBoostRegressor                         0.8061              -0.0434   \n",
       "XGBRegressor                              0.6014               0.4193   \n",
       "ExtraTreesRegressor                       0.6440               0.3340   \n",
       "LinearRegression                          0.7176               0.1731   \n",
       "KNeighborsRegressor                       0.6812               0.2549   \n",
       "SVR                                       0.6304               0.3618   \n",
       "MLPRegressor                              0.6705               0.2782   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.6409                0.5628   \n",
       "DecisionTreeRegressor                    0.5983                0.5403   \n",
       "RandomForestRegressor                    0.6518                0.5758   \n",
       "GradientBoostingRegressor                0.6174                0.5289   \n",
       "AdaBoostRegressor                        0.3735                0.3857   \n",
       "XGBRegressor                             0.6515                0.5702   \n",
       "ExtraTreesRegressor                      0.6026                0.5420   \n",
       "LinearRegression                         0.5220                0.5230   \n",
       "KNeighborsRegressor                      0.5603                0.4793   \n",
       "SVR                                      0.6104                0.5473   \n",
       "MLPRegressor                             0.5631                0.5203   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE  Test R2  \\\n",
       "LGBMRegressor               0.3699   0.4602    0.6082   0.4154   \n",
       "DecisionTreeRegressor       0.3858   0.4579    0.6212   0.3903   \n",
       "RandomForestRegressor       0.3631   0.4498    0.6025   0.4263   \n",
       "GradientBoostingRegressor   0.3957   0.4789    0.6291   0.3747   \n",
       "AdaBoostRegressor           0.6339   0.6458    0.7962  -0.0017   \n",
       "XGBRegressor                0.3605   0.4490    0.6004   0.4303   \n",
       "ExtraTreesRegressor         0.3820   0.4562    0.6181   0.3963   \n",
       "LinearRegression            0.4325   0.4818    0.6577   0.3165   \n",
       "KNeighborsRegressor         0.4374   0.4891    0.6614   0.3088   \n",
       "SVR                         0.3938   0.4586    0.6275   0.3778   \n",
       "MLPRegressor                0.4141   0.4867    0.6435   0.3457   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.6467                    0.5904  \n",
       "DecisionTreeRegressor                       0.6312                    0.5836  \n",
       "RandomForestRegressor                       0.6534                    0.5945  \n",
       "GradientBoostingRegressor                   0.6146                    0.5564  \n",
       "AdaBoostRegressor                           0.3962                    0.4374  \n",
       "XGBRegressor                                0.6571                    0.5946  \n",
       "ExtraTreesRegressor                         0.6346                    0.5847  \n",
       "LinearRegression                            0.5828                    0.5509  \n",
       "KNeighborsRegressor                         0.5931                    0.5366  \n",
       "SVR                                         0.6244                    0.5773  \n",
       "MLPRegressor                                0.5983                    0.5575  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extended fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/Extended_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/Extended_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_extended_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_extended_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9d4e9f-e5f6-432e-92dc-7c59cfb68fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-5.210110133447338, -6.732410735254416, -5.75...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.306895107939291, -5.066698711260405, -5.2...</td>\n",
       "      <td>[-6.393563645699494, -5.3717918456608285, -5.1...</td>\n",
       "      <td>[0.1128025441255652, 0.1879859436716718, 0.099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-5.62, -6.96, -6.6225, -4.7775, -6.6225, -4.2...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.96, -6.24, -5.1, -6.22, -4.8175, -6.6225,...</td>\n",
       "      <td>[-6.992, -6.25, -5.414, -5.822, -5.28499999999...</td>\n",
       "      <td>[0.016000000000000014, 0.8143218037115305, 0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-5.995883333333333, -6.912300000000001, -6.57...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.904207500000001, -5.366545714285714, -5.5...</td>\n",
       "      <td>[-6.889338261904763, -5.802596476190478, -5.51...</td>\n",
       "      <td>[0.043427997538214594, 0.23144892329983693, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-5.14220899759884, -6.6831453381864385, -5.11...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.65121140485979, -5.05463021317866, -4.927...</td>\n",
       "      <td>[-6.591644856785095, -5.169166436478891, -4.88...</td>\n",
       "      <td>[0.11335659133395465, 0.1803984337341485, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.468127256317693, -5.634489472703555, -5.63...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.565563703024749, -5.468127256317693, -5.4...</td>\n",
       "      <td>[-5.63550683719888, -5.577656242307972, -5.568...</td>\n",
       "      <td>[0.0444539065599728, 0.0636833531468969, 0.057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-8.437091, -8.210553, -6.428049, -4.702557, -...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8522077, -5.8823566, -5.266061, -6.993047...</td>\n",
       "      <td>[-6.8898225, -6.0707283, -5.294844, -6.246085,...</td>\n",
       "      <td>[0.090542756, 0.21896191, 0.21398959, 0.562217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-5.555600000000003, -6.9600000000000035, -6.6...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.987200000000002, -6.240000000000006, -5.3...</td>\n",
       "      <td>[-6.99744, -6.110300000000003, -5.456930000000...</td>\n",
       "      <td>[0.005119999999999081, 0.7415917583145069, 0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.948734010075369, -6.813726583610469, -5.27...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.689984371798825, -4.526532803486631, -4.8...</td>\n",
       "      <td>[-6.7342323006033, -4.467796207798678, -4.7829...</td>\n",
       "      <td>[0.12183121057459037, 0.3111950647582891, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.603333333333333, -6.986666666666667, -6.61...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -4.513333333333333, -5.5...</td>\n",
       "      <td>[-6.952000000000001, -4.504, -5.33133333333333...</td>\n",
       "      <td>[0.05356615847093516, 0.029013406862651362, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.1420042443352685, -6.815193698706107, -4.7...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.872507555402064, -4.889444177337033, -4.6...</td>\n",
       "      <td>[-6.86148874132725, -4.929863505344455, -4.635...</td>\n",
       "      <td>[0.039694526457737696, 0.02502980312024346, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-5.997627115009501, -7.005223977969993, -5.47...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.031900514329814, -5.333153838349111, -5.2...</td>\n",
       "      <td>[-7.067541858092713, -5.528891465360111, -5.19...</td>\n",
       "      <td>[0.16631877714842672, 0.2626996200831333, 0.06...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-5.210110133447338, -6.732410735254416, -5.75...   \n",
       "1   [-5.62, -6.96, -6.6225, -4.7775, -6.6225, -4.2...   \n",
       "2   [-5.995883333333333, -6.912300000000001, -6.57...   \n",
       "3   [-5.14220899759884, -6.6831453381864385, -5.11...   \n",
       "4   [-5.468127256317693, -5.634489472703555, -5.63...   \n",
       "5   [-8.437091, -8.210553, -6.428049, -4.702557, -...   \n",
       "6   [-5.555600000000003, -6.9600000000000035, -6.6...   \n",
       "7   [-5.948734010075369, -6.813726583610469, -5.27...   \n",
       "8   [-5.603333333333333, -6.986666666666667, -6.61...   \n",
       "9   [-5.1420042443352685, -6.815193698706107, -4.7...   \n",
       "10  [-5.997627115009501, -7.005223977969993, -5.47...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.306895107939291, -5.066698711260405, -5.2...   \n",
       "1   [[-6.96, -6.24, -5.1, -6.22, -4.8175, -6.6225,...   \n",
       "2   [[-6.904207500000001, -5.366545714285714, -5.5...   \n",
       "3   [[-6.65121140485979, -5.05463021317866, -4.927...   \n",
       "4   [[-5.565563703024749, -5.468127256317693, -5.4...   \n",
       "5   [[-6.8522077, -5.8823566, -5.266061, -6.993047...   \n",
       "6   [[-6.987200000000002, -6.240000000000006, -5.3...   \n",
       "7   [[-6.689984371798825, -4.526532803486631, -4.8...   \n",
       "8   [[-6.986666666666667, -4.513333333333333, -5.5...   \n",
       "9   [[-6.872507555402064, -4.889444177337033, -4.6...   \n",
       "10  [[-7.031900514329814, -5.333153838349111, -5.2...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.393563645699494, -5.3717918456608285, -5.1...   \n",
       "1   [-6.992, -6.25, -5.414, -5.822, -5.28499999999...   \n",
       "2   [-6.889338261904763, -5.802596476190478, -5.51...   \n",
       "3   [-6.591644856785095, -5.169166436478891, -4.88...   \n",
       "4   [-5.63550683719888, -5.577656242307972, -5.568...   \n",
       "5   [-6.8898225, -6.0707283, -5.294844, -6.246085,...   \n",
       "6   [-6.99744, -6.110300000000003, -5.456930000000...   \n",
       "7   [-6.7342323006033, -4.467796207798678, -4.7829...   \n",
       "8   [-6.952000000000001, -4.504, -5.33133333333333...   \n",
       "9   [-6.86148874132725, -4.929863505344455, -4.635...   \n",
       "10  [-7.067541858092713, -5.528891465360111, -5.19...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.1128025441255652, 0.1879859436716718, 0.099...  \n",
       "1   [0.016000000000000014, 0.8143218037115305, 0.8...  \n",
       "2   [0.043427997538214594, 0.23144892329983693, 0....  \n",
       "3   [0.11335659133395465, 0.1803984337341485, 0.02...  \n",
       "4   [0.0444539065599728, 0.0636833531468969, 0.057...  \n",
       "5   [0.090542756, 0.21896191, 0.21398959, 0.562217...  \n",
       "6   [0.005119999999999081, 0.7415917583145069, 0.8...  \n",
       "7   [0.12183121057459037, 0.3111950647582891, 0.06...  \n",
       "8   [0.05356615847093516, 0.029013406862651362, 0....  \n",
       "9   [0.039694526457737696, 0.02502980312024346, 0....  \n",
       "10  [0.16631877714842672, 0.2626996200831333, 0.06...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20febcb7-4d1e-4379-afd0-8529a034bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_Extended_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_Extended_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665fc304-0b52-4806-bef9-fb605de5323e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 1024)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 1024)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2259\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 753\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2259\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 753\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 761\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2247\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 749\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 760\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.3943460045042735\n",
      "0.3816944486595305\n",
      "0.39951321976568144\n",
      "0.3694771686711973\n",
      "0.013089758674744933\n",
      "0.4126161990470977\n",
      "0.37799805855253577\n",
      "0.3113140791222936\n",
      "0.26649613335725697\n",
      "0.37118141330251087\n",
      "0.32682914520613093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3892</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.6191</td>\n",
       "      <td>0.3943</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.5554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4337</td>\n",
       "      <td>0.4837</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>0.3036</td>\n",
       "      <td>0.5824</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>0.6244</td>\n",
       "      <td>0.5565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.3757</td>\n",
       "      <td>0.4643</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.3967</td>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4617</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.5581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3991</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>0.3592</td>\n",
       "      <td>0.6018</td>\n",
       "      <td>0.5012</td>\n",
       "      <td>0.3990</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.5216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.6459</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>-0.0371</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.3894</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.6408</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.4359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.4621</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>0.4012</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.3717</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.4126</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>0.5608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4243</td>\n",
       "      <td>0.4799</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>0.4657</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>0.5576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.5119</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.4894</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.4381</td>\n",
       "      <td>0.4642</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>0.5009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.4048</td>\n",
       "      <td>0.4713</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>0.5291</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.4679</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.3712</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.5469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>0.4879</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.5853</td>\n",
       "      <td>0.5254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.3804                0.4719   \n",
       "DecisionTreeRegressor                    0.4337                0.4837   \n",
       "RandomForestRegressor                    0.3757                0.4643   \n",
       "GradientBoostingRegressor                0.3991                0.4882   \n",
       "AdaBoostRegressor                        0.6459                0.6522   \n",
       "XGBRegressor                             0.3729                0.4621   \n",
       "ExtraTreesRegressor                      0.4243                0.4799   \n",
       "LinearRegression                         0.5119                0.5123   \n",
       "KNeighborsRegressor                      0.4894                0.5217   \n",
       "SVR                                      0.4048                0.4713   \n",
       "MLPRegressor                             0.4550                0.5019   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.6168               0.3892   \n",
       "DecisionTreeRegressor                     0.6586               0.3036   \n",
       "RandomForestRegressor                     0.6130               0.3967   \n",
       "GradientBoostingRegressor                 0.6318               0.3592   \n",
       "AdaBoostRegressor                         0.8037              -0.0371   \n",
       "XGBRegressor                              0.6107               0.4012   \n",
       "ExtraTreesRegressor                       0.6514               0.3188   \n",
       "LinearRegression                          0.7155               0.1781   \n",
       "KNeighborsRegressor                       0.6996               0.2142   \n",
       "SVR                                       0.6362               0.3500   \n",
       "MLPRegressor                              0.6745               0.2694   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.6241                0.5386   \n",
       "DecisionTreeRegressor                    0.5824                0.5225   \n",
       "RandomForestRegressor                    0.6313                0.5505   \n",
       "GradientBoostingRegressor                0.6018                0.5012   \n",
       "AdaBoostRegressor                        0.3715                0.3894   \n",
       "XGBRegressor                             0.6371                0.5556   \n",
       "ExtraTreesRegressor                      0.5884                0.5238   \n",
       "LinearRegression                         0.5106                0.5058   \n",
       "KNeighborsRegressor                      0.5207                0.4381   \n",
       "SVR                                      0.6004                0.5291   \n",
       "MLPRegressor                             0.5580                0.4952   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.3833   0.4733    0.6191  0.3943   \n",
       "DecisionTreeRegressor       0.3913   0.4632    0.6255  0.3817   \n",
       "RandomForestRegressor       0.3800   0.4617    0.6164  0.3995   \n",
       "GradientBoostingRegressor   0.3990   0.4880    0.6317  0.3695   \n",
       "AdaBoostRegressor           0.6245   0.6408    0.7903  0.0131   \n",
       "XGBRegressor                0.3717   0.4607    0.6097  0.4126   \n",
       "ExtraTreesRegressor         0.3936   0.4657    0.6274  0.3780   \n",
       "LinearRegression            0.4358   0.4921    0.6602  0.3113   \n",
       "KNeighborsRegressor         0.4642   0.5031    0.6813  0.2665   \n",
       "SVR                         0.3979   0.4679    0.6308  0.3712   \n",
       "MLPRegressor                0.4260   0.4879    0.6527  0.3268   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.6286                    0.5554  \n",
       "DecisionTreeRegressor                       0.6244                    0.5565  \n",
       "RandomForestRegressor                       0.6332                    0.5581  \n",
       "GradientBoostingRegressor                   0.6111                    0.5216  \n",
       "AdaBoostRegressor                           0.3984                    0.4359  \n",
       "XGBRegressor                                0.6438                    0.5608  \n",
       "ExtraTreesRegressor                         0.6212                    0.5576  \n",
       "LinearRegression                            0.5763                    0.5419  \n",
       "KNeighborsRegressor                         0.5532                    0.5009  \n",
       "SVR                                         0.6192                    0.5469  \n",
       "MLPRegressor                                0.5853                    0.5254  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fingerprinter fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/Fingerprinter_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/Fingerprinter_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_fingerprinter_fp , pred_df= train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_fingerprinter_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e07543-9f56-4711-b517-8d6032c1a28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-5.054572681655, -6.498864242733969, -5.10971...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.984784757982033, -4.523138670409128, -4.8...</td>\n",
       "      <td>[-6.077116474019431, -4.563319534313782, -4.85...</td>\n",
       "      <td>[0.14157114227210232, 0.03236298861371521, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.0, -6.96, -5.195000000000001, -4.7775, -5....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.48, -5.12, -5.11, -6.24, -5.1950000...</td>\n",
       "      <td>[-7.0, -4.565666666666667, -5.006, -6.822, -5....</td>\n",
       "      <td>[0.0, 0.107215255962531, 0.22800000000000012, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-5.886728888888889, -6.684092261904763, -5.17...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9537, -4.707901666666669, -5.025090238095...</td>\n",
       "      <td>[-6.929163690476192, -4.706269619047621, -4.92...</td>\n",
       "      <td>[0.0493991578605901, 0.12587772817088766, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-4.795584112293573, -6.479001950247324, -4.93...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.539723264817252, -4.778989000466205, -4.9...</td>\n",
       "      <td>[-6.356125430113132, -4.690042410014629, -4.88...</td>\n",
       "      <td>[0.13700210981899594, 0.07373326102932107, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.553678743404556, -5.707758770030314, -5.55...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.553678743404556, -5.553678743404556, -5.5...</td>\n",
       "      <td>[-5.578832213830941, -5.528423399553221, -5.53...</td>\n",
       "      <td>[0.16351682940867196, 0.13310204129271813, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.1767316, -6.774272, -5.1184177, -4.702109,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8874984, -4.5139947, -4.8827777, -5.59299...</td>\n",
       "      <td>[-6.832596, -4.6126914, -4.820067, -5.5934353,...</td>\n",
       "      <td>[0.04431113, 0.15006681, 0.08276358, 0.2412836...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-7.0, -6.9808, -5.194999999999996, -4.7774999...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.563699999999996, -5.120000000000004...</td>\n",
       "      <td>[-7.0, -4.545156666666668, -5.006000000000006,...</td>\n",
       "      <td>[0.0, 0.04971281703723252, 0.22799999999999834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.951929047744257, -6.0598687335401795, -5.2...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.055713588220685, -6.239593214737146, -4.9...</td>\n",
       "      <td>[-6.258447300575504, -5.205028587320231, -4.94...</td>\n",
       "      <td>[0.11993299326332864, 0.8575980679739353, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.603333333333333, -6.986666666666667, -6.49...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.2299999999999995, -5.52666666666666...</td>\n",
       "      <td>[-6.954666666666666, -5.053333333333333, -4.84...</td>\n",
       "      <td>[0.055521767503085344, 0.29412015685203635, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.960774021146256, -6.787210065738998, -4.75...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.83383133007565, -5.133982955754157, -4.68...</td>\n",
       "      <td>[-6.808664480496785, -5.141173652418784, -4.66...</td>\n",
       "      <td>[0.05392850097076415, 0.0963717167346493, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-5.4830721791909065, -6.215636161445098, -5.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.55194158711032, -3.9025156401405585, -4.9...</td>\n",
       "      <td>[-6.733240509609334, -3.960377015486086, -5.01...</td>\n",
       "      <td>[0.09485808593337328, 0.09648827371555332, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-5.054572681655, -6.498864242733969, -5.10971...   \n",
       "1   [-7.0, -6.96, -5.195000000000001, -4.7775, -5....   \n",
       "2   [-5.886728888888889, -6.684092261904763, -5.17...   \n",
       "3   [-4.795584112293573, -6.479001950247324, -4.93...   \n",
       "4   [-5.553678743404556, -5.707758770030314, -5.55...   \n",
       "5   [-6.1767316, -6.774272, -5.1184177, -4.702109,...   \n",
       "6   [-7.0, -6.9808, -5.194999999999996, -4.7774999...   \n",
       "7   [-5.951929047744257, -6.0598687335401795, -5.2...   \n",
       "8   [-5.603333333333333, -6.986666666666667, -6.49...   \n",
       "9   [-4.960774021146256, -6.787210065738998, -4.75...   \n",
       "10  [-5.4830721791909065, -6.215636161445098, -5.1...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-5.984784757982033, -4.523138670409128, -4.8...   \n",
       "1   [[-7.0, -4.48, -5.12, -5.11, -6.24, -5.1950000...   \n",
       "2   [[-6.9537, -4.707901666666669, -5.025090238095...   \n",
       "3   [[-6.539723264817252, -4.778989000466205, -4.9...   \n",
       "4   [[-5.553678743404556, -5.553678743404556, -5.5...   \n",
       "5   [[-6.8874984, -4.5139947, -4.8827777, -5.59299...   \n",
       "6   [[-7.0, -4.563699999999996, -5.120000000000004...   \n",
       "7   [[-6.055713588220685, -6.239593214737146, -4.9...   \n",
       "8   [[-7.0, -5.2299999999999995, -5.52666666666666...   \n",
       "9   [[-6.83383133007565, -5.133982955754157, -4.68...   \n",
       "10  [[-6.55194158711032, -3.9025156401405585, -4.9...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.077116474019431, -4.563319534313782, -4.85...   \n",
       "1   [-7.0, -4.565666666666667, -5.006, -6.822, -5....   \n",
       "2   [-6.929163690476192, -4.706269619047621, -4.92...   \n",
       "3   [-6.356125430113132, -4.690042410014629, -4.88...   \n",
       "4   [-5.578832213830941, -5.528423399553221, -5.53...   \n",
       "5   [-6.832596, -4.6126914, -4.820067, -5.5934353,...   \n",
       "6   [-7.0, -4.545156666666668, -5.006000000000006,...   \n",
       "7   [-6.258447300575504, -5.205028587320231, -4.94...   \n",
       "8   [-6.954666666666666, -5.053333333333333, -4.84...   \n",
       "9   [-6.808664480496785, -5.141173652418784, -4.66...   \n",
       "10  [-6.733240509609334, -3.960377015486086, -5.01...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.14157114227210232, 0.03236298861371521, 0.0...  \n",
       "1   [0.0, 0.107215255962531, 0.22800000000000012, ...  \n",
       "2   [0.0493991578605901, 0.12587772817088766, 0.12...  \n",
       "3   [0.13700210981899594, 0.07373326102932107, 0.0...  \n",
       "4   [0.16351682940867196, 0.13310204129271813, 0.1...  \n",
       "5   [0.04431113, 0.15006681, 0.08276358, 0.2412836...  \n",
       "6   [0.0, 0.04971281703723252, 0.22799999999999834...  \n",
       "7   [0.11993299326332864, 0.8575980679739353, 0.07...  \n",
       "8   [0.055521767503085344, 0.29412015685203635, 0....  \n",
       "9   [0.05392850097076415, 0.0963717167346493, 0.02...  \n",
       "10  [0.09485808593337328, 0.09648827371555332, 0.0...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbadf989-7318-4702-8266-01cec19fa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fingerprinter_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_Fingerprinter_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_Fingerprinter_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f317713-a346-47b5-82a9-ae3a643e5147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 1024)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 1024)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1272\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1266\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 422\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1281\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 427\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1254\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 418\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1254\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 418\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.34129213874557085\n",
      "0.3272198816008165\n",
      "0.34776215152830636\n",
      "0.3263857084085311\n",
      "0.17569363338224953\n",
      "0.3414285802092967\n",
      "0.3302588742698065\n",
      "0.28031793967211716\n",
      "0.07691896840994839\n",
      "0.30913540647718896\n",
      "0.2940673290066429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.4022</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.6342</td>\n",
       "      <td>0.3541</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.5063</td>\n",
       "      <td>0.4168</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.6456</td>\n",
       "      <td>0.3413</td>\n",
       "      <td>0.5844</td>\n",
       "      <td>0.5085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4247</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.3181</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.4765</td>\n",
       "      <td>0.6291</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.4128</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.6425</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.5184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.5751</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.4263</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.3264</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.4872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.1757</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.4779</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.6010</td>\n",
       "      <td>0.5051</td>\n",
       "      <td>0.4168</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.6456</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.5864</td>\n",
       "      <td>0.5197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.4847</td>\n",
       "      <td>0.6448</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.5869</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.4238</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4682</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.2483</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.4554</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.4836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.5611</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.7490</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.4306</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>0.5842</td>\n",
       "      <td>0.5658</td>\n",
       "      <td>0.7643</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.3517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.4372</td>\n",
       "      <td>0.4838</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>0.5682</td>\n",
       "      <td>0.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.5136</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.2408</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.4597</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>0.5524</td>\n",
       "      <td>0.5032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.4022                0.4832   \n",
       "DecisionTreeRegressor                    0.4247                0.4875   \n",
       "RandomForestRegressor                    0.3957                0.4765   \n",
       "GradientBoostingRegressor                0.4182                0.4950   \n",
       "AdaBoostRegressor                        0.5466                0.5924   \n",
       "XGBRegressor                             0.4004                0.4779   \n",
       "ExtraTreesRegressor                      0.4157                0.4847   \n",
       "LinearRegression                         0.4682                0.5086   \n",
       "KNeighborsRegressor                      0.5611                0.5645   \n",
       "SVR                                      0.4335                0.4835   \n",
       "MLPRegressor                             0.4728                0.5136   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.6342               0.3541   \n",
       "DecisionTreeRegressor                     0.6517               0.3181   \n",
       "RandomForestRegressor                     0.6291               0.3646   \n",
       "GradientBoostingRegressor                 0.6467               0.3286   \n",
       "AdaBoostRegressor                         0.7393               0.1224   \n",
       "XGBRegressor                              0.6328               0.3571   \n",
       "ExtraTreesRegressor                       0.6448               0.3325   \n",
       "LinearRegression                          0.6842               0.2483   \n",
       "KNeighborsRegressor                       0.7490               0.0991   \n",
       "SVR                                       0.6584               0.3039   \n",
       "MLPRegressor                              0.6876               0.2408   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.5951                0.5063   \n",
       "DecisionTreeRegressor                    0.5775                0.4916   \n",
       "RandomForestRegressor                    0.6054                0.5093   \n",
       "GradientBoostingRegressor                0.5751                0.4720   \n",
       "AdaBoostRegressor                        0.4396                0.3900   \n",
       "XGBRegressor                             0.6010                0.5051   \n",
       "ExtraTreesRegressor                      0.5869                0.4949   \n",
       "LinearRegression                         0.5241                0.4685   \n",
       "KNeighborsRegressor                      0.4306                0.3397   \n",
       "SVR                                      0.5620                0.4759   \n",
       "MLPRegressor                             0.5222                0.4597   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.4168   0.4912    0.6456  0.3413   \n",
       "DecisionTreeRegressor       0.4258   0.4865    0.6525  0.3272   \n",
       "RandomForestRegressor       0.4128   0.4822    0.6425  0.3478   \n",
       "GradientBoostingRegressor   0.4263   0.5003    0.6529  0.3264   \n",
       "AdaBoostRegressor           0.5216   0.5829    0.7222  0.1757   \n",
       "XGBRegressor                0.4168   0.4845    0.6456  0.3414   \n",
       "ExtraTreesRegressor         0.4238   0.4862    0.6510  0.3303   \n",
       "LinearRegression            0.4554   0.5050    0.6749  0.2803   \n",
       "KNeighborsRegressor         0.5842   0.5658    0.7643  0.0769   \n",
       "SVR                         0.4372   0.4838    0.6612  0.3091   \n",
       "MLPRegressor                0.4467   0.5006    0.6684  0.2941   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.5844                    0.5085  \n",
       "DecisionTreeRegressor                       0.5771                    0.5123  \n",
       "RandomForestRegressor                       0.5910                    0.5184  \n",
       "GradientBoostingRegressor                   0.5743                    0.4872  \n",
       "AdaBoostRegressor                           0.4931                    0.4354  \n",
       "XGBRegressor                                0.5864                    0.5197  \n",
       "ExtraTreesRegressor                         0.5794                    0.5156  \n",
       "LinearRegression                            0.5401                    0.4836  \n",
       "KNeighborsRegressor                         0.4018                    0.3517  \n",
       "SVR                                         0.5682                    0.4905  \n",
       "MLPRegressor                                0.5524                    0.5032  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GraphOnly fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/Graphonly_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/Graphonly_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_graph_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_graph_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d07b626-865b-44b0-92ba-026fc8c2595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-4.953915252662118, -6.534657041656787, -5.20...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.4284853052792155, -4.8871405470605325, -5...</td>\n",
       "      <td>[-6.435023660987748, -5.132642583665913, -5.17...</td>\n",
       "      <td>[0.07102059602735827, 0.18058381583927116, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-4.805, -7.0, -5.248281250000002, -4.77324999...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.805, -5.248281250000002, -4.82, -5....</td>\n",
       "      <td>[-7.0, -6.561, -5.220977855716688, -6.128, -5....</td>\n",
       "      <td>[0.0, 0.8780000000000002, 0.051497376799151964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-5.124944924103675, -6.939516666666666, -5.22...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.03771311036186, -5.228100325386871,...</td>\n",
       "      <td>[-6.982614816738817, -6.010645198606949, -5.22...</td>\n",
       "      <td>[0.017367788612230053, 0.4937020010792809, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-5.060024743824091, -6.954386865212181, -4.96...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.488638530497739, -5.0475861307519505, -4....</td>\n",
       "      <td>[-6.373596669806568, -5.3743225058336375, -4.9...</td>\n",
       "      <td>[0.10903766030959725, 0.37135808648679475, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.408786610878663, -5.78736170212766, -5.408...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.5266831683168425, -5.408786610878663, -5....</td>\n",
       "      <td>[-5.676293894926543, -5.347214243511325, -5.28...</td>\n",
       "      <td>[0.1809520666823292, 0.09497439950463075, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-5.5538764, -6.891533, -5.1962934, -4.789754,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.972633, -5.4913654, -5.1962934, -6.207151...</td>\n",
       "      <td>[-7.012512, -6.2977157, -5.169132, -6.043078, ...</td>\n",
       "      <td>[0.028772052, 0.40571493, 0.04417925, 0.246743...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-4.805000000000006, -7.0, -5.2482812499999945...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.805000000000006, -5.248281249999994...</td>\n",
       "      <td>[-7.0, -6.561000000000002, -5.220977855716685,...</td>\n",
       "      <td>[0.0, 0.8779999999999976, 0.051497376799150944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.411188695740503, -7.13582012514197, -5.141...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.755509851716345, -5.144603493984921, -5.1...</td>\n",
       "      <td>[-6.777083000237599, -4.960357065903923, -5.10...</td>\n",
       "      <td>[0.0525503901938067, 0.1418246031652898, 0.031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.1933333333333325, -6.986666666666667, -7.0...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.420000000000001, -7.0, -5.383333333...</td>\n",
       "      <td>[-7.0, -4.689333333333334, -7.0, -5.4773333333...</td>\n",
       "      <td>[0.0, 0.3536313208853409, 0.0, 0.1582459407939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.7998455359027155, -6.993772097541642, -4.7...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.900064672563355, -4.6938019928885435, -4....</td>\n",
       "      <td>[-6.889847920561131, -4.702268844924371, -4.72...</td>\n",
       "      <td>[0.020262504649472365, 0.03774984528325181, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-5.284653613679783, -7.360141197537246, -5.14...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.813149330666522, -4.936590090091385, -5.1...</td>\n",
       "      <td>[-6.898813403197424, -5.03047094874536, -5.089...</td>\n",
       "      <td>[0.07610650103764482, 0.1718351459457838, 0.06...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-4.953915252662118, -6.534657041656787, -5.20...   \n",
       "1   [-4.805, -7.0, -5.248281250000002, -4.77324999...   \n",
       "2   [-5.124944924103675, -6.939516666666666, -5.22...   \n",
       "3   [-5.060024743824091, -6.954386865212181, -4.96...   \n",
       "4   [-5.408786610878663, -5.78736170212766, -5.408...   \n",
       "5   [-5.5538764, -6.891533, -5.1962934, -4.789754,...   \n",
       "6   [-4.805000000000006, -7.0, -5.2482812499999945...   \n",
       "7   [-5.411188695740503, -7.13582012514197, -5.141...   \n",
       "8   [-5.1933333333333325, -6.986666666666667, -7.0...   \n",
       "9   [-4.7998455359027155, -6.993772097541642, -4.7...   \n",
       "10  [-5.284653613679783, -7.360141197537246, -5.14...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.4284853052792155, -4.8871405470605325, -5...   \n",
       "1   [[-7.0, -4.805, -5.248281250000002, -4.82, -5....   \n",
       "2   [[-7.0, -5.03771311036186, -5.228100325386871,...   \n",
       "3   [[-6.488638530497739, -5.0475861307519505, -4....   \n",
       "4   [[-5.5266831683168425, -5.408786610878663, -5....   \n",
       "5   [[-6.972633, -5.4913654, -5.1962934, -6.207151...   \n",
       "6   [[-7.0, -4.805000000000006, -5.248281249999994...   \n",
       "7   [[-6.755509851716345, -5.144603493984921, -5.1...   \n",
       "8   [[-7.0, -4.420000000000001, -7.0, -5.383333333...   \n",
       "9   [[-6.900064672563355, -4.6938019928885435, -4....   \n",
       "10  [[-6.813149330666522, -4.936590090091385, -5.1...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.435023660987748, -5.132642583665913, -5.17...   \n",
       "1   [-7.0, -6.561, -5.220977855716688, -6.128, -5....   \n",
       "2   [-6.982614816738817, -6.010645198606949, -5.22...   \n",
       "3   [-6.373596669806568, -5.3743225058336375, -4.9...   \n",
       "4   [-5.676293894926543, -5.347214243511325, -5.28...   \n",
       "5   [-7.012512, -6.2977157, -5.169132, -6.043078, ...   \n",
       "6   [-7.0, -6.561000000000002, -5.220977855716685,...   \n",
       "7   [-6.777083000237599, -4.960357065903923, -5.10...   \n",
       "8   [-7.0, -4.689333333333334, -7.0, -5.4773333333...   \n",
       "9   [-6.889847920561131, -4.702268844924371, -4.72...   \n",
       "10  [-6.898813403197424, -5.03047094874536, -5.089...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.07102059602735827, 0.18058381583927116, 0.0...  \n",
       "1   [0.0, 0.8780000000000002, 0.051497376799151964...  \n",
       "2   [0.017367788612230053, 0.4937020010792809, 0.0...  \n",
       "3   [0.10903766030959725, 0.37135808648679475, 0.0...  \n",
       "4   [0.1809520666823292, 0.09497439950463075, 0.14...  \n",
       "5   [0.028772052, 0.40571493, 0.04417925, 0.246743...  \n",
       "6   [0.0, 0.8779999999999976, 0.051497376799150944...  \n",
       "7   [0.0525503901938067, 0.1418246031652898, 0.031...  \n",
       "8   [0.0, 0.3536313208853409, 0.0, 0.1582459407939...  \n",
       "9   [0.020262504649472365, 0.03774984528325181, 0....  \n",
       "10  [0.07610650103764482, 0.1718351459457838, 0.06...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38669406-3c42-4078-9613-120ee64b1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_Graphonly_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_Graphonly_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db94888-dc6d-4bf8-84cb-eacf13a56c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 4860)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 4860)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 280\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 296\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 921\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 307\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 900\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 297\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5198390093948186\n",
      "0.4882746222803809\n",
      "0.535259358979113\n",
      "0.46328178032353706\n",
      "0.21165880717483299\n",
      "0.5439631465278828\n",
      "0.4862822882356771\n",
      "0.410708691313036\n",
      "0.3911493846159053\n",
      "0.49735507541700474\n",
      "0.522910524969116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2945</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.5272</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.5512</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.6930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3707</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.6088</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.6675</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.6905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2844</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.7373</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.4603</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.6582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>0.4989</td>\n",
       "      <td>0.5676</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.5393</td>\n",
       "      <td>0.5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.3893</td>\n",
       "      <td>0.5231</td>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.7491</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.7379</td>\n",
       "      <td>0.7089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4221</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.4277</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.4086</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.6911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3829</td>\n",
       "      <td>0.4566</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.3852</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.4497</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.6445</td>\n",
       "      <td>0.6417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3777</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.6145</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.3911</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.6194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3191</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.4877</td>\n",
       "      <td>0.7027</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>0.3181</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.6886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.4131</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.6767</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2945                0.4061   \n",
       "DecisionTreeRegressor                    0.3707                0.4267   \n",
       "RandomForestRegressor                    0.2844                0.3957   \n",
       "GradientBoostingRegressor                0.3361                0.4394   \n",
       "AdaBoostRegressor                        0.5221                0.5800   \n",
       "XGBRegressor                             0.2736                0.3893   \n",
       "ExtraTreesRegressor                      0.3564                0.4221   \n",
       "LinearRegression                         0.3829                0.4566   \n",
       "KNeighborsRegressor                      0.3777                0.4540   \n",
       "SVR                                      0.3191                0.4130   \n",
       "MLPRegressor                             0.3297                0.4131   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.5427               0.5272   \n",
       "DecisionTreeRegressor                     0.6088               0.4049   \n",
       "RandomForestRegressor                     0.5332               0.5434   \n",
       "GradientBoostingRegressor                 0.5797               0.4603   \n",
       "AdaBoostRegressor                         0.7225               0.1618   \n",
       "XGBRegressor                              0.5231               0.5607   \n",
       "ExtraTreesRegressor                       0.5970               0.4277   \n",
       "LinearRegression                          0.6188               0.3852   \n",
       "KNeighborsRegressor                       0.6145               0.3936   \n",
       "SVR                                       0.5649               0.4877   \n",
       "MLPRegressor                              0.5742               0.4706   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7273                0.6904   \n",
       "DecisionTreeRegressor                    0.6675                0.6482   \n",
       "RandomForestRegressor                    0.7373                0.7043   \n",
       "GradientBoostingRegressor                0.6832                0.6383   \n",
       "AdaBoostRegressor                        0.4970                0.4473   \n",
       "XGBRegressor                             0.7491                0.7086   \n",
       "ExtraTreesRegressor                      0.6779                0.6543   \n",
       "LinearRegression                         0.6295                0.6179   \n",
       "KNeighborsRegressor                      0.6424                0.5912   \n",
       "SVR                                      0.7027                0.6689   \n",
       "MLPRegressor                             0.6980                0.6767   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.3039   0.4100    0.5512  0.5198   \n",
       "DecisionTreeRegressor       0.3238   0.4080    0.5691  0.4883   \n",
       "RandomForestRegressor       0.2941   0.3964    0.5423  0.5353   \n",
       "GradientBoostingRegressor   0.3397   0.4408    0.5828  0.4633   \n",
       "AdaBoostRegressor           0.4989   0.5676    0.7063  0.2117   \n",
       "XGBRegressor                0.2886   0.3958    0.5372  0.5440   \n",
       "ExtraTreesRegressor         0.3251   0.4086    0.5702  0.4863   \n",
       "LinearRegression            0.3729   0.4497    0.6107  0.4107   \n",
       "KNeighborsRegressor         0.3853   0.4486    0.6207  0.3911   \n",
       "SVR                         0.3181   0.4081    0.5640  0.4974   \n",
       "MLPRegressor                0.3019   0.3972    0.5495  0.5229   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7221                    0.6930  \n",
       "DecisionTreeRegressor                       0.7065                    0.6905  \n",
       "RandomForestRegressor                       0.7320                    0.7098  \n",
       "GradientBoostingRegressor                   0.6860                    0.6582  \n",
       "AdaBoostRegressor                           0.5393                    0.5001  \n",
       "XGBRegressor                                0.7379                    0.7089  \n",
       "ExtraTreesRegressor                         0.7051                    0.6911  \n",
       "LinearRegression                            0.6445                    0.6417  \n",
       "KNeighborsRegressor                         0.6399                    0.6194  \n",
       "SVR                                         0.7096                    0.6886  \n",
       "MLPRegressor                                0.7271                    0.7073  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KlekotaRoth fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/KlekotaRoth_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/KlekotaRoth_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_KlekotaRoth_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_KlekotaRoth_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66ed29e-31a6-4fd8-bffb-2376dcd069dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-5.054157956992978, -6.191867230360358, -4.99...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.671025641441484, -4.807873362339619, -5.4...</td>\n",
       "      <td>[-6.771761707721355, -5.000511410197683, -5.44...</td>\n",
       "      <td>[0.13300900164476903, 0.1367893260281191, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-4.7, -7.0, -4.47, -4.39, -4.515000000000001,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.375, -4.32, -5.89, -6.24, -4.39, -5...</td>\n",
       "      <td>[-6.83, -5.279, -5.092, -5.856285714285714, -6...</td>\n",
       "      <td>[0.10751744044572485, 0.5544132033059818, 0.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-5.25398357142857, -6.6502166666666644, -4.97...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.5613666666666655, -4.944375000000001, -5....</td>\n",
       "      <td>[-6.751495666666666, -5.051986380952381, -5.25...</td>\n",
       "      <td>[0.09923777935175039, 0.190504641207495, 0.071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-4.998103122591567, -6.446859134215356, -4.96...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.570759711248891, -4.891553504666785, -5.1...</td>\n",
       "      <td>[-6.6718231677083155, -4.910190983485441, -5.0...</td>\n",
       "      <td>[0.05875599376040858, 0.0510377511978016, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.6070818505338025, -5.7097874720357895, -5....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.718568456096558, -5.568749109052049, -5.6...</td>\n",
       "      <td>[-5.711732031063603, -5.497269322083481, -5.62...</td>\n",
       "      <td>[0.05624384395704462, 0.0642314943462804, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-4.9887757, -6.7772355, -5.3717394, -4.858517...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.5603876, -4.940669, -5.3446703, -6.492645...</td>\n",
       "      <td>[-7.1524444, -5.119002, -5.297551, -5.855855, ...</td>\n",
       "      <td>[0.22800697, 0.174265, 0.1335067, 0.5189332, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-4.7447999999999935, -7.0, -4.530333333333344...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -4.394800000000003, -4.319999999999994...</td>\n",
       "      <td>[-6.830000000000004, -5.166169999999999, -5.04...</td>\n",
       "      <td>[0.10751744044572457, 0.4992485949905098, 0.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.052242846561083, -6.286541960512412, -4.72...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.710505849339044, -4.978726087452911, -4.9...</td>\n",
       "      <td>[-6.739854277513606, -5.028491848594683, -4.91...</td>\n",
       "      <td>[0.06243188235852099, 0.04704168807776333, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-4.8999999999999995, -7.0, -5.626666666666666...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -5.1933333333333325, -5....</td>\n",
       "      <td>[-6.904000000000001, -5.116, -5.52, -5.6146666...</td>\n",
       "      <td>[0.04165466493816895, 0.3840856385987085, 0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.862511114721572, -6.8505754908200265, -4.6...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9099575148058445, -4.728377656062778, -4....</td>\n",
       "      <td>[-6.89439910462067, -4.770812628831248, -4.793...</td>\n",
       "      <td>[0.025300092130619876, 0.027800118025745644, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-4.960012361965677, -6.798937248348149, -4.76...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.859620280568971, -5.047775837021225, -5.2...</td>\n",
       "      <td>[-6.900464016562897, -5.120774709478227, -5.30...</td>\n",
       "      <td>[0.2579732674780649, 0.0902056721998569, 0.097...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-5.054157956992978, -6.191867230360358, -4.99...   \n",
       "1   [-4.7, -7.0, -4.47, -4.39, -4.515000000000001,...   \n",
       "2   [-5.25398357142857, -6.6502166666666644, -4.97...   \n",
       "3   [-4.998103122591567, -6.446859134215356, -4.96...   \n",
       "4   [-5.6070818505338025, -5.7097874720357895, -5....   \n",
       "5   [-4.9887757, -6.7772355, -5.3717394, -4.858517...   \n",
       "6   [-4.7447999999999935, -7.0, -4.530333333333344...   \n",
       "7   [-5.052242846561083, -6.286541960512412, -4.72...   \n",
       "8   [-4.8999999999999995, -7.0, -5.626666666666666...   \n",
       "9   [-4.862511114721572, -6.8505754908200265, -4.6...   \n",
       "10  [-4.960012361965677, -6.798937248348149, -4.76...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.671025641441484, -4.807873362339619, -5.4...   \n",
       "1   [[-7.0, -4.375, -4.32, -5.89, -6.24, -4.39, -5...   \n",
       "2   [[-6.5613666666666655, -4.944375000000001, -5....   \n",
       "3   [[-6.570759711248891, -4.891553504666785, -5.1...   \n",
       "4   [[-5.718568456096558, -5.568749109052049, -5.6...   \n",
       "5   [[-7.5603876, -4.940669, -5.3446703, -6.492645...   \n",
       "6   [[-7.0, -4.394800000000003, -4.319999999999994...   \n",
       "7   [[-6.710505849339044, -4.978726087452911, -4.9...   \n",
       "8   [[-6.986666666666667, -5.1933333333333325, -5....   \n",
       "9   [[-6.9099575148058445, -4.728377656062778, -4....   \n",
       "10  [[-6.859620280568971, -5.047775837021225, -5.2...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.771761707721355, -5.000511410197683, -5.44...   \n",
       "1   [-6.83, -5.279, -5.092, -5.856285714285714, -6...   \n",
       "2   [-6.751495666666666, -5.051986380952381, -5.25...   \n",
       "3   [-6.6718231677083155, -4.910190983485441, -5.0...   \n",
       "4   [-5.711732031063603, -5.497269322083481, -5.62...   \n",
       "5   [-7.1524444, -5.119002, -5.297551, -5.855855, ...   \n",
       "6   [-6.830000000000004, -5.166169999999999, -5.04...   \n",
       "7   [-6.739854277513606, -5.028491848594683, -4.91...   \n",
       "8   [-6.904000000000001, -5.116, -5.52, -5.6146666...   \n",
       "9   [-6.89439910462067, -4.770812628831248, -4.793...   \n",
       "10  [-6.900464016562897, -5.120774709478227, -5.30...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.13300900164476903, 0.1367893260281191, 0.06...  \n",
       "1   [0.10751744044572485, 0.5544132033059818, 0.96...  \n",
       "2   [0.09923777935175039, 0.190504641207495, 0.071...  \n",
       "3   [0.05875599376040858, 0.0510377511978016, 0.06...  \n",
       "4   [0.05624384395704462, 0.0642314943462804, 0.02...  \n",
       "5   [0.22800697, 0.174265, 0.1335067, 0.5189332, 0...  \n",
       "6   [0.10751744044572457, 0.4992485949905098, 0.98...  \n",
       "7   [0.06243188235852099, 0.04704168807776333, 0.0...  \n",
       "8   [0.04165466493816895, 0.3840856385987085, 0.33...  \n",
       "9   [0.025300092130619876, 0.027800118025745644, 0...  \n",
       "10  [0.2579732674780649, 0.0902056721998569, 0.097...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1e073c4-c53b-4c38-9f6a-409ad22ddbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KlekotaRoth_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_KlekotaRoth_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_KlekotaRoth_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccfae8cb-c4fe-4f61-84e9-e4a104ad9e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 4860)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 4860)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2839\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 339\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2886\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 355\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2936\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 366\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2902\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 359\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2896\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 356\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5996235945314838\n",
      "0.5639491507991439\n",
      "0.6048063547988829\n",
      "0.5336694862694245\n",
      "0.28189744740319556\n",
      "0.621263296122524\n",
      "0.6288701855223133\n",
      "0.43951648028515666\n",
      "0.5111765043095504\n",
      "0.556308465004117\n",
      "0.5742406614201043\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.3608</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>0.7841</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>0.3676</td>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.7753</td>\n",
       "      <td>0.7558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>0.5639</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>0.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>0.7932</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.6048</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.7656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2908</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.5392</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.2951</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.7177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.5583</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.5681</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.2819</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.5852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.3507</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.6213</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.7694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.2349</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.7933</td>\n",
       "      <td>0.7784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3724</td>\n",
       "      <td>0.4351</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.4021</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.5956</td>\n",
       "      <td>0.4395</td>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.6876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.2734</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>0.5610</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.3763</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.5563</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>0.7343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.3693</td>\n",
       "      <td>0.5231</td>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.7734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2413                0.3608   \n",
       "DecisionTreeRegressor                    0.3072                0.3847   \n",
       "RandomForestRegressor                    0.2309                0.3529   \n",
       "GradientBoostingRegressor                0.2908                0.4018   \n",
       "AdaBoostRegressor                        0.4824                0.5583   \n",
       "XGBRegressor                             0.2265                0.3475   \n",
       "ExtraTreesRegressor                      0.2261                0.3491   \n",
       "LinearRegression                         0.3724                0.4351   \n",
       "KNeighborsRegressor                      0.3143                0.4077   \n",
       "SVR                                      0.2734                0.3721   \n",
       "MLPRegressor                             0.2736                0.3693   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.4912               0.6126   \n",
       "DecisionTreeRegressor                     0.5542               0.5068   \n",
       "RandomForestRegressor                     0.4806               0.6292   \n",
       "GradientBoostingRegressor                 0.5392               0.5331   \n",
       "AdaBoostRegressor                         0.6946               0.2254   \n",
       "XGBRegressor                              0.4760               0.6363   \n",
       "ExtraTreesRegressor                       0.4754               0.6370   \n",
       "LinearRegression                          0.6102               0.4021   \n",
       "KNeighborsRegressor                       0.5606               0.4954   \n",
       "SVR                                       0.5229               0.5610   \n",
       "MLPRegressor                              0.5231               0.5607   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7841                0.7550   \n",
       "DecisionTreeRegressor                    0.7319                0.7166   \n",
       "RandomForestRegressor                    0.7932                0.7677   \n",
       "GradientBoostingRegressor                0.7368                0.6996   \n",
       "AdaBoostRegressor                        0.5681                0.5331   \n",
       "XGBRegressor                             0.7977                0.7696   \n",
       "ExtraTreesRegressor                      0.7985                0.7724   \n",
       "LinearRegression                         0.6440                0.6553   \n",
       "KNeighborsRegressor                      0.7155                0.6774   \n",
       "SVR                                      0.7525                0.7299   \n",
       "MLPRegressor                             0.7602                0.7439   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2534   0.3676    0.5034  0.5996   \n",
       "DecisionTreeRegressor       0.2759   0.3663    0.5253  0.5639   \n",
       "RandomForestRegressor       0.2501   0.3568    0.5001  0.6048   \n",
       "GradientBoostingRegressor   0.2951   0.4018    0.5432  0.5337   \n",
       "AdaBoostRegressor           0.4544   0.5399    0.6741  0.2819   \n",
       "XGBRegressor                0.2397   0.3507    0.4896  0.6213   \n",
       "ExtraTreesRegressor         0.2349   0.3469    0.4846  0.6289   \n",
       "LinearRegression            0.3547   0.4320    0.5956  0.4395   \n",
       "KNeighborsRegressor         0.3093   0.3975    0.5562  0.5112   \n",
       "SVR                         0.2808   0.3763    0.5299  0.5563   \n",
       "MLPRegressor                0.2694   0.3613    0.5191  0.5742   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7753                    0.7558  \n",
       "DecisionTreeRegressor                       0.7558                    0.7532  \n",
       "RandomForestRegressor                       0.7778                    0.7656  \n",
       "GradientBoostingRegressor                   0.7352                    0.7177  \n",
       "AdaBoostRegressor                           0.6097                    0.5852  \n",
       "XGBRegressor                                0.7883                    0.7694  \n",
       "ExtraTreesRegressor                         0.7933                    0.7784  \n",
       "LinearRegression                            0.6658                    0.6876  \n",
       "KNeighborsRegressor                         0.7245                    0.7091  \n",
       "SVR                                         0.7482                    0.7343  \n",
       "MLPRegressor                                0.7670                    0.7734  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KlekotaRoth Count fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/KlekotaRothCount_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/KlekotaRothCount_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_KlekotaRothCount_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_KlekotaRothCount_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06d8c840-4cc9-4370-bf0c-8fe6856f6324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.467749321574162, -6.623705394182443, -6.03...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.997994065065435, -6.414553587269026, -6.6...</td>\n",
       "      <td>[-7.151885813305382, -6.434383414686645, -6.59...</td>\n",
       "      <td>[0.10518687791621008, 0.09254534494622917, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-6.24, -7.0, -7.0, -5.92, -5.15, -4.77, -4.66...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.24, -7.0, -7.0, -7.0, -6.85, -6.85,...</td>\n",
       "      <td>[-7.0, -6.544, -6.992, -6.396, -6.55, -6.72399...</td>\n",
       "      <td>[0.0, 0.37232244090304295, 0.01600000000000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.7438, -6.744399999999998, -5.8691016666666...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9354, -6.635500000000003, -6.771500000000...</td>\n",
       "      <td>[-6.947020000000002, -6.666260000000001, -6.58...</td>\n",
       "      <td>[0.016007548219513126, 0.2029012134019893, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.202071049003006, -6.641640720602897, -5.92...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.041259866292835, -6.3513192068027395, -6....</td>\n",
       "      <td>[-7.193116589281702, -6.45460379217071, -6.520...</td>\n",
       "      <td>[0.17902024313381015, 0.17779769620480668, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.924212299060027, -5.7825, -5.5120925553320...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.013020134228188, -5.7825, -6.313392857142...</td>\n",
       "      <td>[-6.087702445289085, -5.952852035526168, -6.03...</td>\n",
       "      <td>[0.12180299989279732, 0.1752146039696586, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.845116, -7.122616, -6.7358203, -5.44078, -...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.35293, -6.4759326, -6.990032, -6.873097, ...</td>\n",
       "      <td>[-7.1894617, -6.592904, -7.009122, -6.560726, ...</td>\n",
       "      <td>[0.15143919, 0.22919108, 0.16092433, 0.3625372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.68525, -6.868299999999998, -6.104550000000...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9965, -6.590400000000002, -6.747699999999...</td>\n",
       "      <td>[-6.984440000000001, -6.703900000000002, -6.76...</td>\n",
       "      <td>[0.009708470528357894, 0.19671736069803109, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.137564542377576, -6.486956505415558, -4.77...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.013549403470219, -5.309797517213946, -5.1...</td>\n",
       "      <td>[-6.148902608428957, -5.356094111390378, -5.13...</td>\n",
       "      <td>[0.10358448414094945, 0.06061241747474251, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-4.8999999999999995, -7.0, -5.62, -5.55, -4.6...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -5.1933333333333325, -6....</td>\n",
       "      <td>[-6.989333333333333, -5.575999999999999, -6.40...</td>\n",
       "      <td>[0.005333333333333102, 0.21866666666666723, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.205489354598905, -6.808520423147991, -5.30...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.324567888746655, -6.158299009403002, -6.7...</td>\n",
       "      <td>[-7.252162203523644, -6.317877420641227, -6.69...</td>\n",
       "      <td>[0.07803546764939835, 0.0996689552576794, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-7.151911308075067, -6.8722710732492205, -6.4...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-8.605189913511628, -6.9028239624130565, -8....</td>\n",
       "      <td>[-8.401591519026708, -6.80420707043425, -7.756...</td>\n",
       "      <td>[0.34370575535192516, 0.3733238416545241, 0.28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.467749321574162, -6.623705394182443, -6.03...   \n",
       "1   [-6.24, -7.0, -7.0, -5.92, -5.15, -4.77, -4.66...   \n",
       "2   [-6.7438, -6.744399999999998, -5.8691016666666...   \n",
       "3   [-6.202071049003006, -6.641640720602897, -5.92...   \n",
       "4   [-5.924212299060027, -5.7825, -5.5120925553320...   \n",
       "5   [-6.845116, -7.122616, -6.7358203, -5.44078, -...   \n",
       "6   [-6.68525, -6.868299999999998, -6.104550000000...   \n",
       "7   [-5.137564542377576, -6.486956505415558, -4.77...   \n",
       "8   [-4.8999999999999995, -7.0, -5.62, -5.55, -4.6...   \n",
       "9   [-6.205489354598905, -6.808520423147991, -5.30...   \n",
       "10  [-7.151911308075067, -6.8722710732492205, -6.4...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.997994065065435, -6.414553587269026, -6.6...   \n",
       "1   [[-7.0, -6.24, -7.0, -7.0, -7.0, -6.85, -6.85,...   \n",
       "2   [[-6.9354, -6.635500000000003, -6.771500000000...   \n",
       "3   [[-7.041259866292835, -6.3513192068027395, -6....   \n",
       "4   [[-6.013020134228188, -5.7825, -6.313392857142...   \n",
       "5   [[-7.35293, -6.4759326, -6.990032, -6.873097, ...   \n",
       "6   [[-6.9965, -6.590400000000002, -6.747699999999...   \n",
       "7   [[-6.013549403470219, -5.309797517213946, -5.1...   \n",
       "8   [[-6.986666666666667, -5.1933333333333325, -6....   \n",
       "9   [[-7.324567888746655, -6.158299009403002, -6.7...   \n",
       "10  [[-8.605189913511628, -6.9028239624130565, -8....   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.151885813305382, -6.434383414686645, -6.59...   \n",
       "1   [-7.0, -6.544, -6.992, -6.396, -6.55, -6.72399...   \n",
       "2   [-6.947020000000002, -6.666260000000001, -6.58...   \n",
       "3   [-7.193116589281702, -6.45460379217071, -6.520...   \n",
       "4   [-6.087702445289085, -5.952852035526168, -6.03...   \n",
       "5   [-7.1894617, -6.592904, -7.009122, -6.560726, ...   \n",
       "6   [-6.984440000000001, -6.703900000000002, -6.76...   \n",
       "7   [-6.148902608428957, -5.356094111390378, -5.13...   \n",
       "8   [-6.989333333333333, -5.575999999999999, -6.40...   \n",
       "9   [-7.252162203523644, -6.317877420641227, -6.69...   \n",
       "10  [-8.401591519026708, -6.80420707043425, -7.756...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.10518687791621008, 0.09254534494622917, 0.1...  \n",
       "1   [0.0, 0.37232244090304295, 0.01600000000000001...  \n",
       "2   [0.016007548219513126, 0.2029012134019893, 0.1...  \n",
       "3   [0.17902024313381015, 0.17779769620480668, 0.1...  \n",
       "4   [0.12180299989279732, 0.1752146039696586, 0.25...  \n",
       "5   [0.15143919, 0.22919108, 0.16092433, 0.3625372...  \n",
       "6   [0.009708470528357894, 0.19671736069803109, 0....  \n",
       "7   [0.10358448414094945, 0.06061241747474251, 0.0...  \n",
       "8   [0.005333333333333102, 0.21866666666666723, 0....  \n",
       "9   [0.07803546764939835, 0.0996689552576794, 0.06...  \n",
       "10  [0.34370575535192516, 0.3733238416545241, 0.28...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a318fc66-c4c4-43c6-934b-ea22aaaa1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KlekotaRothCount_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_KlekotaRoth_Count_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_KlekotaRoth_Count_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6c9cf8d-858d-4362-9f14-3c45f4a6508c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 166)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 166)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 240\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 243\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 243\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 243\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 243\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.4416788374678461\n",
      "0.4396820179229245\n",
      "0.46164977117809014\n",
      "0.40476432820922537\n",
      "0.14954572445935377\n",
      "0.45324125409938887\n",
      "0.4424216338542787\n",
      "0.3269057122448473\n",
      "0.11979230647610706\n",
      "0.39958234805313597\n",
      "0.4155622999938905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.4417</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3924</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.6273</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.4322</td>\n",
       "      <td>0.5955</td>\n",
       "      <td>0.4397</td>\n",
       "      <td>0.6664</td>\n",
       "      <td>0.6539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.3541</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.3407</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.6608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3798</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0.3901</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.5999</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.4048</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>0.6189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5675</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.4445</td>\n",
       "      <td>0.4238</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>0.7336</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.3528</td>\n",
       "      <td>0.4338</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.6617</td>\n",
       "      <td>0.6367</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.3844</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>0.6339</td>\n",
       "      <td>0.6198</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.4424</td>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>0.4877</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>0.5728</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.5583</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.4526</td>\n",
       "      <td>0.4219</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.7463</td>\n",
       "      <td>0.1198</td>\n",
       "      <td>0.4587</td>\n",
       "      <td>0.4266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.6129</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4337</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.3996</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>0.6378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3943</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>0.6279</td>\n",
       "      <td>0.3669</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.6128</td>\n",
       "      <td>0.3698</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.4156</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.6412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.3553                0.4411   \n",
       "DecisionTreeRegressor                    0.3924                0.4485   \n",
       "RandomForestRegressor                    0.3541                0.4352   \n",
       "GradientBoostingRegressor                0.3798                0.4629   \n",
       "AdaBoostRegressor                        0.5675                0.6090   \n",
       "XGBRegressor                             0.3528                0.4338   \n",
       "ExtraTreesRegressor                      0.3844                0.4460   \n",
       "LinearRegression                         0.4301                0.4888   \n",
       "KNeighborsRegressor                      0.5583                0.5356   \n",
       "SVR                                      0.3756                0.4340   \n",
       "MLPRegressor                             0.3943                0.4552   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.5961               0.4295   \n",
       "DecisionTreeRegressor                     0.6264               0.3700   \n",
       "RandomForestRegressor                     0.5951               0.4315   \n",
       "GradientBoostingRegressor                 0.6163               0.3901   \n",
       "AdaBoostRegressor                         0.7533               0.0888   \n",
       "XGBRegressor                              0.5940               0.4335   \n",
       "ExtraTreesRegressor                       0.6200               0.3827   \n",
       "LinearRegression                          0.6558               0.3095   \n",
       "KNeighborsRegressor                       0.7472               0.1035   \n",
       "SVR                                       0.6129               0.3969   \n",
       "MLPRegressor                              0.6279               0.3669   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.6556                0.6289   \n",
       "DecisionTreeRegressor                    0.6273                0.6161   \n",
       "RandomForestRegressor                    0.6594                0.6355   \n",
       "GradientBoostingRegressor                0.6283                0.5999   \n",
       "AdaBoostRegressor                        0.4445                0.4238   \n",
       "XGBRegressor                             0.6617                0.6367   \n",
       "ExtraTreesRegressor                      0.6339                0.6198   \n",
       "LinearRegression                         0.5584                0.5543   \n",
       "KNeighborsRegressor                      0.4526                0.4219   \n",
       "SVR                                      0.6373                0.6202   \n",
       "MLPRegressor                             0.6170                0.6128   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.3533   0.4429    0.5944  0.4417   \n",
       "DecisionTreeRegressor       0.3546   0.4322    0.5955  0.4397   \n",
       "RandomForestRegressor       0.3407   0.4270    0.5837  0.4616   \n",
       "GradientBoostingRegressor   0.3767   0.4604    0.6137  0.4048   \n",
       "AdaBoostRegressor           0.5382   0.5969    0.7336  0.1495   \n",
       "XGBRegressor                0.3460   0.4321    0.5882  0.4532   \n",
       "ExtraTreesRegressor         0.3529   0.4317    0.5940  0.4424   \n",
       "LinearRegression            0.4260   0.4877    0.6527  0.3269   \n",
       "KNeighborsRegressor         0.5570   0.5280    0.7463  0.1198   \n",
       "SVR                         0.3800   0.4337    0.6164  0.3996   \n",
       "MLPRegressor                0.3698   0.4454    0.6082  0.4156   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.6659                    0.6406  \n",
       "DecisionTreeRegressor                       0.6664                    0.6539  \n",
       "RandomForestRegressor                       0.6801                    0.6608  \n",
       "GradientBoostingRegressor                   0.6420                    0.6189  \n",
       "AdaBoostRegressor                           0.4976                    0.4551  \n",
       "XGBRegressor                                0.6741                    0.6652  \n",
       "ExtraTreesRegressor                         0.6681                    0.6561  \n",
       "LinearRegression                            0.5728                    0.5694  \n",
       "KNeighborsRegressor                         0.4587                    0.4266  \n",
       "SVR                                         0.6396                    0.6378  \n",
       "MLPRegressor                                0.6466                    0.6412  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MACCS fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/MACCS_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/MACCS_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_MACCS_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_MACCS_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4955277-90e5-4b2b-bde9-6bce541c01be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-4.828854615263665, -6.25409174394604, -4.782...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.25409174394604, -4.77692003777844, -5.174...</td>\n",
       "      <td>[-6.382234928074743, -4.907868998332539, -5.11...</td>\n",
       "      <td>[0.11991125078650615, 0.12036585461728498, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-4.8999999999999995, -7.0, -4.801176470588236...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.816666666666666, -5.283818181818183...</td>\n",
       "      <td>[-6.987333333333334, -5.214666666666666, -5.19...</td>\n",
       "      <td>[0.02533333333333303, 0.38978826160992697, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-4.90569964285714, -6.9707676190476215, -4.78...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.913628605824498, -5.794885079365076, -5.2...</td>\n",
       "      <td>[-6.930332289429968, -5.214396165223664, -5.19...</td>\n",
       "      <td>[0.016298820400586684, 0.3838726863050127, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-4.690342217944251, -6.29020172780605, -4.945...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.264818181643189, -4.695472454316142, -4.9...</td>\n",
       "      <td>[-6.4265646379471395, -4.7873401517700245, -4....</td>\n",
       "      <td>[0.12107986246483377, 0.04811141695798136, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.395815384615388, -5.768305531833068, -5.29...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.664646153846155, -5.395815384615388, -5.3...</td>\n",
       "      <td>[-5.591162677700295, -5.370591589523299, -5.37...</td>\n",
       "      <td>[0.179746667553664, 0.14341113076273732, 0.143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-5.044717, -6.8042765, -4.7162204, -4.8664494...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.71183, -5.2756224, -5.2298694, -6.33378, ...</td>\n",
       "      <td>[-6.8375244, -5.120825, -5.1633034, -6.16767, ...</td>\n",
       "      <td>[0.08154567, 0.15820575, 0.06364988, 0.2141117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-4.8999999999999915, -7.0, -4.801176470588242...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.81666666666667, -5.283818181818176,...</td>\n",
       "      <td>[-6.987333333333334, -5.214666666666666, -5.19...</td>\n",
       "      <td>[0.025333333333331966, 0.3897882616099315, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.783102794790144, -6.155838290302034, -5.04...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.074338701094595, -4.792171396907944, -5.0...</td>\n",
       "      <td>[-6.260375281168595, -4.832185810738035, -4.98...</td>\n",
       "      <td>[0.10079208316089719, 0.02187978401212345, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-4.8999999999999995, -6.986666666666667, -5.8...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -5.816666666666666, -7.0...</td>\n",
       "      <td>[-6.989333333333333, -5.58, -6.957333333333334...</td>\n",
       "      <td>[0.005333333333333102, 0.5033929324538081, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.706629860321147, -6.899857396741986, -4.56...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.89945879937141, -4.6295363354867245, -4.7...</td>\n",
       "      <td>[-6.893104743119852, -4.688924966011017, -4.72...</td>\n",
       "      <td>[0.0134519078867844, 0.045612497700995666, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-4.82749872350046, -6.835299626567392, -4.875...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.7340044564608545, -5.186495597585306, -5....</td>\n",
       "      <td>[-6.770479832080494, -5.184959924997299, -5.22...</td>\n",
       "      <td>[0.07738970710258487, 0.17222412348160474, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-4.828854615263665, -6.25409174394604, -4.782...   \n",
       "1   [-4.8999999999999995, -7.0, -4.801176470588236...   \n",
       "2   [-4.90569964285714, -6.9707676190476215, -4.78...   \n",
       "3   [-4.690342217944251, -6.29020172780605, -4.945...   \n",
       "4   [-5.395815384615388, -5.768305531833068, -5.29...   \n",
       "5   [-5.044717, -6.8042765, -4.7162204, -4.8664494...   \n",
       "6   [-4.8999999999999915, -7.0, -4.801176470588242...   \n",
       "7   [-4.783102794790144, -6.155838290302034, -5.04...   \n",
       "8   [-4.8999999999999995, -6.986666666666667, -5.8...   \n",
       "9   [-4.706629860321147, -6.899857396741986, -4.56...   \n",
       "10  [-4.82749872350046, -6.835299626567392, -4.875...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.25409174394604, -4.77692003777844, -5.174...   \n",
       "1   [[-7.0, -5.816666666666666, -5.283818181818183...   \n",
       "2   [[-6.913628605824498, -5.794885079365076, -5.2...   \n",
       "3   [[-6.264818181643189, -4.695472454316142, -4.9...   \n",
       "4   [[-5.664646153846155, -5.395815384615388, -5.3...   \n",
       "5   [[-6.71183, -5.2756224, -5.2298694, -6.33378, ...   \n",
       "6   [[-7.0, -5.81666666666667, -5.283818181818176,...   \n",
       "7   [[-6.074338701094595, -4.792171396907944, -5.0...   \n",
       "8   [[-6.986666666666667, -5.816666666666666, -7.0...   \n",
       "9   [[-6.89945879937141, -4.6295363354867245, -4.7...   \n",
       "10  [[-6.7340044564608545, -5.186495597585306, -5....   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.382234928074743, -4.907868998332539, -5.11...   \n",
       "1   [-6.987333333333334, -5.214666666666666, -5.19...   \n",
       "2   [-6.930332289429968, -5.214396165223664, -5.19...   \n",
       "3   [-6.4265646379471395, -4.7873401517700245, -4....   \n",
       "4   [-5.591162677700295, -5.370591589523299, -5.37...   \n",
       "5   [-6.8375244, -5.120825, -5.1633034, -6.16767, ...   \n",
       "6   [-6.987333333333334, -5.214666666666666, -5.19...   \n",
       "7   [-6.260375281168595, -4.832185810738035, -4.98...   \n",
       "8   [-6.989333333333333, -5.58, -6.957333333333334...   \n",
       "9   [-6.893104743119852, -4.688924966011017, -4.72...   \n",
       "10  [-6.770479832080494, -5.184959924997299, -5.22...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.11991125078650615, 0.12036585461728498, 0.0...  \n",
       "1   [0.02533333333333303, 0.38978826160992697, 0.0...  \n",
       "2   [0.016298820400586684, 0.3838726863050127, 0.0...  \n",
       "3   [0.12107986246483377, 0.04811141695798136, 0.0...  \n",
       "4   [0.179746667553664, 0.14341113076273732, 0.143...  \n",
       "5   [0.08154567, 0.15820575, 0.06364988, 0.2141117...  \n",
       "6   [0.025333333333331966, 0.3897882616099315, 0.0...  \n",
       "7   [0.10079208316089719, 0.02187978401212345, 0.0...  \n",
       "8   [0.005333333333333102, 0.5033929324538081, 0.0...  \n",
       "9   [0.0134519078867844, 0.045612497700995666, 0.0...  \n",
       "10  [0.07738970710258487, 0.17222412348160474, 0.1...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d29ef2f8-7796-4ef7-8540-a0ddb4beb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MACCS_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_MACCS_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_MACCS_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b035c4b0-be00-4843-a8fd-f2a8a38b7035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 881)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 881)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 786\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 262\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 801\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 267\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 795\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 792\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 264\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 795\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.41280151013628863\n",
      "0.3965274615091062\n",
      "0.42470628963076207\n",
      "0.39279706971146233\n",
      "0.03417529171917333\n",
      "0.4290321790978585\n",
      "0.39651458828330866\n",
      "0.36162742313232443\n",
      "0.1312127005114303\n",
      "0.37367762516189607\n",
      "0.38940811094729266\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>0.6132</td>\n",
       "      <td>0.3963</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.4657</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>0.4128</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>0.5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.6398</td>\n",
       "      <td>0.3427</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.5734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.3698</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.6384</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.3641</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.4247</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.5788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3821</td>\n",
       "      <td>0.4777</td>\n",
       "      <td>0.6181</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>0.4765</td>\n",
       "      <td>0.6199</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.5532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.6411</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>0.4012</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.6011</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.5855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4022</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.6342</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.6078</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.5730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4201</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.3255</td>\n",
       "      <td>0.5767</td>\n",
       "      <td>0.5119</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.3616</td>\n",
       "      <td>0.6033</td>\n",
       "      <td>0.5448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.5654</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.7520</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.5498</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.4487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.5617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4137</td>\n",
       "      <td>0.4817</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>0.5879</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.3894</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.5746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.3760                0.4697   \n",
       "DecisionTreeRegressor                    0.4094                0.4759   \n",
       "RandomForestRegressor                    0.3698                0.4633   \n",
       "GradientBoostingRegressor                0.3821                0.4777   \n",
       "AdaBoostRegressor                        0.6210                0.6411   \n",
       "XGBRegressor                             0.3730                0.4638   \n",
       "ExtraTreesRegressor                      0.4022                0.4732   \n",
       "LinearRegression                         0.4201                0.4887   \n",
       "KNeighborsRegressor                      0.5654                0.5673   \n",
       "SVR                                      0.3949                0.4669   \n",
       "MLPRegressor                             0.4137                0.4817   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.6132               0.3963   \n",
       "DecisionTreeRegressor                     0.6398               0.3427   \n",
       "RandomForestRegressor                     0.6081               0.4062   \n",
       "GradientBoostingRegressor                 0.6181               0.3865   \n",
       "AdaBoostRegressor                         0.7880               0.0029   \n",
       "XGBRegressor                              0.6107               0.4012   \n",
       "ExtraTreesRegressor                       0.6342               0.3542   \n",
       "LinearRegression                          0.6481               0.3255   \n",
       "KNeighborsRegressor                       0.7520               0.0921   \n",
       "SVR                                       0.6284               0.3659   \n",
       "MLPRegressor                              0.6432               0.3358   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.6296                0.5375   \n",
       "DecisionTreeRegressor                    0.6012                0.5261   \n",
       "RandomForestRegressor                    0.6384                0.5470   \n",
       "GradientBoostingRegressor                0.6243                0.5217   \n",
       "AdaBoostRegressor                        0.4036                0.3920   \n",
       "XGBRegressor                             0.6364                0.5410   \n",
       "ExtraTreesRegressor                      0.6078                0.5306   \n",
       "LinearRegression                         0.5767                0.5119   \n",
       "KNeighborsRegressor                      0.4792                0.3955   \n",
       "SVR                                      0.6141                0.5267   \n",
       "MLPRegressor                             0.5879                0.5190   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.3716   0.4657    0.6096  0.4128   \n",
       "DecisionTreeRegressor       0.3819   0.4573    0.6180  0.3965   \n",
       "RandomForestRegressor       0.3641   0.4543    0.6034  0.4247   \n",
       "GradientBoostingRegressor   0.3843   0.4765    0.6199  0.3928   \n",
       "AdaBoostRegressor           0.6112   0.6363    0.7818  0.0342   \n",
       "XGBRegressor                0.3613   0.4502    0.6011  0.4290   \n",
       "ExtraTreesRegressor         0.3819   0.4575    0.6180  0.3965   \n",
       "LinearRegression            0.4040   0.4861    0.6356  0.3616   \n",
       "KNeighborsRegressor         0.5498   0.5558    0.7415  0.1312   \n",
       "SVR                         0.3964   0.4618    0.6296  0.3737   \n",
       "MLPRegressor                0.3864   0.4674    0.6216  0.3894   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.6432                    0.5700  \n",
       "DecisionTreeRegressor                       0.6338                    0.5734  \n",
       "RandomForestRegressor                       0.6521                    0.5788  \n",
       "GradientBoostingRegressor                   0.6296                    0.5532  \n",
       "AdaBoostRegressor                           0.4205                    0.4286  \n",
       "XGBRegressor                                0.6557                    0.5855  \n",
       "ExtraTreesRegressor                         0.6340                    0.5730  \n",
       "LinearRegression                            0.6033                    0.5448  \n",
       "KNeighborsRegressor                         0.5023                    0.4487  \n",
       "SVR                                         0.6216                    0.5617  \n",
       "MLPRegressor                                0.6251                    0.5746  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PubChem fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/PubChem_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/PubChem_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_PubChem_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_PubChem_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb4a00c1-1d6d-414d-8e43-13b678f0b2e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.15240091869389, -6.409222493499245, -5.545...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.730628525521913, -6.160845049049088, -6.1...</td>\n",
       "      <td>[-7.03747074163312, -5.91633115788449, -6.0649...</td>\n",
       "      <td>[0.31613404943333073, 0.32462689353377144, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-6.89, -7.0, -5.511875000000001, -4.979759036...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.873333333333334, -6.89, -7.0, -6.87...</td>\n",
       "      <td>[-6.948, -6.974666666666667, -6.88666666666666...</td>\n",
       "      <td>[0.049558046773455613, 0.05066666666666641, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.8417517511520645, -6.983499999999999, -5.5...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.951514285714284, -6.865683174603171, -6.8...</td>\n",
       "      <td>[-6.953734857142857, -6.86388281962482, -6.824...</td>\n",
       "      <td>[0.007862618798297322, 0.025702446569454675, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.759241818307694, -6.926074604175503, -5.32...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.6521262779075485, -6.570095986570666, -6....</td>\n",
       "      <td>[-7.660522247833451, -6.391796237208716, -6.32...</td>\n",
       "      <td>[0.05095329964644285, 0.21846501206762203, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.870566190768713, -5.801438356164383, -5.43...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.870566190768713, -5.727960175447544, -5.8...</td>\n",
       "      <td>[-5.847272281495562, -5.73358052499466, -5.825...</td>\n",
       "      <td>[0.053836174943512054, 0.0835560159715254, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-8.323095, -8.49177, -5.5085397, -4.992343, -...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.355886, -7.7571683, -7.0634513, -6.523109...</td>\n",
       "      <td>[-7.1913886, -7.1380224, -6.9227333, -6.431646...</td>\n",
       "      <td>[0.23967122, 0.33813962, 0.087070495, 0.144615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.88999999999999, -7.0, -5.511874999999992, ...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.873333333333334, -6.88999999999999,...</td>\n",
       "      <td>[-6.947999999999996, -6.966306666666666, -6.89...</td>\n",
       "      <td>[0.04955804677346036, 0.04922495482758469, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-6.45522034418687, -7.055143305233996, -5.545...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.749785115888298, -6.116769408880275, -6.7...</td>\n",
       "      <td>[-7.901167677574543, -6.153447963219231, -6.73...</td>\n",
       "      <td>[0.10380520823425542, 0.07125564115036094, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-6.963333333333334, -7.0, -6.836666666666666,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.973333333333334, -7.0, -6.963333333333334...</td>\n",
       "      <td>[-6.978666666666667, -7.0, -6.970666666666668,...</td>\n",
       "      <td>[0.006531972647421959, 0.0, 0.0146666666666664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.347262239146147, -6.995727536382716, -5.24...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.931115307275416, -6.327606660447614, -6.3...</td>\n",
       "      <td>[-6.925149257760651, -6.501785916112955, -6.51...</td>\n",
       "      <td>[0.029477865723266827, 0.10331472781994015, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.703087792671567, -7.457397508176215, -5.60...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.678232761097775, -6.462315446020942, -6.6...</td>\n",
       "      <td>[-7.801901092582239, -6.542179646051291, -6.80...</td>\n",
       "      <td>[0.415506974938055, 0.31619345960187173, 0.219...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.15240091869389, -6.409222493499245, -5.545...   \n",
       "1   [-6.89, -7.0, -5.511875000000001, -4.979759036...   \n",
       "2   [-6.8417517511520645, -6.983499999999999, -5.5...   \n",
       "3   [-6.759241818307694, -6.926074604175503, -5.32...   \n",
       "4   [-5.870566190768713, -5.801438356164383, -5.43...   \n",
       "5   [-8.323095, -8.49177, -5.5085397, -4.992343, -...   \n",
       "6   [-6.88999999999999, -7.0, -5.511874999999992, ...   \n",
       "7   [-6.45522034418687, -7.055143305233996, -5.545...   \n",
       "8   [-6.963333333333334, -7.0, -6.836666666666666,...   \n",
       "9   [-6.347262239146147, -6.995727536382716, -5.24...   \n",
       "10  [-6.703087792671567, -7.457397508176215, -5.60...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.730628525521913, -6.160845049049088, -6.1...   \n",
       "1   [[-7.0, -6.873333333333334, -6.89, -7.0, -6.87...   \n",
       "2   [[-6.951514285714284, -6.865683174603171, -6.8...   \n",
       "3   [[-7.6521262779075485, -6.570095986570666, -6....   \n",
       "4   [[-5.870566190768713, -5.727960175447544, -5.8...   \n",
       "5   [[-7.355886, -7.7571683, -7.0634513, -6.523109...   \n",
       "6   [[-7.0, -6.873333333333334, -6.88999999999999,...   \n",
       "7   [[-7.749785115888298, -6.116769408880275, -6.7...   \n",
       "8   [[-6.973333333333334, -7.0, -6.963333333333334...   \n",
       "9   [[-6.931115307275416, -6.327606660447614, -6.3...   \n",
       "10  [[-7.678232761097775, -6.462315446020942, -6.6...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.03747074163312, -5.91633115788449, -6.0649...   \n",
       "1   [-6.948, -6.974666666666667, -6.88666666666666...   \n",
       "2   [-6.953734857142857, -6.86388281962482, -6.824...   \n",
       "3   [-7.660522247833451, -6.391796237208716, -6.32...   \n",
       "4   [-5.847272281495562, -5.73358052499466, -5.825...   \n",
       "5   [-7.1913886, -7.1380224, -6.9227333, -6.431646...   \n",
       "6   [-6.947999999999996, -6.966306666666666, -6.89...   \n",
       "7   [-7.901167677574543, -6.153447963219231, -6.73...   \n",
       "8   [-6.978666666666667, -7.0, -6.970666666666668,...   \n",
       "9   [-6.925149257760651, -6.501785916112955, -6.51...   \n",
       "10  [-7.801901092582239, -6.542179646051291, -6.80...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.31613404943333073, 0.32462689353377144, 0.2...  \n",
       "1   [0.049558046773455613, 0.05066666666666641, 0....  \n",
       "2   [0.007862618798297322, 0.025702446569454675, 0...  \n",
       "3   [0.05095329964644285, 0.21846501206762203, 0.0...  \n",
       "4   [0.053836174943512054, 0.0835560159715254, 0.0...  \n",
       "5   [0.23967122, 0.33813962, 0.087070495, 0.144615...  \n",
       "6   [0.04955804677346036, 0.04922495482758469, 0.0...  \n",
       "7   [0.10380520823425542, 0.07125564115036094, 0.0...  \n",
       "8   [0.006531972647421959, 0.0, 0.0146666666666664...  \n",
       "9   [0.029477865723266827, 0.10331472781994015, 0....  \n",
       "10  [0.415506974938055, 0.31619345960187173, 0.219...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2964217-8bba-42a5-ae90-7d89fb8473c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PubChem_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_PubChem_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_PubChem_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ad464c9-859c-4185-a14f-34f15a87bd41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 307)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 307)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 90\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 90\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 90\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 90\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.2523661343086917\n",
      "0.2529154762727547\n",
      "0.25969546020652445\n",
      "0.25061898724424225\n",
      "0.13783563021558676\n",
      "0.25786267427373555\n",
      "0.25364696543833687\n",
      "0.24399943825097192\n",
      "-0.12105840127964118\n",
      "0.23059697664687706\n",
      "0.2373710329049996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.4717</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.5264</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4554</td>\n",
       "      <td>0.5131</td>\n",
       "      <td>0.6748</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.5213</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.4394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.4526</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.5237</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.5168</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.5119</td>\n",
       "      <td>0.4385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.4143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5497</td>\n",
       "      <td>0.5959</td>\n",
       "      <td>0.7414</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.5456</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.4424</td>\n",
       "      <td>0.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.4537</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.5230</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.5165</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>0.4362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4559</td>\n",
       "      <td>0.5136</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.2679</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.3795</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.4080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>0.8424</td>\n",
       "      <td>-0.1393</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.7094</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.8423</td>\n",
       "      <td>-0.1211</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.4760</td>\n",
       "      <td>0.5089</td>\n",
       "      <td>0.6899</td>\n",
       "      <td>0.2357</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.4869</td>\n",
       "      <td>0.5111</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.5223</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.2374</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.4429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.4717                0.5262   \n",
       "DecisionTreeRegressor                    0.4554                0.5131   \n",
       "RandomForestRegressor                    0.4526                0.5125   \n",
       "GradientBoostingRegressor                0.4615                0.5206   \n",
       "AdaBoostRegressor                        0.5497                0.5959   \n",
       "XGBRegressor                             0.4537                0.5127   \n",
       "ExtraTreesRegressor                      0.4559                0.5136   \n",
       "LinearRegression                         0.4785                0.5295   \n",
       "KNeighborsRegressor                      0.7096                0.6317   \n",
       "SVR                                      0.4760                0.5089   \n",
       "MLPRegressor                             0.4745                0.5223   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.6868               0.2427   \n",
       "DecisionTreeRegressor                     0.6748               0.2688   \n",
       "RandomForestRegressor                     0.6727               0.2733   \n",
       "GradientBoostingRegressor                 0.6794               0.2589   \n",
       "AdaBoostRegressor                         0.7414               0.1174   \n",
       "XGBRegressor                              0.6736               0.2715   \n",
       "ExtraTreesRegressor                       0.6752               0.2679   \n",
       "LinearRegression                          0.6917               0.2318   \n",
       "KNeighborsRegressor                       0.8424              -0.1393   \n",
       "SVR                                       0.6899               0.2357   \n",
       "MLPRegressor                              0.6889               0.2381   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.4926                0.3835   \n",
       "DecisionTreeRegressor                    0.5213                0.3941   \n",
       "RandomForestRegressor                    0.5237                0.3968   \n",
       "GradientBoostingRegressor                0.5091                0.3928   \n",
       "AdaBoostRegressor                        0.4256                0.3161   \n",
       "XGBRegressor                             0.5230                0.3969   \n",
       "ExtraTreesRegressor                      0.5202                0.3942   \n",
       "LinearRegression                         0.4826                0.3795   \n",
       "KNeighborsRegressor                      0.2377                0.1502   \n",
       "SVR                                      0.5021                0.3978   \n",
       "MLPRegressor                             0.4939                0.3905   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE  Test R2  \\\n",
       "LGBMRegressor               0.4731   0.5264    0.6878   0.2524   \n",
       "DecisionTreeRegressor       0.4728   0.5169    0.6876   0.2529   \n",
       "RandomForestRegressor       0.4685   0.5168    0.6845   0.2597   \n",
       "GradientBoostingRegressor   0.4742   0.5265    0.6886   0.2506   \n",
       "AdaBoostRegressor           0.5456   0.5961    0.7386   0.1378   \n",
       "XGBRegressor                0.4696   0.5165    0.6853   0.2579   \n",
       "ExtraTreesRegressor         0.4723   0.5166    0.6873   0.2536   \n",
       "LinearRegression            0.4784   0.5298    0.6917   0.2440   \n",
       "KNeighborsRegressor         0.7094   0.6324    0.8423  -0.1211   \n",
       "SVR                         0.4869   0.5111    0.6978   0.2306   \n",
       "MLPRegressor                0.4826   0.5210    0.6947   0.2374   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.5025                    0.4199  \n",
       "DecisionTreeRegressor                       0.5075                    0.4394  \n",
       "RandomForestRegressor                       0.5119                    0.4385  \n",
       "GradientBoostingRegressor                   0.5008                    0.4143  \n",
       "AdaBoostRegressor                           0.4424                    0.3875  \n",
       "XGBRegressor                                0.5108                    0.4362  \n",
       "ExtraTreesRegressor                         0.5079                    0.4399  \n",
       "LinearRegression                            0.4941                    0.4080  \n",
       "KNeighborsRegressor                         0.2195                    0.1702  \n",
       "SVR                                         0.4988                    0.4273  \n",
       "MLPRegressor                                0.4950                    0.4429  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Substructure fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/Substructure_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/Substructure_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_Substructure_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_Substructure_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6f8d69c-82b2-4ecc-801b-4a997e1040e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-5.1765165647687255, -6.115999270764352, -5.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.115999270764352, -5.1765165647687255, -5....</td>\n",
       "      <td>[-6.223803935418417, -5.23510786812346, -5.173...</td>\n",
       "      <td>[0.07419030034403576, 0.0380275825419148, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-5.088333333333333, -6.900833333333334, -5.16...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.900833333333334, -5.088333333333333, -5.1...</td>\n",
       "      <td>[-6.910515384615385, -5.566761904761904, -5.13...</td>\n",
       "      <td>[0.029148345781561377, 0.29670803808448715, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-5.076318534492043, -6.9064871039392335, -5.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.906487103939234, -5.076318534492043, -5.1...</td>\n",
       "      <td>[-6.912931768470837, -5.5702805028802045, -5.1...</td>\n",
       "      <td>[0.02750031991738278, 0.30973715553062103, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-5.0477080181230125, -6.657747306540635, -5.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.657747306540635, -5.0477080181230125, -5....</td>\n",
       "      <td>[-6.543614244757757, -5.118199857641798, -5.13...</td>\n",
       "      <td>[0.06974657852196715, 0.043943005853952936, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.337882797731561, -5.893963133640551, -5.33...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.893963133640551, -5.337882797731561, -5.3...</td>\n",
       "      <td>[-5.804903426009342, -5.368202233480746, -5.36...</td>\n",
       "      <td>[0.19793378106761128, 0.1217614130678465, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-5.099984, -6.8878307, -5.160158, -5.160158, ...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8878307, -5.099984, -5.160158, -4.860455,...</td>\n",
       "      <td>[-6.899044, -5.523138, -5.1358643, -4.9446115,...</td>\n",
       "      <td>[0.031615507, 0.26666743, 0.016278781, 0.20925...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-5.088333333333323, -6.900833333333335, -5.16...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.900833333333335, -5.088333333333323, -5.1...</td>\n",
       "      <td>[-6.9105153846153895, -5.566761904761902, -5.1...</td>\n",
       "      <td>[0.029148345781560572, 0.2967080380844896, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.072410162397099, -6.010943270708908, -5.15...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.010943270708908, -5.072410162397099, -5.1...</td>\n",
       "      <td>[-6.174629451019132, -5.055658563434185, -5.13...</td>\n",
       "      <td>[0.08899424116007519, 0.03262090182441304, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.593333333333334, -6.986666666666667, -7.0,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -5.593333333333334, -7.0...</td>\n",
       "      <td>[-6.984, -6.621333333333334, -7.0, -5.12133333...</td>\n",
       "      <td>[0.005333333333333456, 0.5474693294301212, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.676290881539564, -6.900171571476855, -4.83...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.900171571476855, -4.676290881539564, -4.8...</td>\n",
       "      <td>[-6.900172829360703, -4.794388523813799, -4.82...</td>\n",
       "      <td>[0.0001230336518123236, 0.07316673838856275, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-4.93382632799022, -6.691550353951627, -5.185...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.691550353951627, -4.93382632799022, -5.18...</td>\n",
       "      <td>[-6.739691026487586, -5.169034919296488, -5.13...</td>\n",
       "      <td>[0.053399544221650316, 0.1618831006221375, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-5.1765165647687255, -6.115999270764352, -5.1...   \n",
       "1   [-5.088333333333333, -6.900833333333334, -5.16...   \n",
       "2   [-5.076318534492043, -6.9064871039392335, -5.1...   \n",
       "3   [-5.0477080181230125, -6.657747306540635, -5.1...   \n",
       "4   [-5.337882797731561, -5.893963133640551, -5.33...   \n",
       "5   [-5.099984, -6.8878307, -5.160158, -5.160158, ...   \n",
       "6   [-5.088333333333323, -6.900833333333335, -5.16...   \n",
       "7   [-5.072410162397099, -6.010943270708908, -5.15...   \n",
       "8   [-5.593333333333334, -6.986666666666667, -7.0,...   \n",
       "9   [-4.676290881539564, -6.900171571476855, -4.83...   \n",
       "10  [-4.93382632799022, -6.691550353951627, -5.185...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.115999270764352, -5.1765165647687255, -5....   \n",
       "1   [[-6.900833333333334, -5.088333333333333, -5.1...   \n",
       "2   [[-6.906487103939234, -5.076318534492043, -5.1...   \n",
       "3   [[-6.657747306540635, -5.0477080181230125, -5....   \n",
       "4   [[-5.893963133640551, -5.337882797731561, -5.3...   \n",
       "5   [[-6.8878307, -5.099984, -5.160158, -4.860455,...   \n",
       "6   [[-6.900833333333335, -5.088333333333323, -5.1...   \n",
       "7   [[-6.010943270708908, -5.072410162397099, -5.1...   \n",
       "8   [[-6.986666666666667, -5.593333333333334, -7.0...   \n",
       "9   [[-6.900171571476855, -4.676290881539564, -4.8...   \n",
       "10  [[-6.691550353951627, -4.93382632799022, -5.18...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.223803935418417, -5.23510786812346, -5.173...   \n",
       "1   [-6.910515384615385, -5.566761904761904, -5.13...   \n",
       "2   [-6.912931768470837, -5.5702805028802045, -5.1...   \n",
       "3   [-6.543614244757757, -5.118199857641798, -5.13...   \n",
       "4   [-5.804903426009342, -5.368202233480746, -5.36...   \n",
       "5   [-6.899044, -5.523138, -5.1358643, -4.9446115,...   \n",
       "6   [-6.9105153846153895, -5.566761904761902, -5.1...   \n",
       "7   [-6.174629451019132, -5.055658563434185, -5.13...   \n",
       "8   [-6.984, -6.621333333333334, -7.0, -5.12133333...   \n",
       "9   [-6.900172829360703, -4.794388523813799, -4.82...   \n",
       "10  [-6.739691026487586, -5.169034919296488, -5.13...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.07419030034403576, 0.0380275825419148, 0.00...  \n",
       "1   [0.029148345781561377, 0.29670803808448715, 0....  \n",
       "2   [0.02750031991738278, 0.30973715553062103, 0.0...  \n",
       "3   [0.06974657852196715, 0.043943005853952936, 0....  \n",
       "4   [0.19793378106761128, 0.1217614130678465, 0.12...  \n",
       "5   [0.031615507, 0.26666743, 0.016278781, 0.20925...  \n",
       "6   [0.029148345781560572, 0.2967080380844896, 0.0...  \n",
       "7   [0.08899424116007519, 0.03262090182441304, 0.0...  \n",
       "8   [0.005333333333333456, 0.5474693294301212, 0.0...  \n",
       "9   [0.0001230336518123236, 0.07316673838856275, 0...  \n",
       "10  [0.053399544221650316, 0.1618831006221375, 0.0...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78b9d7ed-303c-4718-a003-4be649cbcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Substructure_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_Substructure_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_Substructure_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddddcec8-5336-4678-9ad8-12a37d5f6819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 307)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 307)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 513\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 519\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 507\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 505\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5862460433746561\n",
      "0.5756222326310896\n",
      "0.5934181489253311\n",
      "0.48292159607349805\n",
      "0.2028495002245233\n",
      "0.6004697165528066\n",
      "0.5919023075047537\n",
      "0.2986260208257846\n",
      "0.5187478840972479\n",
      "0.42271208733643995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/akshay/anaconda3/envs/py312/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48511283394264737\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2624</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.5786</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.5117</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>0.2686</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.5182</td>\n",
       "      <td>0.5756</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.7809</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>0.5639</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>0.4238</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.4829</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.6949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5313</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.7289</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.5512</td>\n",
       "      <td>0.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2417</td>\n",
       "      <td>0.3576</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.2528</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.6005</td>\n",
       "      <td>0.7752</td>\n",
       "      <td>0.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.3592</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>0.7621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4397</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.6662</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.4064</td>\n",
       "      <td>0.5613</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.3961</td>\n",
       "      <td>0.5519</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.7108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.4221</td>\n",
       "      <td>0.6044</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.6592</td>\n",
       "      <td>0.6783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.3377</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.5811</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.7361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.2624                0.3780   \n",
       "DecisionTreeRegressor                    0.3161                0.3899   \n",
       "RandomForestRegressor                    0.2431                0.3602   \n",
       "GradientBoostingRegressor                0.3179                0.4239   \n",
       "AdaBoostRegressor                        0.5313                0.5965   \n",
       "XGBRegressor                             0.2417                0.3576   \n",
       "ExtraTreesRegressor                      0.2432                0.3592   \n",
       "LinearRegression                         0.4397                0.4876   \n",
       "KNeighborsRegressor                      0.3150                0.4064   \n",
       "SVR                                      0.3542                0.4244   \n",
       "MLPRegressor                             0.3377                0.4116   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.5123               0.5786   \n",
       "DecisionTreeRegressor                     0.5622               0.4924   \n",
       "RandomForestRegressor                     0.4930               0.6097   \n",
       "GradientBoostingRegressor                 0.5639               0.4895   \n",
       "AdaBoostRegressor                         0.7289               0.1469   \n",
       "XGBRegressor                              0.4916               0.6120   \n",
       "ExtraTreesRegressor                       0.4931               0.6096   \n",
       "LinearRegression                          0.6631               0.2941   \n",
       "KNeighborsRegressor                       0.5613               0.4942   \n",
       "SVR                                       0.5952               0.4312   \n",
       "MLPRegressor                              0.5811               0.4577   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.7625                0.7254   \n",
       "DecisionTreeRegressor                    0.7201                0.7034   \n",
       "RandomForestRegressor                    0.7809                0.7495   \n",
       "GradientBoostingRegressor                0.7103                0.6768   \n",
       "AdaBoostRegressor                        0.5036                0.4280   \n",
       "XGBRegressor                             0.7829                0.7483   \n",
       "ExtraTreesRegressor                      0.7812                0.7485   \n",
       "LinearRegression                         0.5434                0.5641   \n",
       "KNeighborsRegressor                      0.7102                0.6787   \n",
       "SVR                                      0.6679                0.6616   \n",
       "MLPRegressor                             0.6842                0.6868   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2618   0.3729    0.5117  0.5862   \n",
       "DecisionTreeRegressor       0.2686   0.3632    0.5182  0.5756   \n",
       "RandomForestRegressor       0.2573   0.3594    0.5072  0.5934   \n",
       "GradientBoostingRegressor   0.3272   0.4238    0.5720  0.4829   \n",
       "AdaBoostRegressor           0.5045   0.5797    0.7103  0.2028   \n",
       "XGBRegressor                0.2528   0.3559    0.5028  0.6005   \n",
       "ExtraTreesRegressor         0.2583   0.3596    0.5082  0.5919   \n",
       "LinearRegression            0.4438   0.4866    0.6662  0.2986   \n",
       "KNeighborsRegressor         0.3046   0.3961    0.5519  0.5187   \n",
       "SVR                         0.3653   0.4221    0.6044  0.4227   \n",
       "MLPRegressor                0.3258   0.3953    0.5708  0.4851   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7692                    0.7488  \n",
       "DecisionTreeRegressor                       0.7619                    0.7516  \n",
       "RandomForestRegressor                       0.7706                    0.7611  \n",
       "GradientBoostingRegressor                   0.7046                    0.6949  \n",
       "AdaBoostRegressor                           0.5512                    0.4800  \n",
       "XGBRegressor                                0.7752                    0.7604  \n",
       "ExtraTreesRegressor                         0.7702                    0.7621  \n",
       "LinearRegression                            0.5468                    0.5764  \n",
       "KNeighborsRegressor                         0.7258                    0.7108  \n",
       "SVR                                         0.6592                    0.6783  \n",
       "MLPRegressor                                0.7010                    0.7361  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Substructure Count fingerprints\n",
    "df_train = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Train/SubstructureCount_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('/home/users/akshay/PCPpred/PAMPA/features/Fingerprints/Test/SubstructureCount_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "df_SubstructureCount_fp, pred_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "df_SubstructureCount_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ca35a04-2126-44d7-b350-faad0b3bae38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.984988093988094, -6.874354012838001, -5.76...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.018970450241344, -5.817410302907244, -6.8...</td>\n",
       "      <td>[-6.97681800604188, -5.890625592487536, -6.896...</td>\n",
       "      <td>[0.031844742780730836, 0.14786966484697378, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.0, -7.0, -6.244999999999999, -5.07, -4.59,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.2, -6.96, -7.0, -6.24, -7.0, -6.85,...</td>\n",
       "      <td>[-6.976000000000001, -5.48, -6.992, -6.754, -5...</td>\n",
       "      <td>[0.01959591794226544, 0.2836899716239544, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.884099999999998, -6.871400000000002, -6.08...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.959099999999998, -5.758666666666669, -6.9...</td>\n",
       "      <td>[-6.9711, -5.791460000000002, -6.94571, -6.252...</td>\n",
       "      <td>[0.014284677105206627, 0.17308964973228333, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.7569234264413245, -6.6529208801483195, -5....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0555655635533885, -5.398139696109834, -6....</td>\n",
       "      <td>[-7.122438663819739, -5.490769107178844, -6.77...</td>\n",
       "      <td>[0.06606522621599681, 0.1501292997603641, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-6.543428571428572, -5.959210526315789, -5.70...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.543428571428572, -5.714731064764001, -6.5...</td>\n",
       "      <td>[-6.092710670620762, -5.694517651920593, -6.02...</td>\n",
       "      <td>[0.24773951815862527, 0.09382615786149985, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.9898057, -6.8005347, -5.990174, -4.797337,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.989251, -5.6280417, -6.7466702, -7.050244...</td>\n",
       "      <td>[-7.049016, -5.7448792, -6.951416, -6.670949, ...</td>\n",
       "      <td>[0.04864793, 0.17339802, 0.12257617, 0.4663881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.7646999999999995, -6.756800000000001, -6.2...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.965, -6.237200000000002, -6.9003999999999...</td>\n",
       "      <td>[-6.97304, -6.242980000000001, -6.8344, -6.478...</td>\n",
       "      <td>[0.006861661606345793, 0.1262953269127563, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.280245626491479, -5.895392542571749, -5.51...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.0117887517806645, -4.6411953739140435, -5...</td>\n",
       "      <td>[-6.19918580553964, -4.698957279642839, -5.676...</td>\n",
       "      <td>[0.09731223194497061, 0.06727830500580526, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-6.453333333333333, -7.0, -6.496666666666666,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986666666666667, -5.603333333333333, -7.0...</td>\n",
       "      <td>[-6.9893333333333345, -6.294, -6.824, -5.40799...</td>\n",
       "      <td>[0.005333333333333102, 0.4281142111373762, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.691550259534014, -6.897124498175519, -5.50...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.1613209558550786, -6.033844266641924, -6....</td>\n",
       "      <td>[-7.166614671576741, -6.128104668832263, -6.75...</td>\n",
       "      <td>[0.026794922281811653, 0.08046582871499011, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-7.0919498023906264, -6.231024988187164, -6.2...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.45332650738089, -5.822690019706291, -7.48...</td>\n",
       "      <td>[-7.544943668709311, -5.993219996170878, -7.47...</td>\n",
       "      <td>[0.24794526009456785, 0.2207532957299662, 0.22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.984988093988094, -6.874354012838001, -5.76...   \n",
       "1   [-7.0, -7.0, -6.244999999999999, -5.07, -4.59,...   \n",
       "2   [-6.884099999999998, -6.871400000000002, -6.08...   \n",
       "3   [-6.7569234264413245, -6.6529208801483195, -5....   \n",
       "4   [-6.543428571428572, -5.959210526315789, -5.70...   \n",
       "5   [-6.9898057, -6.8005347, -5.990174, -4.797337,...   \n",
       "6   [-6.7646999999999995, -6.756800000000001, -6.2...   \n",
       "7   [-5.280245626491479, -5.895392542571749, -5.51...   \n",
       "8   [-6.453333333333333, -7.0, -6.496666666666666,...   \n",
       "9   [-6.691550259534014, -6.897124498175519, -5.50...   \n",
       "10  [-7.0919498023906264, -6.231024988187164, -6.2...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.018970450241344, -5.817410302907244, -6.8...   \n",
       "1   [[-7.0, -5.2, -6.96, -7.0, -6.24, -7.0, -6.85,...   \n",
       "2   [[-6.959099999999998, -5.758666666666669, -6.9...   \n",
       "3   [[-7.0555655635533885, -5.398139696109834, -6....   \n",
       "4   [[-6.543428571428572, -5.714731064764001, -6.5...   \n",
       "5   [[-6.989251, -5.6280417, -6.7466702, -7.050244...   \n",
       "6   [[-6.965, -6.237200000000002, -6.9003999999999...   \n",
       "7   [[-6.0117887517806645, -4.6411953739140435, -5...   \n",
       "8   [[-6.986666666666667, -5.603333333333333, -7.0...   \n",
       "9   [[-7.1613209558550786, -6.033844266641924, -6....   \n",
       "10  [[-7.45332650738089, -5.822690019706291, -7.48...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.97681800604188, -5.890625592487536, -6.896...   \n",
       "1   [-6.976000000000001, -5.48, -6.992, -6.754, -5...   \n",
       "2   [-6.9711, -5.791460000000002, -6.94571, -6.252...   \n",
       "3   [-7.122438663819739, -5.490769107178844, -6.77...   \n",
       "4   [-6.092710670620762, -5.694517651920593, -6.02...   \n",
       "5   [-7.049016, -5.7448792, -6.951416, -6.670949, ...   \n",
       "6   [-6.97304, -6.242980000000001, -6.8344, -6.478...   \n",
       "7   [-6.19918580553964, -4.698957279642839, -5.676...   \n",
       "8   [-6.9893333333333345, -6.294, -6.824, -5.40799...   \n",
       "9   [-7.166614671576741, -6.128104668832263, -6.75...   \n",
       "10  [-7.544943668709311, -5.993219996170878, -7.47...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.031844742780730836, 0.14786966484697378, 0....  \n",
       "1   [0.01959591794226544, 0.2836899716239544, 0.01...  \n",
       "2   [0.014284677105206627, 0.17308964973228333, 0....  \n",
       "3   [0.06606522621599681, 0.1501292997603641, 0.05...  \n",
       "4   [0.24773951815862527, 0.09382615786149985, 0.2...  \n",
       "5   [0.04864793, 0.17339802, 0.12257617, 0.4663881...  \n",
       "6   [0.006861661606345793, 0.1262953269127563, 0.0...  \n",
       "7   [0.09731223194497061, 0.06727830500580526, 0.0...  \n",
       "8   [0.005333333333333102, 0.4281142111373762, 0.2...  \n",
       "9   [0.026794922281811653, 0.08046582871499011, 0....  \n",
       "10  [0.24794526009456785, 0.2207532957299662, 0.22...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab79676d-245b-4ea5-af56-93d2b69ff7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SubstructureCount_fp.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Results_Substructure_Count_fp.csv')\n",
    "pred_df.to_csv('/home/users/akshay/PCPpred/PAMPA/Results/Fingerprints/Prediction_data_Substructure_Count_fp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2fb71-f33c-41f3-b48e-f3d8727c0ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e8cc3c-eb4e-4182-8c47-1c9e5129f034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c0d7a-b8b5-481a-8fc6-d6f4dcbff261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13fdbc-f955-4122-9b10-5f7310d77033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ec9c5-ddc2-400c-ba30-2d8b1b79792c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f067c1b-d1ea-4c74-8511-c38d58abd39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85beb737-b395-4cf5-a887-56757b4bfcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ea3ac-03cd-41b0-a15f-004dad8a0e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848716b-62ba-4dcb-96c5-3a99159993ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad929000-ba54-451e-8cae-f8a3cb4b944f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e4602-1a0f-413e-bddb-f4acaf5d28e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766ea66-890a-429a-81d5-825d1bf14fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad40a0-9c51-4603-bd81-86056067bd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffed55-4542-4561-a259-9e821d38834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619baa5c-7853-44f2-8984-78350e8499c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c5fb6-8674-4c95-b930-1853aec9c780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb0383-b1c8-45fb-b212-3fa77ff4eb46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9d94a-e8fb-4628-9b57-7cc6b36753fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5b414-e7b6-4f00-a27e-efe0a1dda325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7716c4d-0d5a-4e1c-a87e-36e0f5e4903a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33b81d-cbd1-4e7c-87d1-fa55935096b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227dd7a-14e7-49e2-8401-e6f1043a84b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714f355-5833-4c5a-9c27-4efecbc947a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186896a-12e5-4941-b2b7-2faf5ec5cca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7735ea5-dbf0-40f2-97d7-67a9e1a77af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a063c9e-6680-45f4-98fd-454741ce4755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3656277-1671-4931-86d7-ef415fa163b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "import joblib\n",
    "def train_and_test_predict_with_tuning(models, param_grids, X_train, y_train, X_test, y_test, save_dir):\n",
    "   \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        best_params = None\n",
    "\n",
    "        # hyperparameter tuning \n",
    "        if model_name in param_grids and param_grids[model_name]:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model, \n",
    "                param_grid=param_grids[model_name], \n",
    "                cv=kf,\n",
    "                scoring='neg_mean_squared_error', \n",
    "                n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            print(model_name)\n",
    "            print(\": best params\",best_params)\n",
    "        else:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            best_params = {}\n",
    "            print(model_name, ':Used Default params')\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)  \n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test Predictions folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "            'Best Parameters': best_params\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "        # Save the model\n",
    "        model_path = os.path.join(save_dir, f\"{model_name}.joblib\")\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"Saved {model_name} model to {model_path}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761724bd-3c2d-47d8-815c-ada020140c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "        'ExtraTreesRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None,1,5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'LGBMRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'num_leaves': [31, 50, 100]\n",
    "        },\n",
    "        'DecisionTreeRegressor': {\n",
    "            'max_depth': [None, 10, 20, 50, 100],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'RandomForestRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None, 1, 5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'GradientBoostingRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7, 10]\n",
    "        },\n",
    "        'AdaBoostRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.1, 1.0]\n",
    "        },\n",
    "        'SVR': {\n",
    "            'C': [0.001, 0.1, 1, 10],\n",
    "            'epsilon': [0.1, 0.2, 0.5],\n",
    "            'gamma': [0.001, 0.1, 1, 10]\n",
    "        },\n",
    "        'KNeighborsRegressor': {\n",
    "            'n_neighbors': [3, 5, 10],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        },\n",
    "        'MLPRegressor': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'learning_rate': ['constant', 'adaptive'],\n",
    "            'max_iter': [100,200, 400]\n",
    "}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2c7e7-f0cb-471a-bb9e-3b6f92c39ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All fingerprints const rem Hyperparametric tuning\n",
    "df_train = pd.read_csv('Fingerprints/Train/All_fingerprints_train.csv')\n",
    "X_train = df_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "X_train, const_col = remove_constant_columns(X_train)\n",
    "y_train = df_train['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "df_test = pd.read_csv('Fingerprints/Test/All_fingerprints_test.csv')\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "save_dir = 'fingerprints_results/Models_All_const_rem_fingerprints_HPT/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "result_df, prediction_df = train_and_test_predict_with_tuning(models, param_grids, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79c116-01ea-4605-ad2e-2ff7b1343c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927389c5-5219-4f62-8b60-c4ca7f63871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('fingerprints_results/Results_All_const_rem_fingerprints_HPT.csv')\n",
    "prediction_df.to_csv('fingerprints_results/Prediction_data_All_const_rem_fingerprints_HPT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9c7c6-5320-40ca-849f-cc50b5afb269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
