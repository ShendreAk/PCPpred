{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c7463c-e540-4aff-a4cd-195e542f8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression  # LogisticRegression is not used for regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm.lgb import LGBMRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0d9842-2746-4713-9a2c-9905529ac3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_names(df):\n",
    "    # Function to clean feature names\n",
    "    def clean_name(name):\n",
    "        # Replace any character that is not alphanumeric or underscore with an underscore\n",
    "        return re.sub(r'[^a-zA-Z0-9_]', '_', name)\n",
    "\n",
    "    # Apply the cleaning function to each column name\n",
    "    df.columns = [clean_name(col) for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6550a75e-4895-4937-8ff1-97ce3a24f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8b33e4-30eb-4680-a527-7eb807c216e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 385)\n",
      "(5568,)\n",
      "(1392, 385)\n",
      "(1392,)\n",
      "0.5464820023986398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 591\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 606\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5247288660538272\n",
      "0.5956636633193892\n",
      "0.4905601124199077\n",
      "0.5667333280143192\n",
      "0.4679766732802857\n",
      "0.21457638105922228\n",
      "0.5001508407281767\n",
      "0.4252963062724475\n",
      "0.4549736143980967\n",
      "0.453024235401302\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.3240</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.3841</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.5465</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.7728</td>\n",
       "      <td>0.7435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4343</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>0.6051</td>\n",
       "      <td>0.3224</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.5678</td>\n",
       "      <td>0.4906</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.2742</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3347</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>0.4626</td>\n",
       "      <td>0.6906</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>0.3367</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.6956</td>\n",
       "      <td>0.6735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.5764</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.4923</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.5446</td>\n",
       "      <td>0.4979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3201</td>\n",
       "      <td>0.4012</td>\n",
       "      <td>0.5657</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.6991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.3637</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.6031</td>\n",
       "      <td>0.4253</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.6680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3702</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.6084</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>0.6512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4053</td>\n",
       "      <td>0.4338</td>\n",
       "      <td>0.6367</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.3461</td>\n",
       "      <td>0.4146</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.6888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.3240                0.4080   \n",
       "LGBMRegressor                            0.3008                0.4004   \n",
       "XGBRegressor                             0.2699                0.3799   \n",
       "DecisionTreeRegressor                    0.4343                0.4638   \n",
       "RandomForestRegressor                    0.2928                0.3913   \n",
       "GradientBoostingRegressor                0.3347                0.4324   \n",
       "AdaBoostRegressor                        0.5216                0.5764   \n",
       "SVR                                      0.3201                0.4012   \n",
       "LinearRegression                         0.3840                0.4460   \n",
       "KNeighborsRegressor                      0.3702                0.4459   \n",
       "MLPRegressor                             0.4053                0.4338   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "ExtraTreesRegressor                       0.5692               0.4798   \n",
       "LGBMRegressor                             0.5485               0.5170   \n",
       "XGBRegressor                              0.5195               0.5666   \n",
       "DecisionTreeRegressor                     0.6590               0.3028   \n",
       "RandomForestRegressor                     0.5411               0.5298   \n",
       "GradientBoostingRegressor                 0.5785               0.4626   \n",
       "AdaBoostRegressor                         0.7222               0.1625   \n",
       "SVR                                       0.5657               0.4861   \n",
       "LinearRegression                          0.6196               0.3835   \n",
       "KNeighborsRegressor                       0.6084               0.4056   \n",
       "MLPRegressor                              0.6367               0.3492   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.7077                0.6780   \n",
       "LGBMRegressor                            0.7202                0.6958   \n",
       "XGBRegressor                             0.7528                0.7135   \n",
       "DecisionTreeRegressor                    0.6320                0.6051   \n",
       "RandomForestRegressor                    0.7298                0.6930   \n",
       "GradientBoostingRegressor                0.6906                0.6539   \n",
       "AdaBoostRegressor                        0.4923                0.4384   \n",
       "SVR                                      0.7012                0.6885   \n",
       "LinearRegression                         0.6264                0.6372   \n",
       "KNeighborsRegressor                      0.6520                0.6163   \n",
       "MLPRegressor                             0.6452                0.6685   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "ExtraTreesRegressor         0.2870   0.3841    0.5357  0.5465   \n",
       "LGBMRegressor               0.3008   0.4033    0.5484  0.5247   \n",
       "XGBRegressor                0.2559   0.3704    0.5058  0.5957   \n",
       "DecisionTreeRegressor       0.3224   0.4017    0.5678  0.4906   \n",
       "RandomForestRegressor       0.2742   0.3794    0.5236  0.5667   \n",
       "GradientBoostingRegressor   0.3367   0.4335    0.5802  0.4680   \n",
       "AdaBoostRegressor           0.4970   0.5692    0.7050  0.2146   \n",
       "SVR                         0.3163   0.3982    0.5624  0.5002   \n",
       "LinearRegression            0.3637   0.4399    0.6031  0.4253   \n",
       "KNeighborsRegressor         0.3449   0.4280    0.5873  0.4550   \n",
       "MLPRegressor                0.3461   0.4146    0.5883  0.4530   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "ExtraTreesRegressor                         0.7448                    0.7132  \n",
       "LGBMRegressor                               0.7259                    0.7057  \n",
       "XGBRegressor                                0.7728                    0.7435  \n",
       "DecisionTreeRegressor                       0.7168                    0.6916  \n",
       "RandomForestRegressor                       0.7533                    0.7215  \n",
       "GradientBoostingRegressor                   0.6956                    0.6735  \n",
       "AdaBoostRegressor                           0.5446                    0.4979  \n",
       "SVR                                         0.7107                    0.6991  \n",
       "LinearRegression                            0.6543                    0.6680  \n",
       "KNeighborsRegressor                         0.6821                    0.6512  \n",
       "MLPRegressor                                0.6930                    0.6888  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Monomer composition\n",
    "df_mc_train = pd.read_csv('Monomer_features/Train_mon_comp.csv')\n",
    "df_mc_train = clean_feature_names(df_mc_train)\n",
    "X_train = df_mc_train.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "y_train = df_mc_train['Permeability']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "df_mc_test = pd.read_csv('Monomer_features/Test_mon_comp.csv')\n",
    "df_mc_test = clean_feature_names(df_mc_test)\n",
    "X_test = df_mc_test.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "y_test = df_mc_test['Permeability']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    SVR(),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3), \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a5eb181-3f5d-4be9-adba-e2c087e1c39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.682, -6.829199999999998, -5.6058, -5.39870...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9338000000000015, -6.576300000000003, -6....</td>\n",
       "      <td>[-6.92923, -6.662480000000002, -6.618329999999...</td>\n",
       "      <td>[0.021276503472140735, 0.13309262038144554, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.474209958508049, -6.088745749683978, -5.12...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.658264488678373, -6.420684318030899, -6.7...</td>\n",
       "      <td>[-6.895847020647485, -6.4802321135909455, -6.6...</td>\n",
       "      <td>[0.23526243115789805, 0.057434991655542326, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-5.7332354, -6.5855656, -5.2311544, -5.181078...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.3695793, -6.166127, -7.0612116, -5.902663...</td>\n",
       "      <td>[-6.4050436, -6.4133353, -7.03028, -5.640264, ...</td>\n",
       "      <td>[0.25567287, 0.19114357, 0.34366196, 0.1417031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.0, -6.92, -5.15, -4.68, -5.15, -4.59, -4.7...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.24, -7.0, -5.89, -6.24, -7.0, -7.0,...</td>\n",
       "      <td>[-7.0, -6.08, -6.16, -5.758, -5.879, -6.334000...</td>\n",
       "      <td>[0.0, 0.7593681584053944, 0.6914332939626208, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.366176190476193, -6.334999999999999, -5.48...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8537, -6.423642857142861, -6.499599999999...</td>\n",
       "      <td>[-6.760695796358002, -6.539240034453241, -6.30...</td>\n",
       "      <td>[0.14228066585014743, 0.0921094304859949, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-5.661132826352657, -6.1049209987207815, -5.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.030654600992403, -5.686372544162835, -6.0...</td>\n",
       "      <td>[-5.965359961798017, -5.722811104192969, -5.93...</td>\n",
       "      <td>[0.07600969637957382, 0.06791902208528118, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.746646566799839, -6.085248650371831, -5.67...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.954906012906758, -5.954906012906758, -5.7...</td>\n",
       "      <td>[-5.996077476395867, -5.950694138844628, -5.96...</td>\n",
       "      <td>[0.049043737214825626, 0.11624832276308386, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.746940374655192, -6.992144524494609, -4.61...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8630504517521915, -4.69010704863332, -5.2...</td>\n",
       "      <td>[-6.840530818840689, -4.729312626905109, -5.21...</td>\n",
       "      <td>[0.03300027405190978, 0.040329207650596534, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.051873989189084, -5.837585594266053, -4.88...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.788147915702857, -4.910120991697232, -5.4...</td>\n",
       "      <td>[-5.8928536688605035, -4.947099605589861, -5.3...</td>\n",
       "      <td>[0.08600423802372432, 0.05053495664178832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.3566666666666665, -7.0, -5.853333333333333...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.433333333333334, -6.04, -5.38333333...</td>\n",
       "      <td>[-6.9093333333333335, -5.915333333333334, -6.2...</td>\n",
       "      <td>[0.04533333333333331, 0.3732178392782902, 0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-5.334094166192884, -6.481173596385949, -4.82...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.99987255157857, -5.052528453849139, -6.69...</td>\n",
       "      <td>[-7.1414070255219855, -5.264330438965572, -6.4...</td>\n",
       "      <td>[0.16236913724611685, 0.11795009375639318, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0         ExtraTreesRegressor   \n",
       "1               LGBMRegressor   \n",
       "2                XGBRegressor   \n",
       "3       DecisionTreeRegressor   \n",
       "4       RandomForestRegressor   \n",
       "5   GradientBoostingRegressor   \n",
       "6           AdaBoostRegressor   \n",
       "7                         SVR   \n",
       "8            LinearRegression   \n",
       "9         KNeighborsRegressor   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.682, -6.829199999999998, -5.6058, -5.39870...   \n",
       "1   [-6.474209958508049, -6.088745749683978, -5.12...   \n",
       "2   [-5.7332354, -6.5855656, -5.2311544, -5.181078...   \n",
       "3   [-7.0, -6.92, -5.15, -4.68, -5.15, -4.59, -4.7...   \n",
       "4   [-6.366176190476193, -6.334999999999999, -5.48...   \n",
       "5   [-5.661132826352657, -6.1049209987207815, -5.1...   \n",
       "6   [-5.746646566799839, -6.085248650371831, -5.67...   \n",
       "7   [-4.746940374655192, -6.992144524494609, -4.61...   \n",
       "8   [-5.051873989189084, -5.837585594266053, -4.88...   \n",
       "9   [-5.3566666666666665, -7.0, -5.853333333333333...   \n",
       "10  [-5.334094166192884, -6.481173596385949, -4.82...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.9338000000000015, -6.576300000000003, -6....   \n",
       "1   [[-6.658264488678373, -6.420684318030899, -6.7...   \n",
       "2   [[-6.3695793, -6.166127, -7.0612116, -5.902663...   \n",
       "3   [[-7.0, -6.24, -7.0, -5.89, -6.24, -7.0, -7.0,...   \n",
       "4   [[-6.8537, -6.423642857142861, -6.499599999999...   \n",
       "5   [[-6.030654600992403, -5.686372544162835, -6.0...   \n",
       "6   [[-5.954906012906758, -5.954906012906758, -5.7...   \n",
       "7   [[-6.8630504517521915, -4.69010704863332, -5.2...   \n",
       "8   [[-5.788147915702857, -4.910120991697232, -5.4...   \n",
       "9   [[-7.0, -5.433333333333334, -6.04, -5.38333333...   \n",
       "10  [[-6.99987255157857, -5.052528453849139, -6.69...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.92923, -6.662480000000002, -6.618329999999...   \n",
       "1   [-6.895847020647485, -6.4802321135909455, -6.6...   \n",
       "2   [-6.4050436, -6.4133353, -7.03028, -5.640264, ...   \n",
       "3   [-7.0, -6.08, -6.16, -5.758, -5.879, -6.334000...   \n",
       "4   [-6.760695796358002, -6.539240034453241, -6.30...   \n",
       "5   [-5.965359961798017, -5.722811104192969, -5.93...   \n",
       "6   [-5.996077476395867, -5.950694138844628, -5.96...   \n",
       "7   [-6.840530818840689, -4.729312626905109, -5.21...   \n",
       "8   [-5.8928536688605035, -4.947099605589861, -5.3...   \n",
       "9   [-6.9093333333333335, -5.915333333333334, -6.2...   \n",
       "10  [-7.1414070255219855, -5.264330438965572, -6.4...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.021276503472140735, 0.13309262038144554, 0....  \n",
       "1   [0.23526243115789805, 0.057434991655542326, 0....  \n",
       "2   [0.25567287, 0.19114357, 0.34366196, 0.1417031...  \n",
       "3   [0.0, 0.7593681584053944, 0.6914332939626208, ...  \n",
       "4   [0.14228066585014743, 0.0921094304859949, 0.13...  \n",
       "5   [0.07600969637957382, 0.06791902208528118, 0.1...  \n",
       "6   [0.049043737214825626, 0.11624832276308386, 0....  \n",
       "7   [0.03300027405190978, 0.040329207650596534, 0....  \n",
       "8   [0.08600423802372432, 0.05053495664178832, 0.0...  \n",
       "9   [0.04533333333333331, 0.3732178392782902, 0.23...  \n",
       "10  [0.16236913724611685, 0.11795009375639318, 0.1...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e785dfc1-c1ee-4947-910b-65866cf78c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('monomer_results/Monomer_comp_results.csv')\n",
    "prediction_df.to_csv('monomer_results/Monomer_comp_prediction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da34d420-9984-451d-9881-edfa6db2184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of constant columns\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    \n",
    "    df_cleaned = df.drop(columns=constant_columns)\n",
    "    \n",
    "    return df_cleaned, constant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbc2e0b-e2d4-43da-9fc4-fed695b0d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 243)\n",
      "(5568,)\n",
      "(1392, 243)\n",
      "(1392,)\n",
      "             A        dA       meA     Me_dA  Ala_indol_2_yl_  \\\n",
      "0    -0.501813 -0.349957  1.366587 -0.476635        -0.032844   \n",
      "1    -0.501813 -0.349957  1.366587  0.793660        -0.032844   \n",
      "2    -0.501813 -0.349957  1.366587 -0.476635        -0.032844   \n",
      "3     0.624153 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "4    -0.501813 -0.349957  1.366587  0.793660        -0.032844   \n",
      "...        ...       ...       ...       ...              ...   \n",
      "1387  4.752694 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1388  4.752694 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1389  3.439067 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1390 -0.501813 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1391  4.752694 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "\n",
      "      dAla_indol_2_yl_  Ala_5_Tet_       Abu      dAbu    Me_Abu  ...  \\\n",
      "0            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "2            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "3            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "4            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "...                ...         ...       ...       ...       ...  ...   \n",
      "1387         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1388         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1389         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1390         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1391         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "\n",
      "       Mono117   Mono118   Mono119   Mono120   Mono121   Mono122   Mono124  \\\n",
      "0    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "2    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "3    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "4    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1387 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1388 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1389 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1390 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1391 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "\n",
      "       Mono125   Mono126   Mono127  \n",
      "0    -0.013403 -0.018956 -0.013403  \n",
      "1    -0.013403 -0.018956 -0.013403  \n",
      "2    -0.013403 -0.018956 -0.013403  \n",
      "3    -0.013403 -0.018956 -0.013403  \n",
      "4    -0.013403 -0.018956 -0.013403  \n",
      "...        ...       ...       ...  \n",
      "1387 -0.013403 -0.018956 -0.013403  \n",
      "1388 -0.013403 -0.018956 -0.013403  \n",
      "1389 -0.013403 -0.018956 -0.013403  \n",
      "1390 -0.013403 -0.018956 -0.013403  \n",
      "1391 -0.013403 -0.018956 -0.013403  \n",
      "\n",
      "[1392 rows x 243 columns]\n",
      "0      -7.00\n",
      "1      -7.00\n",
      "2      -7.00\n",
      "3      -6.74\n",
      "4      -5.54\n",
      "        ... \n",
      "1387   -4.50\n",
      "1388   -4.80\n",
      "1389   -6.38\n",
      "1390   -7.80\n",
      "1391   -4.90\n",
      "Name: Permeability, Length: 1392, dtype: float64\n",
      "0.5470310601697982\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 591\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 606\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.5247288660538272\n",
      "0.5956636633193892\n",
      "0.49317712795029844\n",
      "0.5676183017952517\n",
      "0.4681992278625312\n",
      "0.22230573998860337\n",
      "0.500150101646058\n",
      "0.4252963062724473\n",
      "0.45508318415566695\n",
      "0.42317132153615533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.4079</td>\n",
       "      <td>0.5694</td>\n",
       "      <td>0.4794</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.3838</td>\n",
       "      <td>0.5354</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.7451</td>\n",
       "      <td>0.7145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.7728</td>\n",
       "      <td>0.7435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.4626</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.6344</td>\n",
       "      <td>0.6085</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2923</td>\n",
       "      <td>0.3911</td>\n",
       "      <td>0.5407</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.6935</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.5231</td>\n",
       "      <td>0.5676</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.3347</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.5786</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.5801</td>\n",
       "      <td>0.4682</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>0.6736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.5703</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.5416</td>\n",
       "      <td>0.4927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3201</td>\n",
       "      <td>0.4012</td>\n",
       "      <td>0.5657</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.6991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.3637</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.6031</td>\n",
       "      <td>0.4253</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.6680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3698</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>0.3448</td>\n",
       "      <td>0.4277</td>\n",
       "      <td>0.5872</td>\n",
       "      <td>0.4551</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>0.6522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4077</td>\n",
       "      <td>0.4313</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.3242                0.4079   \n",
       "LGBMRegressor                            0.3008                0.4004   \n",
       "XGBRegressor                             0.2699                0.3799   \n",
       "DecisionTreeRegressor                    0.4315                0.4626   \n",
       "RandomForestRegressor                    0.2923                0.3911   \n",
       "GradientBoostingRegressor                0.3347                0.4324   \n",
       "AdaBoostRegressor                        0.5151                0.5703   \n",
       "SVR                                      0.3201                0.4012   \n",
       "LinearRegression                         0.3840                0.4460   \n",
       "KNeighborsRegressor                      0.3698                0.4459   \n",
       "MLPRegressor                             0.4077                0.4313   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "ExtraTreesRegressor                       0.5694               0.4794   \n",
       "LGBMRegressor                             0.5485               0.5170   \n",
       "XGBRegressor                              0.5195               0.5666   \n",
       "DecisionTreeRegressor                     0.6569               0.3071   \n",
       "RandomForestRegressor                     0.5407               0.5306   \n",
       "GradientBoostingRegressor                 0.5786               0.4625   \n",
       "AdaBoostRegressor                         0.7177               0.1730   \n",
       "SVR                                       0.5657               0.4861   \n",
       "LinearRegression                          0.6196               0.3835   \n",
       "KNeighborsRegressor                       0.6081               0.4062   \n",
       "MLPRegressor                              0.6385               0.3454   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.7076                0.6773   \n",
       "LGBMRegressor                            0.7202                0.6958   \n",
       "XGBRegressor                             0.7528                0.7135   \n",
       "DecisionTreeRegressor                    0.6344                0.6085   \n",
       "RandomForestRegressor                    0.7304                0.6935   \n",
       "GradientBoostingRegressor                0.6905                0.6539   \n",
       "AdaBoostRegressor                        0.4929                0.4360   \n",
       "SVR                                      0.7012                0.6885   \n",
       "LinearRegression                         0.6264                0.6372   \n",
       "KNeighborsRegressor                      0.6521                0.6158   \n",
       "MLPRegressor                             0.6484                0.6709   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "ExtraTreesRegressor         0.2867   0.3838    0.5354  0.5470   \n",
       "LGBMRegressor               0.3008   0.4033    0.5484  0.5247   \n",
       "XGBRegressor                0.2559   0.3704    0.5058  0.5957   \n",
       "DecisionTreeRegressor       0.3207   0.4008    0.5663  0.4932   \n",
       "RandomForestRegressor       0.2736   0.3791    0.5231  0.5676   \n",
       "GradientBoostingRegressor   0.3365   0.4335    0.5801  0.4682   \n",
       "AdaBoostRegressor           0.4921   0.5640    0.7015  0.2223   \n",
       "SVR                         0.3163   0.3982    0.5624  0.5002   \n",
       "LinearRegression            0.3637   0.4399    0.6031  0.4253   \n",
       "KNeighborsRegressor         0.3448   0.4277    0.5872  0.4551   \n",
       "MLPRegressor                0.3650   0.4198    0.6042  0.4232   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "ExtraTreesRegressor                         0.7451                    0.7145  \n",
       "LGBMRegressor                               0.7259                    0.7057  \n",
       "XGBRegressor                                0.7728                    0.7435  \n",
       "DecisionTreeRegressor                       0.7186                    0.6920  \n",
       "RandomForestRegressor                       0.7538                    0.7218  \n",
       "GradientBoostingRegressor                   0.6959                    0.6736  \n",
       "AdaBoostRegressor                           0.5416                    0.4927  \n",
       "SVR                                         0.7107                    0.6991  \n",
       "LinearRegression                            0.6543                    0.6680  \n",
       "KNeighborsRegressor                         0.6821                    0.6522  \n",
       "MLPRegressor                                0.6814                    0.6916  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mc_train = pd.read_csv('Monomer_features/Train_mon_comp.csv')\n",
    "df_mc_train = clean_feature_names(df_mc_train)\n",
    "df_mc_train, const_col = remove_constant_columns(df_mc_train)\n",
    "X_train = df_mc_train.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "y_train = df_mc_train['Permeability']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "df_mc_test = pd.read_csv('Monomer_features/Test_mon_comp.csv')\n",
    "df_mc_test = clean_feature_names(df_mc_test)\n",
    "X_test = df_mc_test.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "X_test = X_test.drop(const_col, axis=1)\n",
    "y_test = df_mc_test['Permeability']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "models = [\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    SVR(),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3), \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f063b631-9ad3-4ba5-a651-802ca0706b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.720999999999999, -6.836799999999999, -5.62...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.9633, -6.477500000000004, -6.633549999999...</td>\n",
       "      <td>[-6.94846, -6.579693333333336, -6.58385, -6.13...</td>\n",
       "      <td>[0.020029438334611318, 0.0679120817266291, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.474209958508049, -6.088745749683978, -5.12...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.658264488678373, -6.420684318030899, -6.7...</td>\n",
       "      <td>[-6.895847020647485, -6.4802321135909455, -6.6...</td>\n",
       "      <td>[0.23526243115789805, 0.057434991655542326, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-5.7332354, -6.5855656, -5.2311544, -5.181078...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.3695793, -6.166127, -7.0612116, -5.902663...</td>\n",
       "      <td>[-6.4050436, -6.4133353, -7.03028, -5.640264, ...</td>\n",
       "      <td>[0.25567287, 0.19114357, 0.34366196, 0.1417031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.0, -6.92, -5.15, -4.68, -5.15, -5.04, -4.7...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.24, -6.92, -5.89, -6.24, -7.0, -7.0...</td>\n",
       "      <td>[-7.0, -6.08, -6.4079999999999995, -5.80200000...</td>\n",
       "      <td>[0.0, 0.7593681584053944, 0.6971484777290989, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.314800000000003, -6.355499999999998, -5.48...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.866200000000001, -6.3479000000000045, -6....</td>\n",
       "      <td>[-6.769855444444445, -6.521707277777781, -6.29...</td>\n",
       "      <td>[0.1357908885152214, 0.1017731964996332, 0.095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-5.661132826352657, -6.1049209987207815, -5.1...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.030654600992403, -5.686372544162835, -6.0...</td>\n",
       "      <td>[-5.965359961798017, -5.722811104192969, -5.93...</td>\n",
       "      <td>[0.07600969637957404, 0.06791902208528118, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.746646566799846, -6.085248650371841, -5.67...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.95490601290677, -5.95490601290677, -5.746...</td>\n",
       "      <td>[-5.993029782302644, -5.96964426654275, -5.962...</td>\n",
       "      <td>[0.04783613247453708, 0.08195349802888562, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-4.747084708363476, -6.991938546745366, -4.61...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.862979570324438, -4.6903321426120135, -5....</td>\n",
       "      <td>[-6.840600493445666, -4.729365327013005, -5.21...</td>\n",
       "      <td>[0.03295343652981298, 0.04023257183936915, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.051873989189086, -5.837585594266059, -4.88...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.788147915702867, -4.910120991697235, -5.4...</td>\n",
       "      <td>[-5.892853668860508, -4.947099605589864, -5.38...</td>\n",
       "      <td>[0.0860042380237223, 0.05053495664178806, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.3566666666666665, -7.0, -5.853333333333333...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -5.433333333333334, -6.04, -5.38333333...</td>\n",
       "      <td>[-6.9093333333333335, -5.915333333333334, -6.2...</td>\n",
       "      <td>[0.04533333333333331, 0.3732178392782902, 0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-5.21641633852669, -6.1025567579433595, -5.12...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.483884376570737, -4.941779578489587, -6.7...</td>\n",
       "      <td>[-7.524441437204364, -5.100643160287208, -6.58...</td>\n",
       "      <td>[0.08934472923693557, 0.20009340087779598, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0         ExtraTreesRegressor   \n",
       "1               LGBMRegressor   \n",
       "2                XGBRegressor   \n",
       "3       DecisionTreeRegressor   \n",
       "4       RandomForestRegressor   \n",
       "5   GradientBoostingRegressor   \n",
       "6           AdaBoostRegressor   \n",
       "7                         SVR   \n",
       "8            LinearRegression   \n",
       "9         KNeighborsRegressor   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.720999999999999, -6.836799999999999, -5.62...   \n",
       "1   [-6.474209958508049, -6.088745749683978, -5.12...   \n",
       "2   [-5.7332354, -6.5855656, -5.2311544, -5.181078...   \n",
       "3   [-7.0, -6.92, -5.15, -4.68, -5.15, -5.04, -4.7...   \n",
       "4   [-6.314800000000003, -6.355499999999998, -5.48...   \n",
       "5   [-5.661132826352657, -6.1049209987207815, -5.1...   \n",
       "6   [-5.746646566799846, -6.085248650371841, -5.67...   \n",
       "7   [-4.747084708363476, -6.991938546745366, -4.61...   \n",
       "8   [-5.051873989189086, -5.837585594266059, -4.88...   \n",
       "9   [-5.3566666666666665, -7.0, -5.853333333333333...   \n",
       "10  [-5.21641633852669, -6.1025567579433595, -5.12...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.9633, -6.477500000000004, -6.633549999999...   \n",
       "1   [[-6.658264488678373, -6.420684318030899, -6.7...   \n",
       "2   [[-6.3695793, -6.166127, -7.0612116, -5.902663...   \n",
       "3   [[-7.0, -6.24, -6.92, -5.89, -6.24, -7.0, -7.0...   \n",
       "4   [[-6.866200000000001, -6.3479000000000045, -6....   \n",
       "5   [[-6.030654600992403, -5.686372544162835, -6.0...   \n",
       "6   [[-5.95490601290677, -5.95490601290677, -5.746...   \n",
       "7   [[-6.862979570324438, -4.6903321426120135, -5....   \n",
       "8   [[-5.788147915702867, -4.910120991697235, -5.4...   \n",
       "9   [[-7.0, -5.433333333333334, -6.04, -5.38333333...   \n",
       "10  [[-7.483884376570737, -4.941779578489587, -6.7...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.94846, -6.579693333333336, -6.58385, -6.13...   \n",
       "1   [-6.895847020647485, -6.4802321135909455, -6.6...   \n",
       "2   [-6.4050436, -6.4133353, -7.03028, -5.640264, ...   \n",
       "3   [-7.0, -6.08, -6.4079999999999995, -5.80200000...   \n",
       "4   [-6.769855444444445, -6.521707277777781, -6.29...   \n",
       "5   [-5.965359961798017, -5.722811104192969, -5.93...   \n",
       "6   [-5.993029782302644, -5.96964426654275, -5.962...   \n",
       "7   [-6.840600493445666, -4.729365327013005, -5.21...   \n",
       "8   [-5.892853668860508, -4.947099605589864, -5.38...   \n",
       "9   [-6.9093333333333335, -5.915333333333334, -6.2...   \n",
       "10  [-7.524441437204364, -5.100643160287208, -6.58...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.020029438334611318, 0.0679120817266291, 0.1...  \n",
       "1   [0.23526243115789805, 0.057434991655542326, 0....  \n",
       "2   [0.25567287, 0.19114357, 0.34366196, 0.1417031...  \n",
       "3   [0.0, 0.7593681584053944, 0.6971484777290989, ...  \n",
       "4   [0.1357908885152214, 0.1017731964996332, 0.095...  \n",
       "5   [0.07600969637957404, 0.06791902208528118, 0.1...  \n",
       "6   [0.04783613247453708, 0.08195349802888562, 0.1...  \n",
       "7   [0.03295343652981298, 0.04023257183936915, 0.0...  \n",
       "8   [0.0860042380237223, 0.05053495664178806, 0.04...  \n",
       "9   [0.04533333333333331, 0.3732178392782902, 0.23...  \n",
       "10  [0.08934472923693557, 0.20009340087779598, 0.1...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50af241-fd2e-44c0-90d9-1e606bf4c198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ala_tBu_',\n",
       " 'Me_Ala_indol_2_yl_',\n",
       " 'Me_Abu_morpholino_',\n",
       " 'meD',\n",
       " 'Asp_Ph_2_NH2__',\n",
       " 'Glu_3R_Me_',\n",
       " 'Phe_CHF2_',\n",
       " 'Me_Phe_4_Cl_',\n",
       " 'Bn_4_OH__Gly',\n",
       " 'Bu_Gly',\n",
       " 'EtOEt_Gly',\n",
       " 'PhEt_Gly',\n",
       " 'isoamyl_Gly',\n",
       " '2_pyridylmethyl_Gly',\n",
       " 'Me_Hph',\n",
       " 'Hph_2_Cl_',\n",
       " 'Hph_3_Cl_',\n",
       " 'Hph_4_Cl_',\n",
       " 'Hse_Et_',\n",
       " 'Hyp_Et_',\n",
       " 'dK',\n",
       " 'meK',\n",
       " 'Me_dK',\n",
       " 'Lys_Cbz_',\n",
       " 'Lys_iPr_',\n",
       " 'Lys_Me_',\n",
       " 'Me_Lys_Me_',\n",
       " 'dLeu_3R_OH_',\n",
       " 'dN',\n",
       " 'Nle_CHF2_',\n",
       " 'Nle_OH_',\n",
       " 'Orn',\n",
       " '4Pal',\n",
       " 'dPip',\n",
       " 'Gln_Mes_',\n",
       " 'Ser_Bn_',\n",
       " 'Ser_EtNMe2_',\n",
       " 'Ser_EtOH_',\n",
       " 'Ser_isoamyl_',\n",
       " 'dSer_Me_',\n",
       " 'Ser_Ph_2_Cl__',\n",
       " 'Ser_Ph_3_Cl__',\n",
       " 'Ser_Pr_',\n",
       " 'Me_Ser_isoamyl_',\n",
       " 'Me_Ser_Pr_',\n",
       " 'dT',\n",
       " 'Me_Tza',\n",
       " '_N__O_Val',\n",
       " 'meW',\n",
       " 'Me_dW',\n",
       " 'Trp_6_Br_',\n",
       " 'Tyr_CHF2_',\n",
       " 'dTyr_bR_OMe_',\n",
       " '_N__O_Tyr',\n",
       " 'Mono3',\n",
       " 'Mono4',\n",
       " 'Mono5',\n",
       " 'Mono15',\n",
       " 'Mono17',\n",
       " 'Mono18',\n",
       " 'Mono19',\n",
       " 'Mono20',\n",
       " 'Mono23',\n",
       " 'Mono24',\n",
       " 'Mono25',\n",
       " 'Mono32',\n",
       " 'Mono33',\n",
       " 'Mono36',\n",
       " 'Mono48',\n",
       " 'Mono49',\n",
       " 'Mono50',\n",
       " 'Mono51',\n",
       " 'Mono52',\n",
       " 'Mono53',\n",
       " 'Mono54',\n",
       " 'Mono55',\n",
       " 'Mono56',\n",
       " 'Mono57',\n",
       " 'Mono58',\n",
       " 'Mono59',\n",
       " 'Mono60',\n",
       " 'Mono61',\n",
       " 'Mono62',\n",
       " 'Mono63',\n",
       " 'Mono64',\n",
       " 'Mono65',\n",
       " 'Mono66',\n",
       " 'Mono70',\n",
       " 'Mono75',\n",
       " 'Mono106',\n",
       " 'Mono107',\n",
       " 'deca_',\n",
       " 'Mono21_',\n",
       " 'Mono22_',\n",
       " 'Thr_O__S_',\n",
       " 'Ac3c',\n",
       " 'Abu_5_Tet_',\n",
       " 'Gly_allyl_',\n",
       " '_pyrro',\n",
       " 'Aze',\n",
       " 'Bal_d3_Me_',\n",
       " 'Me_Bal_d3_Me_',\n",
       " 'Bal_d3_EtPh_',\n",
       " 'meH',\n",
       " 'Phe_3_Cl_',\n",
       " 'Phe_3_F_',\n",
       " 'Phe_4_Cl_',\n",
       " 'Mono113',\n",
       " 'Ser_tBuOH_',\n",
       " 'Val_3_OH_',\n",
       " 'Mono114',\n",
       " 'Ac5c',\n",
       " 'Hph_4_CF3_3_5_diF_',\n",
       " 'Hph_4_Me_',\n",
       " 'Phe_3_5_diCl_',\n",
       " 'Hph_4_CF3_3_Cl_',\n",
       " 'Me_Phe_4_Me_',\n",
       " 'Hph_4_tBu_',\n",
       " 'Hph_3_4_diCl_',\n",
       " 'Hch',\n",
       " 'Phe_3_Cl_5_F_',\n",
       " 'Me_Gly_cPent_',\n",
       " 'Phe_3_CF3_',\n",
       " 'Et_Phe_4_Me_',\n",
       " 'Hph_4_CF3_',\n",
       " '_nme2',\n",
       " 'Me_Chg',\n",
       " 'Et_Leu',\n",
       " 'Me_Ser_Me_',\n",
       " 'Me_Hse_Me_',\n",
       " 'Gly_cPr_',\n",
       " 'Me_Gly_cPr_',\n",
       " 'Gly_cBu_',\n",
       " 'Me_Gly_cBu_',\n",
       " 'Gly_cPent_',\n",
       " 'Ala_cPr_',\n",
       " 'Ala_cBu_',\n",
       " 'Ala_cPent_',\n",
       " 'Me_Nva_F2_',\n",
       " '_mor',\n",
       " '_aze',\n",
       " 'Mono123']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "295d9e4d-0ec1-4df2-b0c1-52fb580bec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('monomer_results/Monomer_comp_constRemoval_results.csv')\n",
    "prediction_df.to_csv('monomer_results/Monomer_comp_constRemoval_prediction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66020e79-6888-4903-87d0-f9dcdd3795ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low variance column removal\n",
    "def remove_low_variance_columns(df, threshold=0.005):\n",
    "    # df = df.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "    variances = df.var()\n",
    "    \n",
    "    low_variance_columns = variances[variances < threshold].index.tolist()\n",
    "    \n",
    "    df_cleaned = df.drop(columns=low_variance_columns)\n",
    "    \n",
    "    return df_cleaned, low_variance_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65ac8b9e-d53a-418f-b54f-0d41ef6ebcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 8)\n",
      "(5568,)\n",
      "(1392, 8)\n",
      "(1392,)\n",
      "0.3410821104954864\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 159\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.33366136286539794\n",
      "0.34264205727543895\n",
      "0.32019316230017547\n",
      "0.3429105270253181\n",
      "0.3151606595086289\n",
      "0.13041446360181763\n",
      "0.26840356300069734\n",
      "0.1345080896155424\n",
      "0.25878869304819674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30401115376335774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4258</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.3164</td>\n",
       "      <td>0.5756</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.5887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>0.5587</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>0.4793</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>0.5790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>0.6480</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.5587</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.4738</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.5880</td>\n",
       "      <td>0.5932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4471</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.4782</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.5759</td>\n",
       "      <td>0.5829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.4176</td>\n",
       "      <td>0.4743</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.3294</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.5539</td>\n",
       "      <td>0.4158</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>0.6448</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.5863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.4363</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.2995</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.5661</td>\n",
       "      <td>0.5672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5762</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>0.7591</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.5503</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>0.7418</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.4476</td>\n",
       "      <td>0.4397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.4635</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.4839</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.5270</td>\n",
       "      <td>0.5342</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>0.4645</td>\n",
       "      <td>0.5477</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.5149</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.4691</td>\n",
       "      <td>0.4966</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.2588</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.2797</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>0.5602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.4258                0.4766   \n",
       "LGBMRegressor                            0.4141                0.4750   \n",
       "XGBRegressor                             0.4199                0.4734   \n",
       "DecisionTreeRegressor                    0.4471                0.4836   \n",
       "RandomForestRegressor                    0.4176                0.4743   \n",
       "GradientBoostingRegressor                0.4363                0.4902   \n",
       "AdaBoostRegressor                        0.5762                0.6014   \n",
       "SVR                                      0.4635                0.4803   \n",
       "LinearRegression                         0.5270                0.5342   \n",
       "KNeighborsRegressor                      0.5076                0.5149   \n",
       "MLPRegressor                             0.4486                0.4948   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "ExtraTreesRegressor                       0.6525               0.3164   \n",
       "LGBMRegressor                             0.6435               0.3351   \n",
       "XGBRegressor                              0.6480               0.3258   \n",
       "DecisionTreeRegressor                     0.6687               0.2821   \n",
       "RandomForestRegressor                     0.6462               0.3294   \n",
       "GradientBoostingRegressor                 0.6605               0.2995   \n",
       "AdaBoostRegressor                         0.7591               0.0749   \n",
       "SVR                                       0.6808               0.2558   \n",
       "LinearRegression                          0.7260               0.1538   \n",
       "KNeighborsRegressor                       0.7125               0.1850   \n",
       "MLPRegressor                              0.6698               0.2797   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.5756                0.5533   \n",
       "LGBMRegressor                            0.5789                0.5587   \n",
       "XGBRegressor                             0.5782                0.5587   \n",
       "DecisionTreeRegressor                    0.5556                0.5410   \n",
       "RandomForestRegressor                    0.5819                0.5539   \n",
       "GradientBoostingRegressor                0.5492                0.5422   \n",
       "AdaBoostRegressor                        0.3905                0.3941   \n",
       "SVR                                      0.5261                0.5353   \n",
       "LinearRegression                         0.3922                0.4645   \n",
       "KNeighborsRegressor                      0.5042                0.4922   \n",
       "MLPRegressor                             0.5298                0.5290   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "ExtraTreesRegressor         0.4170   0.4730    0.6457  0.3411   \n",
       "LGBMRegressor               0.4217   0.4793    0.6494  0.3337   \n",
       "XGBRegressor                0.4160   0.4738    0.6450  0.3426   \n",
       "DecisionTreeRegressor       0.4302   0.4782    0.6559  0.3202   \n",
       "RandomForestRegressor       0.4158   0.4734    0.6448  0.3429   \n",
       "GradientBoostingRegressor   0.4334   0.4866    0.6583  0.3152   \n",
       "AdaBoostRegressor           0.5503   0.5930    0.7418  0.1304   \n",
       "SVR                         0.4630   0.4839    0.6804  0.2684   \n",
       "LinearRegression            0.5477   0.5426    0.7401  0.1345   \n",
       "KNeighborsRegressor         0.4691   0.4966    0.6849  0.2588   \n",
       "MLPRegressor                0.4404   0.4926    0.6637  0.3040   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "ExtraTreesRegressor                         0.5889                    0.5887  \n",
       "LGBMRegressor                               0.5779                    0.5790  \n",
       "XGBRegressor                                0.5880                    0.5932  \n",
       "DecisionTreeRegressor                       0.5759                    0.5829  \n",
       "RandomForestRegressor                       0.5888                    0.5863  \n",
       "GradientBoostingRegressor                   0.5661                    0.5672  \n",
       "AdaBoostRegressor                           0.4476                    0.4397  \n",
       "SVR                                         0.5368                    0.5524  \n",
       "LinearRegression                            0.3682                    0.4534  \n",
       "KNeighborsRegressor                         0.5357                    0.5318  \n",
       "MLPRegressor                                0.5514                    0.5602  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('Monomer_features/Train_mon_comp.csv')\n",
    "df_mc_train = clean_feature_names(df_train)\n",
    "df_mc_train = df_mc_train.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "df_mc, const_col = remove_low_variance_columns(df_mc_train)\n",
    "X_train = df_mc\n",
    "y_train = df_train['Permeability']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "df_mc_test = pd.read_csv('Monomer_features/Test_mon_comp.csv')\n",
    "df_mc_test = clean_feature_names(df_mc_test)\n",
    "X_test = df_mc_test.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "X_test = X_test.drop(const_col, axis=1)\n",
    "y_test = df_mc_test['Permeability']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    SVR(),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3), \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43ea6004-3a96-4345-82ca-0b8f22a4c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('monomer_results/Monomer_comp_LVR_results.csv')\n",
    "prediction_df.to_csv('monomer_results/Monomer_comp_LVR_prediction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618ef44-efdb-4f1e-a7d2-8a85fd7ee3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25dcca27-3a21-4d34-b1ec-10543f0a0b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 21)\n",
      "(5568,)\n",
      "(1392, 21)\n",
      "(1392,)\n",
      "0.3606185478919217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 265\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 269\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 268\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 265\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 270\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.3644562695422914\n",
      "0.36628191424893963\n",
      "0.35139236063605694\n",
      "0.36318954077957966\n",
      "0.32951084787063223\n",
      "0.1458382098218206\n",
      "0.314115089061067\n",
      "0.22777349189948604\n",
      "0.1353300653405174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31262581423987024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>0.6236</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>0.6361</td>\n",
       "      <td>0.3606</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.5487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.3945</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.5264</td>\n",
       "      <td>0.4022</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>0.6342</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.3997</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.6322</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.6063</td>\n",
       "      <td>0.5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4287</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.4105</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.6407</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.5430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.3914</td>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>0.4663</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.5483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.4115</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>0.3392</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.4243</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.3295</td>\n",
       "      <td>0.5746</td>\n",
       "      <td>0.5231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5533</td>\n",
       "      <td>0.5967</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.4306</td>\n",
       "      <td>0.3858</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.4328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.3141</td>\n",
       "      <td>0.5729</td>\n",
       "      <td>0.5254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.2018</td>\n",
       "      <td>0.4494</td>\n",
       "      <td>0.4145</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.2278</td>\n",
       "      <td>0.4777</td>\n",
       "      <td>0.4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.5524</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.5194</td>\n",
       "      <td>0.4883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.5611</td>\n",
       "      <td>0.5020</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.3126</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>0.5222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.3889                0.4635   \n",
       "LGBMRegressor                            0.3945                0.4723   \n",
       "XGBRegressor                             0.3997                0.4704   \n",
       "DecisionTreeRegressor                    0.4287                0.4822   \n",
       "RandomForestRegressor                    0.3914                0.4671   \n",
       "GradientBoostingRegressor                0.4115                0.4887   \n",
       "AdaBoostRegressor                        0.5533                0.5967   \n",
       "SVR                                      0.4200                0.4721   \n",
       "LinearRegression                         0.4971                0.5382   \n",
       "KNeighborsRegressor                      0.5524                0.5548   \n",
       "MLPRegressor                             0.4302                0.4892   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "ExtraTreesRegressor                       0.6236               0.3756   \n",
       "LGBMRegressor                             0.6281               0.3666   \n",
       "XGBRegressor                              0.6322               0.3583   \n",
       "DecisionTreeRegressor                     0.6547               0.3117   \n",
       "RandomForestRegressor                     0.6256               0.3716   \n",
       "GradientBoostingRegressor                 0.6415               0.3392   \n",
       "AdaBoostRegressor                         0.7438               0.1116   \n",
       "SVR                                       0.6481               0.3256   \n",
       "LinearRegression                          0.7051               0.2018   \n",
       "KNeighborsRegressor                       0.7432               0.1130   \n",
       "MLPRegressor                              0.6559               0.3093   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.6142                0.5286   \n",
       "LGBMRegressor                            0.6055                0.5264   \n",
       "XGBRegressor                             0.6006                0.5190   \n",
       "DecisionTreeRegressor                    0.5720                0.4987   \n",
       "RandomForestRegressor                    0.6099                0.5288   \n",
       "GradientBoostingRegressor                0.5838                0.4987   \n",
       "AdaBoostRegressor                        0.4306                0.3858   \n",
       "SVR                                      0.5822                0.5071   \n",
       "LinearRegression                         0.4494                0.4145   \n",
       "KNeighborsRegressor                      0.5079                0.4470   \n",
       "MLPRegressor                             0.5611                0.5020   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "ExtraTreesRegressor         0.4046   0.4665    0.6361  0.3606   \n",
       "LGBMRegressor               0.4022   0.4697    0.6342  0.3645   \n",
       "XGBRegressor                0.4010   0.4632    0.6333  0.3663   \n",
       "DecisionTreeRegressor       0.4105   0.4696    0.6407  0.3514   \n",
       "RandomForestRegressor       0.4030   0.4663    0.6348  0.3632   \n",
       "GradientBoostingRegressor   0.4243   0.4899    0.6514  0.3295   \n",
       "AdaBoostRegressor           0.5405   0.5939    0.7352  0.1458   \n",
       "SVR                         0.4340   0.4680    0.6588  0.3141   \n",
       "LinearRegression            0.4887   0.5294    0.6991  0.2278   \n",
       "KNeighborsRegressor         0.5472   0.5442    0.7397  0.1353   \n",
       "MLPRegressor                0.4350   0.4851    0.6595  0.3126   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "ExtraTreesRegressor                         0.6028                    0.5487  \n",
       "LGBMRegressor                               0.6037                    0.5489  \n",
       "XGBRegressor                                0.6063                    0.5524  \n",
       "DecisionTreeRegressor                       0.5961                    0.5430  \n",
       "RandomForestRegressor                       0.6032                    0.5483  \n",
       "GradientBoostingRegressor                   0.5746                    0.5231  \n",
       "AdaBoostRegressor                           0.4498                    0.4328  \n",
       "SVR                                         0.5729                    0.5254  \n",
       "LinearRegression                            0.4777                    0.4461  \n",
       "KNeighborsRegressor                         0.5194                    0.4883  \n",
       "MLPRegressor                                0.5628                    0.5222  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AA composition\n",
    "df_aac_train = pd.read_csv('Monomer_features/Train_aac.csv')\n",
    "X_train = df_aac_train.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "y_train = df_aac_train['Permeability']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "df_aac_test = pd.read_csv('Monomer_features/Test_aac.csv')\n",
    "X_test = df_aac_test.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "y_test = df_aac_test['Permeability']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    SVR(),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3), \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "aac_comp,prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "aac_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2f80429-f863-4202-8507-3d6ecaf665b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.467900000000003, -6.799633333333327, -6.36...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.856399999999997, -6.240000000000006, -6.7...</td>\n",
       "      <td>[-6.890009999999999, -6.372850000000005, -6.79...</td>\n",
       "      <td>[0.05233085514302277, 0.26569999999999644, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.819708776899031, -6.741522957198804, -5.88...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8824174200856305, -6.732630090516726, -6....</td>\n",
       "      <td>[-6.852068279536186, -6.59581741369701, -6.403...</td>\n",
       "      <td>[0.11170179221897755, 0.17425490343377098, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.53945, -6.331082, -6.351551, -5.277498, -5...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.6684756, -6.428478, -6.665841, -6.5263243...</td>\n",
       "      <td>[-6.78958, -6.3500047, -6.774565, -6.413087, -...</td>\n",
       "      <td>[0.16713886, 0.06491435, 0.2544896, 0.19761877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-6.24, -6.89, -5.88, -5.92, -5.88, -4.6850000...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.24, -7.0, -7.0, -7.0, -6.7866666666...</td>\n",
       "      <td>[-7.0, -6.392, -6.006, -6.698, -6.848000000000...</td>\n",
       "      <td>[0.0, 0.3039999999999999, 0.8215984420627878, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.662025, -6.649999999999997, -6.19659666666...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.731189444444443, -6.425633333333335, -6.5...</td>\n",
       "      <td>[-6.705324055555556, -6.4566971111111116, -6.4...</td>\n",
       "      <td>[0.033727279222509725, 0.1051401933965135, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-5.6719335838951555, -5.80558682864085, -5.81...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.6719335838951555, -6.166947448380577, -5....</td>\n",
       "      <td>[-5.707385290317585, -6.063318291225626, -5.75...</td>\n",
       "      <td>[0.038115408217044726, 0.13052320412081825, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.679886214442038, -5.858147654584215, -5.58...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.679886214442038, -5.655448717948713, -5.6...</td>\n",
       "      <td>[-5.678199179006834, -5.672434775988421, -5.67...</td>\n",
       "      <td>[0.012810614882255955, 0.015089402287063593, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.927183211254778, -5.841334576665473, -4.91...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.986617529188543, -5.706267302243386, -6.2...</td>\n",
       "      <td>[-6.8633311727334725, -5.711928660349113, -6.0...</td>\n",
       "      <td>[0.07100479555606345, 0.06968864693284889, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-4.725680904639959, -4.998135232151143, -5.08...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-4.964648579345606, -4.822410898603708, -5.1...</td>\n",
       "      <td>[-4.997225506437236, -4.858070408550772, -5.09...</td>\n",
       "      <td>[0.030655284748342598, 0.032966270644718604, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.633333333333333, -6.936666666666667, -4.53...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.973333333333334, -5.3500000000000005, -7....</td>\n",
       "      <td>[-6.8933333333333335, -5.826666666666666, -6.0...</td>\n",
       "      <td>[0.04173993557999636, 0.29902805516837017, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.221991933160721, -5.946272218393931, -5.11...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.804810980351168, -6.015232497391475, -6.2...</td>\n",
       "      <td>[-6.745631109714326, -6.018362779182618, -6.24...</td>\n",
       "      <td>[0.17317956290528008, 0.12340836672416369, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0         ExtraTreesRegressor   \n",
       "1               LGBMRegressor   \n",
       "2                XGBRegressor   \n",
       "3       DecisionTreeRegressor   \n",
       "4       RandomForestRegressor   \n",
       "5   GradientBoostingRegressor   \n",
       "6           AdaBoostRegressor   \n",
       "7                         SVR   \n",
       "8            LinearRegression   \n",
       "9         KNeighborsRegressor   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.467900000000003, -6.799633333333327, -6.36...   \n",
       "1   [-6.819708776899031, -6.741522957198804, -5.88...   \n",
       "2   [-6.53945, -6.331082, -6.351551, -5.277498, -5...   \n",
       "3   [-6.24, -6.89, -5.88, -5.92, -5.88, -4.6850000...   \n",
       "4   [-6.662025, -6.649999999999997, -6.19659666666...   \n",
       "5   [-5.6719335838951555, -5.80558682864085, -5.81...   \n",
       "6   [-5.679886214442038, -5.858147654584215, -5.58...   \n",
       "7   [-5.927183211254778, -5.841334576665473, -4.91...   \n",
       "8   [-4.725680904639959, -4.998135232151143, -5.08...   \n",
       "9   [-5.633333333333333, -6.936666666666667, -4.53...   \n",
       "10  [-6.221991933160721, -5.946272218393931, -5.11...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.856399999999997, -6.240000000000006, -6.7...   \n",
       "1   [[-6.8824174200856305, -6.732630090516726, -6....   \n",
       "2   [[-6.6684756, -6.428478, -6.665841, -6.5263243...   \n",
       "3   [[-7.0, -6.24, -7.0, -7.0, -7.0, -6.7866666666...   \n",
       "4   [[-6.731189444444443, -6.425633333333335, -6.5...   \n",
       "5   [[-5.6719335838951555, -6.166947448380577, -5....   \n",
       "6   [[-5.679886214442038, -5.655448717948713, -5.6...   \n",
       "7   [[-6.986617529188543, -5.706267302243386, -6.2...   \n",
       "8   [[-4.964648579345606, -4.822410898603708, -5.1...   \n",
       "9   [[-6.973333333333334, -5.3500000000000005, -7....   \n",
       "10  [[-6.804810980351168, -6.015232497391475, -6.2...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.890009999999999, -6.372850000000005, -6.79...   \n",
       "1   [-6.852068279536186, -6.59581741369701, -6.403...   \n",
       "2   [-6.78958, -6.3500047, -6.774565, -6.413087, -...   \n",
       "3   [-7.0, -6.392, -6.006, -6.698, -6.848000000000...   \n",
       "4   [-6.705324055555556, -6.4566971111111116, -6.4...   \n",
       "5   [-5.707385290317585, -6.063318291225626, -5.75...   \n",
       "6   [-5.678199179006834, -5.672434775988421, -5.67...   \n",
       "7   [-6.8633311727334725, -5.711928660349113, -6.0...   \n",
       "8   [-4.997225506437236, -4.858070408550772, -5.09...   \n",
       "9   [-6.8933333333333335, -5.826666666666666, -6.0...   \n",
       "10  [-6.745631109714326, -6.018362779182618, -6.24...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.05233085514302277, 0.26569999999999644, 0.0...  \n",
       "1   [0.11170179221897755, 0.17425490343377098, 0.1...  \n",
       "2   [0.16713886, 0.06491435, 0.2544896, 0.19761877...  \n",
       "3   [0.0, 0.3039999999999999, 0.8215984420627878, ...  \n",
       "4   [0.033727279222509725, 0.1051401933965135, 0.1...  \n",
       "5   [0.038115408217044726, 0.13052320412081825, 0....  \n",
       "6   [0.012810614882255955, 0.015089402287063593, 0...  \n",
       "7   [0.07100479555606345, 0.06968864693284889, 0.1...  \n",
       "8   [0.030655284748342598, 0.032966270644718604, 0...  \n",
       "9   [0.04173993557999636, 0.29902805516837017, 0.6...  \n",
       "10  [0.17317956290528008, 0.12340836672416369, 0.0...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec1d3e07-e7e6-4852-8606-b87a5ce9d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "aac_comp.to_csv('monomer_results/AAC_comp_results.csv')\n",
    "prediction_df.to_csv('monomer_results/AAC_comp_prediction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f96a3ca1-87ef-460b-b313-c4875967e31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 21)\n",
      "(5568,)\n",
      "(1392, 21)\n",
      "(1392,)\n"
     ]
    }
   ],
   "source": [
    "#Constant column removal\n",
    "df_mc_train = pd.read_csv('Monomer_features/Train_aac.csv')\n",
    "df_mc_train, const_col = remove_constant_columns(df_mc_train)\n",
    "X_train = df_mc_train.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "y_train = df_mc_train['Permeability']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "df_mc_test = pd.read_csv('Monomer_features/Test_aac.csv')\n",
    "X_test = df_mc_test.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "X_test = X_test.drop(const_col, axis=1)\n",
    "y_test = df_mc_test['Permeability']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5545901e-6e17-493c-820c-ad6610f49260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 5)\n",
      "(5568,)\n",
      "(1392, 5)\n",
      "(1392,)\n",
      "0.31690614824044205\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.33769393702977923\n",
      "0.33228087327834843\n",
      "0.3033609669747078\n",
      "0.32655721350798705\n",
      "0.31060766174926024\n",
      "0.17790950903393166\n",
      "0.27161707424918013\n",
      "0.12214114709275181\n",
      "0.0507035873032351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2867090237170975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.5594</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.4323</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.5662</td>\n",
       "      <td>0.4961</td>\n",
       "      <td>0.4191</td>\n",
       "      <td>0.4809</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>0.5814</td>\n",
       "      <td>0.5292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>0.4226</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.3323</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.4558</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>0.4839</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.3034</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.5219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.4219</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.3226</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>0.4787</td>\n",
       "      <td>0.6528</td>\n",
       "      <td>0.3266</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>0.5325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.4433</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.4703</td>\n",
       "      <td>0.4363</td>\n",
       "      <td>0.4972</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.3106</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>0.5811</td>\n",
       "      <td>0.7213</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>0.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>0.6912</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.4906</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>0.5406</td>\n",
       "      <td>0.4884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.5534</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.3339</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.5736</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.3502</td>\n",
       "      <td>0.3441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.5849</td>\n",
       "      <td>0.7946</td>\n",
       "      <td>-0.0137</td>\n",
       "      <td>0.4307</td>\n",
       "      <td>0.3815</td>\n",
       "      <td>0.6007</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>0.4423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.4688</td>\n",
       "      <td>0.5163</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.2472</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>0.4468</td>\n",
       "      <td>0.4514</td>\n",
       "      <td>0.5043</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.5383</td>\n",
       "      <td>0.4959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.4320                0.4836   \n",
       "LGBMRegressor                            0.4231                0.4885   \n",
       "XGBRegressor                             0.4300                0.4832   \n",
       "DecisionTreeRegressor                    0.4558                0.4910   \n",
       "RandomForestRegressor                    0.4219                0.4814   \n",
       "GradientBoostingRegressor                0.4433                0.5038   \n",
       "AdaBoostRegressor                        0.5377                0.5881   \n",
       "SVR                                      0.4778                0.4995   \n",
       "LinearRegression                         0.5534                0.5745   \n",
       "KNeighborsRegressor                      0.6313                0.5849   \n",
       "MLPRegressor                             0.4688                0.5163   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "ExtraTreesRegressor                       0.6573               0.3063   \n",
       "LGBMRegressor                             0.6505               0.3206   \n",
       "XGBRegressor                              0.6557               0.3096   \n",
       "DecisionTreeRegressor                     0.6752               0.2681   \n",
       "RandomForestRegressor                     0.6496               0.3226   \n",
       "GradientBoostingRegressor                 0.6658               0.2883   \n",
       "AdaBoostRegressor                         0.7333               0.1367   \n",
       "SVR                                       0.6912               0.2329   \n",
       "LinearRegression                          0.7439               0.1115   \n",
       "KNeighborsRegressor                       0.7946              -0.0137   \n",
       "MLPRegressor                              0.6847               0.2472   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.5594                0.4943   \n",
       "LGBMRegressor                            0.5662                0.4961   \n",
       "XGBRegressor                             0.5620                0.4931   \n",
       "DecisionTreeRegressor                    0.5364                0.4785   \n",
       "RandomForestRegressor                    0.5699                0.4953   \n",
       "GradientBoostingRegressor                0.5377                0.4703   \n",
       "AdaBoostRegressor                        0.4386                0.3955   \n",
       "SVR                                      0.5027                0.4557   \n",
       "LinearRegression                         0.3339                0.3312   \n",
       "KNeighborsRegressor                      0.4307                0.3815   \n",
       "MLPRegressor                             0.4979                0.4468   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "ExtraTreesRegressor         0.4323   0.4803    0.6575  0.3169   \n",
       "LGBMRegressor               0.4191   0.4809    0.6474  0.3377   \n",
       "XGBRegressor                0.4226   0.4755    0.6500  0.3323   \n",
       "DecisionTreeRegressor       0.4409   0.4839    0.6640  0.3034   \n",
       "RandomForestRegressor       0.4262   0.4787    0.6528  0.3266   \n",
       "GradientBoostingRegressor   0.4363   0.4972    0.6605  0.3106   \n",
       "AdaBoostRegressor           0.5202   0.5811    0.7213  0.1779   \n",
       "SVR                         0.4609   0.4906    0.6789  0.2716   \n",
       "LinearRegression            0.5555   0.5736    0.7453  0.1221   \n",
       "KNeighborsRegressor         0.6007   0.5677    0.7751  0.0507   \n",
       "MLPRegressor                0.4514   0.5043    0.6719  0.2867   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "ExtraTreesRegressor                         0.5685                    0.5282  \n",
       "LGBMRegressor                               0.5814                    0.5292  \n",
       "XGBRegressor                                0.5795                    0.5322  \n",
       "DecisionTreeRegressor                       0.5599                    0.5219  \n",
       "RandomForestRegressor                       0.5739                    0.5325  \n",
       "GradientBoostingRegressor                   0.5597                    0.5123  \n",
       "AdaBoostRegressor                           0.4770                    0.4540  \n",
       "SVR                                         0.5406                    0.4884  \n",
       "LinearRegression                            0.3502                    0.3441  \n",
       "KNeighborsRegressor                         0.4589                    0.4423  \n",
       "MLPRegressor                                0.5383                    0.4959  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LVR column removal\n",
    "df_mc_train = pd.read_csv('Monomer_features/Train_aac.csv')\n",
    "X_train = df_mc_train.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "X_train, const_col = remove_low_variance_columns(X_train)\n",
    "\n",
    "y_train = df_mc_train['Permeability']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "df_mc_test = pd.read_csv('Monomer_features/Test_aac.csv')\n",
    "X_test = df_mc_test.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "X_test = X_test.drop(const_col, axis=1)\n",
    "y_test = df_mc_test['Permeability']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models_mc = [\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    SVR(),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3), \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models_mc, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8daadb4-7e43-4bec-a7a1-d95c2d8332e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('monomer_results/AAC_comp_LVR_results.csv')\n",
    "prediction_df.to_csv('monomer_results/AAC_comp_LVR_prediction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b779c93a-5d1d-4ed4-a593-2e0161cfcc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.142719047619044, -6.180599999999997, -5.94...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.339573809523806, -6.620000000000004, -5.4...</td>\n",
       "      <td>[-5.826437587301586, -6.620000000000003, -5.79...</td>\n",
       "      <td>[0.2909876448670126, 0.2403331021727948, 0.208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-5.976825451316693, -5.887059516210813, -5.99...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.923473547800348, -6.244154870974508, -6.1...</td>\n",
       "      <td>[-5.893191470346106, -5.986203698348892, -5.99...</td>\n",
       "      <td>[0.07449471667393556, 0.18380319668265066, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-6.6075077, -6.0224543, -5.993145, -5.842207,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.4230413, -6.5967507, -6.5607395, -6.14823...</td>\n",
       "      <td>[-6.545579, -6.606382, -6.6169686, -6.1833873,...</td>\n",
       "      <td>[0.24737814, 0.26260722, 0.23212905, 0.2083770...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-5.835, -4.68, -6.62, -5.92, -5.88, -4.55, -4...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.96, -6.62, -5.65, -6.126666666666666, -7....</td>\n",
       "      <td>[-6.984, -6.62, -6.2275, -6.126666666666667, -...</td>\n",
       "      <td>[0.01959591794226544, 0.24033310217279674, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.162554557109558, -5.606467142857142, -6.10...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.109942771395271, -6.538520000000001, -6.1...</td>\n",
       "      <td>[-6.163444914474415, -6.446531666666668, -6.09...</td>\n",
       "      <td>[0.2980911340070613, 0.18822081674340704, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.126947156479217, -5.212574111973634, -5.81...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.098635754560118, -5.2132252966222, -6.130...</td>\n",
       "      <td>[-5.72037334503896, -5.2236408739114815, -5.66...</td>\n",
       "      <td>[0.21353816733169637, 0.09392775506445697, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-5.46850810810811, -5.46850810810811, -5.8252...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.46850810810811, -5.327770382695508, -5.46...</td>\n",
       "      <td>[-5.435808819875936, -5.430541770134086, -5.43...</td>\n",
       "      <td>[0.053288430056596385, 0.051931924586600155, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-5.035739048515927, -5.09510980483286, -5.086...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-4.900920359456845, -4.670978845536693, -4.8...</td>\n",
       "      <td>[-4.937783119503217, -4.613126966572476, -4.82...</td>\n",
       "      <td>[0.06061003804844521, 0.03672591032708144, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.200498365394476, -5.337586828677065, -5.10...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.216527926195354, -5.347950483023906, -5.2...</td>\n",
       "      <td>[-5.223138485234157, -5.3589403902088595, -5.2...</td>\n",
       "      <td>[0.014302159346596418, 0.013000734351834633, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-5.706666666666667, -6.28, -4.663333333333333...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-4.95, -5.926666666666667, -5.37666666666666...</td>\n",
       "      <td>[-5.012, -5.666666666666666, -5.164, -5.844666...</td>\n",
       "      <td>[0.2203391325510141, 0.32276582498427253, 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-5.315595947504323, -5.446872469687541, -5.47...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-5.2345698739174455, -4.998711618425122, -5....</td>\n",
       "      <td>[-5.209933960013004, -4.975309410939316, -5.07...</td>\n",
       "      <td>[0.042761473387865755, 0.06906178393708097, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0         ExtraTreesRegressor   \n",
       "1               LGBMRegressor   \n",
       "2                XGBRegressor   \n",
       "3       DecisionTreeRegressor   \n",
       "4       RandomForestRegressor   \n",
       "5   GradientBoostingRegressor   \n",
       "6           AdaBoostRegressor   \n",
       "7                         SVR   \n",
       "8            LinearRegression   \n",
       "9         KNeighborsRegressor   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.142719047619044, -6.180599999999997, -5.94...   \n",
       "1   [-5.976825451316693, -5.887059516210813, -5.99...   \n",
       "2   [-6.6075077, -6.0224543, -5.993145, -5.842207,...   \n",
       "3   [-5.835, -4.68, -6.62, -5.92, -5.88, -4.55, -4...   \n",
       "4   [-6.162554557109558, -5.606467142857142, -6.10...   \n",
       "5   [-6.126947156479217, -5.212574111973634, -5.81...   \n",
       "6   [-5.46850810810811, -5.46850810810811, -5.8252...   \n",
       "7   [-5.035739048515927, -5.09510980483286, -5.086...   \n",
       "8   [-5.200498365394476, -5.337586828677065, -5.10...   \n",
       "9   [-5.706666666666667, -6.28, -4.663333333333333...   \n",
       "10  [-5.315595947504323, -5.446872469687541, -5.47...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-5.339573809523806, -6.620000000000004, -5.4...   \n",
       "1   [[-5.923473547800348, -6.244154870974508, -6.1...   \n",
       "2   [[-6.4230413, -6.5967507, -6.5607395, -6.14823...   \n",
       "3   [[-6.96, -6.62, -5.65, -6.126666666666666, -7....   \n",
       "4   [[-6.109942771395271, -6.538520000000001, -6.1...   \n",
       "5   [[-6.098635754560118, -5.2132252966222, -6.130...   \n",
       "6   [[-5.46850810810811, -5.327770382695508, -5.46...   \n",
       "7   [[-4.900920359456845, -4.670978845536693, -4.8...   \n",
       "8   [[-5.216527926195354, -5.347950483023906, -5.2...   \n",
       "9   [[-4.95, -5.926666666666667, -5.37666666666666...   \n",
       "10  [[-5.2345698739174455, -4.998711618425122, -5....   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-5.826437587301586, -6.620000000000003, -5.79...   \n",
       "1   [-5.893191470346106, -5.986203698348892, -5.99...   \n",
       "2   [-6.545579, -6.606382, -6.6169686, -6.1833873,...   \n",
       "3   [-6.984, -6.62, -6.2275, -6.126666666666667, -...   \n",
       "4   [-6.163444914474415, -6.446531666666668, -6.09...   \n",
       "5   [-5.72037334503896, -5.2236408739114815, -5.66...   \n",
       "6   [-5.435808819875936, -5.430541770134086, -5.43...   \n",
       "7   [-4.937783119503217, -4.613126966572476, -4.82...   \n",
       "8   [-5.223138485234157, -5.3589403902088595, -5.2...   \n",
       "9   [-5.012, -5.666666666666666, -5.164, -5.844666...   \n",
       "10  [-5.209933960013004, -4.975309410939316, -5.07...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.2909876448670126, 0.2403331021727948, 0.208...  \n",
       "1   [0.07449471667393556, 0.18380319668265066, 0.1...  \n",
       "2   [0.24737814, 0.26260722, 0.23212905, 0.2083770...  \n",
       "3   [0.01959591794226544, 0.24033310217279674, 0.9...  \n",
       "4   [0.2980911340070613, 0.18822081674340704, 0.25...  \n",
       "5   [0.21353816733169637, 0.09392775506445697, 0.2...  \n",
       "6   [0.053288430056596385, 0.051931924586600155, 0...  \n",
       "7   [0.06061003804844521, 0.03672591032708144, 0.0...  \n",
       "8   [0.014302159346596418, 0.013000734351834633, 0...  \n",
       "9   [0.2203391325510141, 0.32276582498427253, 0.32...  \n",
       "10  [0.042761473387865755, 0.06906178393708097, 0....  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b8fa70d-ab24-423c-ac9a-ed59e6c0f184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W',\n",
       " 'H',\n",
       " 'M',\n",
       " 'X',\n",
       " 'E',\n",
       " 'Q',\n",
       " 'T',\n",
       " 'N',\n",
       " 'D',\n",
       " 'V',\n",
       " 'Y',\n",
       " 'S',\n",
       " 'C',\n",
       " 'R',\n",
       " 'I',\n",
       " 'K']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8815aa7-5d0d-4762-8638-a715daa6c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def train_and_test_predict_with_tuning(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "   \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        best_params = None\n",
    "\n",
    "        # hyperparameter tuning \n",
    "        if model_name in param_grids and param_grids[model_name]:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model, \n",
    "                param_grid=param_grids[model_name], \n",
    "                cv=kf,\n",
    "                scoring='neg_mean_squared_error', \n",
    "                n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            print(model_name)\n",
    "            print(\": best params\",best_params)\n",
    "        else:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            best_params = {}\n",
    "            print(model_name, ':Used Default params')\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)  \n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "            'Best Parameters': best_params\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44af8e9e-ccc9-4d8d-8275-399ac830b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "        'ExtraTreesRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None,1,5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'LGBMRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'num_leaves': [31, 50, 100]\n",
    "        },\n",
    "        'DecisionTreeRegressor': {\n",
    "            'max_depth': [None, 10, 20, 50, 100],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'RandomForestRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None, 1, 5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'GradientBoostingRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7, 10]\n",
    "        },\n",
    "        'AdaBoostRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.1, 1.0]\n",
    "        },\n",
    "        'SVR': {\n",
    "            'C': [0.001, 0.1, 1, 10],\n",
    "            'epsilon': [0.1, 0.2, 0.5],\n",
    "            'gamma': [0.001, 0.1, 1, 10]\n",
    "        },\n",
    "        'KNeighborsRegressor': {\n",
    "            'n_neighbors': [3, 5, 10],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        },\n",
    "        'MLPRegressor': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'learning_rate': ['constant', 'adaptive'],\n",
    "            'max_iter': [100,200, 400]\n",
    "}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3fb5380-1761-43e7-87b8-4e3702d127c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 243)\n",
      "(5568,)\n",
      "(1392, 243)\n",
      "(1392,)\n",
      "             A        dA       meA     Me_dA  Ala_indol_2_yl_  \\\n",
      "0    -0.501813 -0.349957  1.366587 -0.476635        -0.032844   \n",
      "1    -0.501813 -0.349957  1.366587  0.793660        -0.032844   \n",
      "2    -0.501813 -0.349957  1.366587 -0.476635        -0.032844   \n",
      "3     0.624153 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "4    -0.501813 -0.349957  1.366587  0.793660        -0.032844   \n",
      "...        ...       ...       ...       ...              ...   \n",
      "1387  4.752694 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1388  4.752694 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1389  3.439067 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1390 -0.501813 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "1391  4.752694 -0.349957 -0.555249 -0.476635        -0.032844   \n",
      "\n",
      "      dAla_indol_2_yl_  Ala_5_Tet_       Abu      dAbu    Me_Abu  ...  \\\n",
      "0            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "2            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "3            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "4            -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "...                ...         ...       ...       ...       ...  ...   \n",
      "1387         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1388         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1389         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1390         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "1391         -0.013403   -0.023154 -0.122013 -0.107696 -0.052596  ...   \n",
      "\n",
      "       Mono117   Mono118   Mono119   Mono120   Mono121   Mono122   Mono124  \\\n",
      "0    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "2    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "3    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "4    -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1387 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1388 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1389 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1390 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "1391 -0.023218 -0.013403 -0.018956 -0.013403 -0.013403 -0.026812 -0.023218   \n",
      "\n",
      "       Mono125   Mono126   Mono127  \n",
      "0    -0.013403 -0.018956 -0.013403  \n",
      "1    -0.013403 -0.018956 -0.013403  \n",
      "2    -0.013403 -0.018956 -0.013403  \n",
      "3    -0.013403 -0.018956 -0.013403  \n",
      "4    -0.013403 -0.018956 -0.013403  \n",
      "...        ...       ...       ...  \n",
      "1387 -0.013403 -0.018956 -0.013403  \n",
      "1388 -0.013403 -0.018956 -0.013403  \n",
      "1389 -0.013403 -0.018956 -0.013403  \n",
      "1390 -0.013403 -0.018956 -0.013403  \n",
      "1391 -0.013403 -0.018956 -0.013403  \n",
      "\n",
      "[1392 rows x 243 columns]\n",
      "0      -7.00\n",
      "1      -7.00\n",
      "2      -7.00\n",
      "3      -6.74\n",
      "4      -5.54\n",
      "        ... \n",
      "1387   -4.50\n",
      "1388   -4.80\n",
      "1389   -6.38\n",
      "1390   -7.80\n",
      "1391   -4.90\n",
      "Name: Permeability, Length: 1392, dtype: float64\n",
      "ExtraTreesRegressor : Default params {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n",
      "ExtraTreesRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.5692078298248289\n",
      "LGBMRegressor : Default params {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': 'regression', 'random_state': 101, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 639\n",
      "[LightGBM] [Info] Number of data points in the train set: 5568, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score -5.742906\n",
      "LGBMRegressor\n",
      ": best params {'learning_rate': 0.1, 'n_estimators': 400, 'num_leaves': 50}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 591\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 606\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6024570957198273\n",
      "XGBRegressor : Default params {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 101, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "XGBRegressor :Used Default params\n",
      "0.5956636633193892\n",
      "DecisionTreeRegressor : Default params {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 101, 'splitter': 'best'}\n",
      "DecisionTreeRegressor\n",
      ": best params {'max_depth': 20, 'min_samples_split': 10}\n",
      "0.5504048675557893\n",
      "RandomForestRegressor : Default params {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n",
      "RandomForestRegressor\n",
      ": best params {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 400}\n",
      "0.5787788747743442\n",
      "GradientBoostingRegressor : Default params {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 101, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "GradientBoostingRegressor\n",
      ": best params {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 400}\n",
      "0.6056997793297143\n",
      "AdaBoostRegressor : Default params {'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 101}\n",
      "AdaBoostRegressor\n",
      ": best params {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.2521888782538284\n",
      "SVR : Default params {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "SVR\n",
      ": best params {'C': 10, 'epsilon': 0.2, 'gamma': 0.001}\n",
      "0.5027726689044454\n",
      "LinearRegression : Default params {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
      "LinearRegression :Used Default params\n",
      "0.4252963062724473\n",
      "KNeighborsRegressor : Default params {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "KNeighborsRegressor\n",
      ": best params {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.45451030881561594\n",
      "MLPRegressor : Default params {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 101, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "MLPRegressor\n",
      ": best params {'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 200}\n",
      "0.45384678260928724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.3798</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.7548</td>\n",
       "      <td>0.7267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.7456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.7728</td>\n",
       "      <td>0.7435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.5977</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>0.3842</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.7431</td>\n",
       "      <td>0.7150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.3845</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>0.2666</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.5163</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>0.7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.3712</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.7465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.4825</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.2253</td>\n",
       "      <td>0.4749</td>\n",
       "      <td>0.4591</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.5209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.3997</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.7084</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.3147</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.6959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.3994</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.3637</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.6031</td>\n",
       "      <td>0.4253</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.6680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3548</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>0.3452</td>\n",
       "      <td>0.4271</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.6504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>1.4668</td>\n",
       "      <td>0.5407</td>\n",
       "      <td>1.2111</td>\n",
       "      <td>-1.3551</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.4092</td>\n",
       "      <td>0.5879</td>\n",
       "      <td>0.4538</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.7038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.2794                0.3866   \n",
       "LGBMRegressor                            0.2694                0.3732   \n",
       "XGBRegressor                             0.2699                0.3799   \n",
       "DecisionTreeRegressor                    0.3572                0.4278   \n",
       "RandomForestRegressor                    0.2798                0.3845   \n",
       "GradientBoostingRegressor                0.2629                0.3712   \n",
       "AdaBoostRegressor                        0.4825                0.5214   \n",
       "SVR                                      0.3118                0.3997   \n",
       "LinearRegression                         0.3994                0.4479   \n",
       "KNeighborsRegressor                      0.3548                0.4380   \n",
       "MLPRegressor                             1.4668                0.5407   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "ExtraTreesRegressor                       0.5286               0.5514   \n",
       "LGBMRegressor                             0.5191               0.5674   \n",
       "XGBRegressor                              0.5195               0.5666   \n",
       "DecisionTreeRegressor                     0.5977               0.4264   \n",
       "RandomForestRegressor                     0.5290               0.5507   \n",
       "GradientBoostingRegressor                 0.5127               0.5779   \n",
       "AdaBoostRegressor                         0.6946               0.2253   \n",
       "SVR                                       0.5584               0.4993   \n",
       "LinearRegression                          0.6319               0.3588   \n",
       "KNeighborsRegressor                       0.5957               0.4303   \n",
       "MLPRegressor                              1.2111              -1.3551   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "ExtraTreesRegressor                      0.7426                0.7083   \n",
       "LGBMRegressor                            0.7552                0.7209   \n",
       "XGBRegressor                             0.7528                0.7135   \n",
       "DecisionTreeRegressor                    0.6740                0.6369   \n",
       "RandomForestRegressor                    0.7422                0.7077   \n",
       "GradientBoostingRegressor                0.7605                0.7257   \n",
       "AdaBoostRegressor                        0.4749                0.4591   \n",
       "SVR                                      0.7084                0.6880   \n",
       "LinearRegression                         0.6116                0.6371   \n",
       "KNeighborsRegressor                      0.6612                0.6292   \n",
       "MLPRegressor                             0.3818                0.6638   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "ExtraTreesRegressor         0.2726   0.3798    0.5221  0.5692   \n",
       "LGBMRegressor               0.2516   0.3656    0.5016  0.6025   \n",
       "XGBRegressor                0.2559   0.3704    0.5058  0.5957   \n",
       "DecisionTreeRegressor       0.2845   0.3842    0.5334  0.5504   \n",
       "RandomForestRegressor       0.2666   0.3769    0.5163  0.5788   \n",
       "GradientBoostingRegressor   0.2495   0.3645    0.4995  0.6057   \n",
       "AdaBoostRegressor           0.4732   0.5162    0.6879  0.2522   \n",
       "SVR                         0.3147   0.3986    0.5609  0.5028   \n",
       "LinearRegression            0.3637   0.4399    0.6031  0.4253   \n",
       "KNeighborsRegressor         0.3452   0.4271    0.5875  0.4545   \n",
       "MLPRegressor                0.3456   0.4092    0.5879  0.4538   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "ExtraTreesRegressor                         0.7548                    0.7267  \n",
       "LGBMRegressor                               0.7763                    0.7456  \n",
       "XGBRegressor                                0.7728                    0.7435  \n",
       "DecisionTreeRegressor                       0.7431                    0.7150  \n",
       "RandomForestRegressor                       0.7612                    0.7328  \n",
       "GradientBoostingRegressor                   0.7784                    0.7465  \n",
       "AdaBoostRegressor                           0.5047                    0.5209  \n",
       "SVR                                         0.7107                    0.6959  \n",
       "LinearRegression                            0.6543                    0.6680  \n",
       "KNeighborsRegressor                         0.6775                    0.6504  \n",
       "MLPRegressor                                0.6936                    0.7038  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mc_train = pd.read_csv('Monomer_features/Train_mon_comp.csv')\n",
    "df_mc_train = clean_feature_names(df_mc_train)\n",
    "df_mc_train, const_col = remove_constant_columns(df_mc_train)\n",
    "X_train = df_mc_train.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "y_train = df_mc_train['Permeability']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "df_mc_test = pd.read_csv('Monomer_features/Test_mon_comp.csv')\n",
    "df_mc_test = clean_feature_names(df_mc_test)\n",
    "X_test = df_mc_test.drop(['ID','SMILES','Permeability'], axis=1)\n",
    "X_test = X_test.drop(const_col, axis=1)\n",
    "y_test = df_mc_test['Permeability']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "models = [\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    SVR(),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3), \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict_with_tuning(models,param_grids, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437765ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('monomer_results/Monomer_comp_constRemoval_results_with_HPT.csv')\n",
    "prediction_df.to_csv('monomer_results/Monomer_comp_constRemoval_prediction_data_with_HPT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928d3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
