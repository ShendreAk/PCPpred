{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84288433-5420-437e-b514-6abf8e97fd2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:41:55.271787Z",
     "iopub.status.busy": "2025-07-13T05:41:55.271153Z",
     "iopub.status.idle": "2025-07-13T05:42:34.880313Z",
     "shell.execute_reply": "2025-07-13T05:42:34.879614Z",
     "shell.execute_reply.started": "2025-07-13T05:41:55.271762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.44.2\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib==1.4.2\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn==1.6.0\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Collecting scipy==1.13.1\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting seaborn==0.13.2\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting tqdm==4.66.5\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lightgbm==4.5.0 in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
      "Collecting xgboost==2.1.3\n",
      "  Downloading xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.33.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.0) (3.6.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2025.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn==0.13.2) (3.7.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.3) (2.21.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (11.2.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4) (2024.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.6.15)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4) (2024.2.0)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, joblib, tokenizers, scipy, xgboost, transformers, seaborn, scikit-learn\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.5.1\n",
      "    Uninstalling joblib-1.5.1:\n",
      "      Successfully uninstalled joblib-1.5.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 2.0.3\n",
      "    Uninstalling xgboost-2.0.3:\n",
      "      Successfully uninstalled xgboost-2.0.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.52.4\n",
      "    Uninstalling transformers-4.52.4:\n",
      "      Successfully uninstalled transformers-4.52.4\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.12.2\n",
      "    Uninstalling seaborn-0.12.2:\n",
      "      Successfully uninstalled seaborn-0.12.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.0 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "dataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\n",
      "dataproc-spark-connect 0.7.5 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.13.1 seaborn-0.13.2 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.2 xgboost-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.44.2 joblib==1.4.2 scikit-learn==1.6.0 numpy==1.26.4 pandas==2.2.3 scipy==1.13.1 seaborn==0.13.2 tqdm==4.66.5 lightgbm==4.5.0 xgboost==2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc766717-d639-4b08-9e79-ba48029fcd2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:42:34.881957Z",
     "iopub.status.busy": "2025-07-13T05:42:34.881704Z",
     "iopub.status.idle": "2025-07-13T05:42:42.252540Z",
     "shell.execute_reply": "2025-07-13T05:42:42.251957Z",
     "shell.execute_reply.started": "2025-07-13T05:42:34.881935Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109dc695-32ca-46eb-90cf-42effd239247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:42:42.253516Z",
     "iopub.status.busy": "2025-07-13T05:42:42.253199Z",
     "iopub.status.idle": "2025-07-13T05:42:42.313311Z",
     "shell.execute_reply": "2025-07-13T05:42:42.312407Z",
     "shell.execute_reply.started": "2025-07-13T05:42:42.253498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('/kaggle/input/caco2-set/Train_Caco2.csv')\n",
    "train_df = train_df[['ID', 'SMILES', 'Permeability']]\n",
    "test_df = pd.read_csv('/kaggle/input/caco2-set/Test_Caco2.csv')\n",
    "test_df = test_df[['ID', 'SMILES', 'Permeability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee412c8-292e-411f-bea8-942deede8c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:42:42.315358Z",
     "iopub.status.busy": "2025-07-13T05:42:42.315045Z",
     "iopub.status.idle": "2025-07-13T05:42:46.752053Z",
     "shell.execute_reply": "2025-07-13T05:42:46.751530Z",
     "shell.execute_reply.started": "2025-07-13T05:42:42.315337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03dbc8c81224f79992b6424ecc0410d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a559b1dc9f6c4544ba2afaf49ec0ec78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/501 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fc313dd4c14e0d81fcc135ded454c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00d443aa1104d49a194a7b09ff4b73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768b039e12a64f538ab1da175b39da3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be529e957209410face226381d2233d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/179M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('seyonec/ChemBERTa-zinc-base-v1', num_labels=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Custom dataset class\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=325):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataframe = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.dataframe.iloc[idx]['SMILES']\n",
    "        permeability = self.dataframe.iloc[idx]['Permeability']\n",
    "        inputs = self.tokenizer(smiles, return_tensors='pt', padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
    "        \n",
    "        input_ids = inputs['input_ids'].squeeze(0)  # Shape: (sequence_length,)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)  # Shape: (sequence_length,)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(permeability, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "# datasets\n",
    "train_dataset = SMILESDataset(train_df, tokenizer)\n",
    "test_dataset = SMILESDataset(test_df, tokenizer)\n",
    "batch_size = 16\n",
    "# data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fcb1e8f-19b7-4eb7-83d1-7c6fa60c34d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:42:46.753289Z",
     "iopub.status.busy": "2025-07-13T05:42:46.752824Z",
     "iopub.status.idle": "2025-07-13T05:42:49.737296Z",
     "shell.execute_reply": "2025-07-13T05:42:49.736451Z",
     "shell.execute_reply.started": "2025-07-13T05:42:46.753265Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61be98f-eaa3-4229-a5a9-462cc1373814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:42:49.738492Z",
     "iopub.status.busy": "2025-07-13T05:42:49.738197Z",
     "iopub.status.idle": "2025-07-13T05:53:24.147722Z",
     "shell.execute_reply": "2025-07-13T05:53:24.146960Z",
     "shell.execute_reply.started": "2025-07-13T05:42:49.738467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 63/63 [00:27<00:00,  2.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 2.1308\n",
      "Entered Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 63/63 [00:28<00:00,  2.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.5081\n",
      "Entered Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 63/63 [00:30<00:00,  2.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.4456\n",
      "Entered Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 63/63 [00:33<00:00,  1.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.3594\n",
      "Entered Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 63/63 [00:31<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 0.3161\n",
      "Entered Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 63/63 [00:31<00:00,  1.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.2577\n",
      "Entered Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 63/63 [00:32<00:00,  1.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.2299\n",
      "Entered Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 63/63 [00:31<00:00,  1.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.2073\n",
      "Entered Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 63/63 [00:31<00:00,  1.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.1795\n",
      "Entered Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 63/63 [00:32<00:00,  1.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.1754\n",
      "Entered Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 63/63 [00:32<00:00,  1.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.1369\n",
      "Entered Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 63/63 [00:32<00:00,  1.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train Loss: 0.1235\n",
      "Entered Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 63/63 [00:32<00:00,  1.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train Loss: 0.1276\n",
      "Entered Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 63/63 [00:32<00:00,  1.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Train Loss: 0.1145\n",
      "Entered Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 63/63 [00:32<00:00,  1.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train Loss: 0.1171\n",
      "Entered Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 63/63 [00:32<00:00,  1.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Train Loss: 0.1249\n",
      "Entered Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 63/63 [00:31<00:00,  1.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Train Loss: 0.1082\n",
      "Entered Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 63/63 [00:32<00:00,  1.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Train Loss: 0.0886\n",
      "Entered Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 63/63 [00:32<00:00,  1.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Train Loss: 0.0990\n",
      "Entered Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 63/63 [00:31<00:00,  1.97batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Train Loss: 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Entered Epoch {epoch + 1}\")\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{num_epochs}', unit='batch'):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move all batch tensors to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        labels = batch[\"labels\"].unsqueeze(1)  # still shape: (batch_size, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backprop and optimizer step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62f46a1-d12c-4425-9202-09c9a5fa7955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:24.148653Z",
     "iopub.status.busy": "2025-07-13T05:53:24.148469Z",
     "iopub.status.idle": "2025-07-13T05:53:24.832660Z",
     "shell.execute_reply": "2025-07-13T05:53:24.831765Z",
     "shell.execute_reply.started": "2025-07-13T05:53:24.148639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to /kaggle/working/ChemBERTa_model_1_caco2\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ChemBERTa_model_1_caco2'\n",
    "model_save_path = f'/kaggle/working/{model_name}'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "print(f'Model and tokenizer saved to {model_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f1a62ea-c30c-476d-9d60-f6581c33ed77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:24.833905Z",
     "iopub.status.busy": "2025-07-13T05:53:24.833633Z",
     "iopub.status.idle": "2025-07-13T05:53:27.801862Z",
     "shell.execute_reply": "2025-07-13T05:53:27.801036Z",
     "shell.execute_reply.started": "2025-07-13T05:53:24.833883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 16/16 [00:02<00:00,  5.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3105\n",
      "(252,)\n",
      "(252,)\n",
      "Mean Squared Error: 0.3050\n",
      "Root Mean Squared Error: 0.5523\n",
      "Mean Absolute Error: 0.4132\n",
      "R^2 Score: 0.4730\n",
      "Pearson Correlation Coefficient: 0.7284\n",
      "Spearman Correlation Coefficient: 0.7029\n",
      "Hyperparameters:\n",
      "Learning Rate: 5e-05\n",
      "Batch Size: 16\n",
      "Epochs: 20\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_true_labels = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing', unit='batch'):\n",
    "      \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].unsqueeze(1).to(device).float()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        test_true_labels.extend(labels.cpu().numpy())\n",
    "        preds = outputs.logits.squeeze().cpu().numpy()  \n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Final test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "test_true_labels = np.array(test_true_labels).flatten()\n",
    "predictions = np.array(predictions)\n",
    "print(test_true_labels.shape)\n",
    "print(predictions.shape)\n",
    "\n",
    "# Performance metrics\n",
    "mse = mean_squared_error(test_true_labels, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_true_labels, predictions)\n",
    "r2 = r2_score(test_true_labels, predictions)\n",
    "PCC,_ = pearsonr(test_true_labels, predictions)\n",
    "SCC,_ = spearmanr(test_true_labels, predictions)\n",
    "# Print performance metrics\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "print(f'R^2 Score: {r2:.4f}')\n",
    "print(f'Pearson Correlation Coefficient: {PCC:.4f}')\n",
    "print(f'Spearman Correlation Coefficient: {SCC:.4f}')\n",
    "\n",
    "# Print hyperparameters\n",
    "print(\"Hyperparameters:\")\n",
    "print(f\"Learning Rate: {5e-5}\")\n",
    "print(f\"Batch Size: 16\")\n",
    "print(f\"Epochs: {num_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adefe671-a9fc-47be-b130-7fab5f6f756b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:27.803407Z",
     "iopub.status.busy": "2025-07-13T05:53:27.802810Z",
     "iopub.status.idle": "2025-07-13T05:53:27.965432Z",
     "shell.execute_reply": "2025-07-13T05:53:27.964893Z",
     "shell.execute_reply.started": "2025-07-13T05:53:27.803387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /kaggle/working/ChemBERTa_model_1_caco2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "model_name = 'ChemBERTa_model_1_caco2'\n",
    "model_save_path = f'/kaggle/working/{model_name}'\n",
    "\n",
    "if not os.path.exists(model_save_path):\n",
    "    raise FileNotFoundError(f\"The model directory {model_save_path} does not exist.\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
    "model = AutoModel.from_pretrained(model_save_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98f2535-4295-4f81-9b76-a8ddbbb21ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:27.967532Z",
     "iopub.status.busy": "2025-07-13T05:53:27.967334Z",
     "iopub.status.idle": "2025-07-13T05:53:27.994282Z",
     "shell.execute_reply": "2025-07-13T05:53:27.993786Z",
     "shell.execute_reply.started": "2025-07-13T05:53:27.967500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your datasets\n",
    "train_df = pd.read_csv('/kaggle/input/caco2-set/Train_Caco2.csv')\n",
    "train_df = train_df[['ID', 'SMILES', 'Permeability']]\n",
    "test_df = pd.read_csv('/kaggle/input/caco2-set/Test_Caco2.csv')\n",
    "test_df = test_df[['ID', 'SMILES', 'Permeability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dd54789-f68a-4d25-8cbe-084bad256e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:27.995199Z",
     "iopub.status.busy": "2025-07-13T05:53:27.994928Z",
     "iopub.status.idle": "2025-07-13T05:53:28.255484Z",
     "shell.execute_reply": "2025-07-13T05:53:28.254901Z",
     "shell.execute_reply.started": "2025-07-13T05:53:27.995181Z"
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_df['SMILES']), truncation=True, padding=True, max_length=325, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(list(test_df['SMILES']), truncation=True, padding=True, max_length=325, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e912c89-8c40-4af7-911b-3a59dc51ae53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:28.256416Z",
     "iopub.status.busy": "2025-07-13T05:53:28.256196Z",
     "iopub.status.idle": "2025-07-13T05:53:28.261866Z",
     "shell.execute_reply": "2025-07-13T05:53:28.261030Z",
     "shell.execute_reply.started": "2025-07-13T05:53:28.256399Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "batch_size = 16 \n",
    "\n",
    "def generate_embeddings(encodings, batch_size):\n",
    "    embeddings = []\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(encodings['input_ids']), batch_size), desc=\"Processing batches\"):\n",
    "            batch = {key: val[i:i + batch_size].to(device) for key, val in encodings.items()}  \n",
    "            outputs = model(**batch)\n",
    "            embeddings.append(outputs.last_hidden_state)\n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ce6c97-b15e-45ee-b27d-1e5c866af4ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:28.263423Z",
     "iopub.status.busy": "2025-07-13T05:53:28.262850Z",
     "iopub.status.idle": "2025-07-13T05:53:35.968691Z",
     "shell.execute_reply": "2025-07-13T05:53:35.968130Z",
     "shell.execute_reply.started": "2025-07-13T05:53:28.263399Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 63/63 [00:07<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1008, 216, 768])\n",
      "torch.Size([1008, 768])\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = generate_embeddings(train_encodings, batch_size)\n",
    "print(train_embeddings.shape)\n",
    "train_embeddings = torch.mean(train_embeddings, dim=1)\n",
    "print(train_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c38aa6-4a99-4b4e-a7e7-7642132dbd3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:35.969682Z",
     "iopub.status.busy": "2025-07-13T05:53:35.969400Z",
     "iopub.status.idle": "2025-07-13T05:53:35.983702Z",
     "shell.execute_reply": "2025-07-13T05:53:35.983126Z",
     "shell.execute_reply.started": "2025-07-13T05:53:35.969660Z"
    }
   },
   "outputs": [],
   "source": [
    "column_names = [f'x_fine_emb_ChemBerta{i}' for i in range(train_embeddings.shape[1])]\n",
    "embeddings_df = pd.DataFrame(data=train_embeddings.cpu().numpy(), columns=column_names)\n",
    "train_data = pd.concat([train_df, embeddings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "731bc240-755a-4a58-b19f-a6c85acb7a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:35.984628Z",
     "iopub.status.busy": "2025-07-13T05:53:35.984377Z",
     "iopub.status.idle": "2025-07-13T05:53:37.815462Z",
     "shell.execute_reply": "2025-07-13T05:53:37.814795Z",
     "shell.execute_reply.started": "2025-07-13T05:53:35.984612Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 16/16 [00:01<00:00,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([252, 210, 768])\n",
      "torch.Size([252, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = generate_embeddings(test_encodings, batch_size)\n",
    "print(test_embeddings.shape)\n",
    "test_embeddings = torch.mean(test_embeddings, dim=1)\n",
    "print(test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38563979-f8b2-4c17-8cca-71f8c9552409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:37.816500Z",
     "iopub.status.busy": "2025-07-13T05:53:37.816228Z",
     "iopub.status.idle": "2025-07-13T05:53:37.890711Z",
     "shell.execute_reply": "2025-07-13T05:53:37.890109Z",
     "shell.execute_reply.started": "2025-07-13T05:53:37.816473Z"
    }
   },
   "outputs": [],
   "source": [
    "column_names = [f'x_fine_emb_ChemBerta{i}' for i in range(test_embeddings.shape[1])]\n",
    "embeddings_df = pd.DataFrame(data=test_embeddings.cpu().numpy(), columns=column_names)\n",
    "test_data = pd.concat([test_df, embeddings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1469e31d-d4fe-49ca-86c4-1f698ccbfe23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:37.891831Z",
     "iopub.status.busy": "2025-07-13T05:53:37.891553Z",
     "iopub.status.idle": "2025-07-13T05:53:38.890951Z",
     "shell.execute_reply": "2025-07-13T05:53:38.890148Z",
     "shell.execute_reply.started": "2025-07-13T05:53:37.891806Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"/kaggle/working/Train_ChemBERTa-zinc-base-v1_fine_tuned_embeddings_caco2.csv\",index=False)\n",
    "test_data.to_csv(\"/kaggle/working/Test_ChemBERTa-zinc-base-v1_fine_tuned_embeddings_caco2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fce81d4a-17fa-453a-9ae2-777dbb1e0502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:38.892139Z",
     "iopub.status.busy": "2025-07-13T05:53:38.891837Z",
     "iopub.status.idle": "2025-07-13T05:53:44.839235Z",
     "shell.execute_reply": "2025-07-13T05:53:44.838646Z",
     "shell.execute_reply.started": "2025-07-13T05:53:38.892111Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e6fbc54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:44.840516Z",
     "iopub.status.busy": "2025-07-13T05:53:44.839899Z",
     "iopub.status.idle": "2025-07-13T05:53:45.050338Z",
     "shell.execute_reply": "2025-07-13T05:53:45.049682Z",
     "shell.execute_reply.started": "2025-07-13T05:53:44.840494Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/working/Train_ChemBERTa-zinc-base-v1_fine_tuned_embeddings_caco2.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/working/Test_ChemBERTa-zinc-base-v1_fine_tuned_embeddings_caco2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc56be41-55fb-4de1-a9c0-731c9c9111c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:45.051452Z",
     "iopub.status.busy": "2025-07-13T05:53:45.051183Z",
     "iopub.status.idle": "2025-07-13T05:53:45.061422Z",
     "shell.execute_reply": "2025-07-13T05:53:45.060814Z",
     "shell.execute_reply.started": "2025-07-13T05:53:45.051429Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ce12566-eb05-49c7-b8ba-49c660313da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:53:45.062280Z",
     "iopub.status.busy": "2025-07-13T05:53:45.062023Z",
     "iopub.status.idle": "2025-07-13T05:59:01.596264Z",
     "shell.execute_reply": "2025-07-13T05:59:01.595629Z",
     "shell.execute_reply.started": "2025-07-13T05:53:45.062251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1008, 768)\n",
      "y_train shape:  (1008,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (252, 768)\n",
      "y_test shape:  (252,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -6.296846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -6.274773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 806, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -6.275399\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -6.296788\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 807, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -6.281145\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.5179338779688449\n",
      "0.5113477725557756\n",
      "0.5151444229296693\n",
      "0.5217784262535334\n",
      "0.5263048091043662\n",
      "0.5183064369975443\n",
      "0.5215567812370222\n",
      "-0.6313358274747622\n",
      "0.535741124319264\n",
      "0.5242140705917916\n",
      "0.43135540565055774\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.2404</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.3946</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.7090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.2366</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.3962</td>\n",
       "      <td>0.5297</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9516</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.3915</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.9486</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>0.7066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.7097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>2.2865</td>\n",
       "      <td>1.1810</td>\n",
       "      <td>1.5121</td>\n",
       "      <td>-2.7709</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>-0.6313</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.4508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.7121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.2753</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.7105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2748</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.4314</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.6496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.0578                0.1766   \n",
       "DecisionTreeRegressor                    0.1109                0.2501   \n",
       "RandomForestRegressor                    0.0560                0.1744   \n",
       "GradientBoostingRegressor                0.0572                0.1769   \n",
       "AdaBoostRegressor                        0.0615                0.1870   \n",
       "XGBRegressor                             0.0689                0.1920   \n",
       "ExtraTreesRegressor                      0.0585                0.1751   \n",
       "LinearRegression                         2.2865                1.1810   \n",
       "KNeighborsRegressor                      0.0732                0.1983   \n",
       "SVR                                      0.0544                0.1699   \n",
       "MLPRegressor                             0.2748                0.3981   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.2404               0.9047   \n",
       "DecisionTreeRegressor                     0.3330               0.8172   \n",
       "RandomForestRegressor                     0.2366               0.9077   \n",
       "GradientBoostingRegressor                 0.2393               0.9056   \n",
       "AdaBoostRegressor                         0.2480               0.8986   \n",
       "XGBRegressor                              0.2626               0.8863   \n",
       "ExtraTreesRegressor                       0.2420               0.9034   \n",
       "LinearRegression                          1.5121              -2.7709   \n",
       "KNeighborsRegressor                       0.2705               0.8793   \n",
       "SVR                                       0.2333               0.9103   \n",
       "MLPRegressor                              0.5242               0.5468   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.9512                0.9381   \n",
       "DecisionTreeRegressor                    0.9078                0.8869   \n",
       "RandomForestRegressor                    0.9528                0.9392   \n",
       "GradientBoostingRegressor                0.9516                0.9379   \n",
       "AdaBoostRegressor                        0.9486                0.9358   \n",
       "XGBRegressor                             0.9415                0.9273   \n",
       "ExtraTreesRegressor                      0.9505                0.9382   \n",
       "LinearRegression                         0.4015                0.3900   \n",
       "KNeighborsRegressor                      0.9381                0.9186   \n",
       "SVR                                      0.9541                0.9431   \n",
       "MLPRegressor                             0.8031                0.7882   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE  Test R2  \\\n",
       "LGBMRegressor               0.2790   0.3946    0.5282   0.5179   \n",
       "DecisionTreeRegressor       0.2828   0.4026    0.5318   0.5113   \n",
       "RandomForestRegressor       0.2806   0.3962    0.5297   0.5151   \n",
       "GradientBoostingRegressor   0.2768   0.3915    0.5261   0.5218   \n",
       "AdaBoostRegressor           0.2741   0.3948    0.5236   0.5263   \n",
       "XGBRegressor                0.2788   0.4008    0.5280   0.5183   \n",
       "ExtraTreesRegressor         0.2769   0.3972    0.5262   0.5216   \n",
       "LinearRegression            0.9441   0.7144    0.9716  -0.6313   \n",
       "KNeighborsRegressor         0.2687   0.3857    0.5183   0.5357   \n",
       "SVR                         0.2753   0.3952    0.5247   0.5242   \n",
       "MLPRegressor                0.3291   0.4499    0.5737   0.4314   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7312                    0.7090  \n",
       "DecisionTreeRegressor                       0.7290                    0.7069  \n",
       "RandomForestRegressor                       0.7279                    0.7080  \n",
       "GradientBoostingRegressor                   0.7327                    0.7111  \n",
       "AdaBoostRegressor                           0.7306                    0.7035  \n",
       "XGBRegressor                                0.7296                    0.7066  \n",
       "ExtraTreesRegressor                         0.7315                    0.7097  \n",
       "LinearRegression                            0.4637                    0.4508  \n",
       "KNeighborsRegressor                         0.7436                    0.7121  \n",
       "SVR                                         0.7345                    0.7105  \n",
       "MLPRegressor                                0.6869                    0.6496  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_data['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "X_test = test_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_test = test_data['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7beebd4a-526d-422f-a876-8377dc6646f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:59:01.597178Z",
     "iopub.status.busy": "2025-07-13T05:59:01.596920Z",
     "iopub.status.idle": "2025-07-13T05:59:01.608977Z",
     "shell.execute_reply": "2025-07-13T05:59:01.608305Z",
     "shell.execute_reply.started": "2025-07-13T05:59:01.597161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.2404</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.3946</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.7090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.2366</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.3962</td>\n",
       "      <td>0.5297</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9516</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.3915</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.9486</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>0.7066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.7097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>2.2865</td>\n",
       "      <td>1.1810</td>\n",
       "      <td>1.5121</td>\n",
       "      <td>-2.7709</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>-0.6313</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.4508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.7121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.2753</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.7105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2748</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.4314</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.6496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.0578                0.1766   \n",
       "DecisionTreeRegressor                    0.1109                0.2501   \n",
       "RandomForestRegressor                    0.0560                0.1744   \n",
       "GradientBoostingRegressor                0.0572                0.1769   \n",
       "AdaBoostRegressor                        0.0615                0.1870   \n",
       "XGBRegressor                             0.0689                0.1920   \n",
       "ExtraTreesRegressor                      0.0585                0.1751   \n",
       "LinearRegression                         2.2865                1.1810   \n",
       "KNeighborsRegressor                      0.0732                0.1983   \n",
       "SVR                                      0.0544                0.1699   \n",
       "MLPRegressor                             0.2748                0.3981   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.2404               0.9047   \n",
       "DecisionTreeRegressor                     0.3330               0.8172   \n",
       "RandomForestRegressor                     0.2366               0.9077   \n",
       "GradientBoostingRegressor                 0.2393               0.9056   \n",
       "AdaBoostRegressor                         0.2480               0.8986   \n",
       "XGBRegressor                              0.2626               0.8863   \n",
       "ExtraTreesRegressor                       0.2420               0.9034   \n",
       "LinearRegression                          1.5121              -2.7709   \n",
       "KNeighborsRegressor                       0.2705               0.8793   \n",
       "SVR                                       0.2333               0.9103   \n",
       "MLPRegressor                              0.5242               0.5468   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.9512                0.9381   \n",
       "DecisionTreeRegressor                    0.9078                0.8869   \n",
       "RandomForestRegressor                    0.9528                0.9392   \n",
       "GradientBoostingRegressor                0.9516                0.9379   \n",
       "AdaBoostRegressor                        0.9486                0.9358   \n",
       "XGBRegressor                             0.9415                0.9273   \n",
       "ExtraTreesRegressor                      0.9505                0.9382   \n",
       "LinearRegression                         0.4015                0.3900   \n",
       "KNeighborsRegressor                      0.9381                0.9186   \n",
       "SVR                                      0.9541                0.9431   \n",
       "MLPRegressor                             0.8031                0.7882   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE  Test R2  \\\n",
       "LGBMRegressor               0.2790   0.3946    0.5282   0.5179   \n",
       "DecisionTreeRegressor       0.2828   0.4026    0.5318   0.5113   \n",
       "RandomForestRegressor       0.2806   0.3962    0.5297   0.5151   \n",
       "GradientBoostingRegressor   0.2768   0.3915    0.5261   0.5218   \n",
       "AdaBoostRegressor           0.2741   0.3948    0.5236   0.5263   \n",
       "XGBRegressor                0.2788   0.4008    0.5280   0.5183   \n",
       "ExtraTreesRegressor         0.2769   0.3972    0.5262   0.5216   \n",
       "LinearRegression            0.9441   0.7144    0.9716  -0.6313   \n",
       "KNeighborsRegressor         0.2687   0.3857    0.5183   0.5357   \n",
       "SVR                         0.2753   0.3952    0.5247   0.5242   \n",
       "MLPRegressor                0.3291   0.4499    0.5737   0.4314   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7312                    0.7090  \n",
       "DecisionTreeRegressor                       0.7290                    0.7069  \n",
       "RandomForestRegressor                       0.7279                    0.7080  \n",
       "GradientBoostingRegressor                   0.7327                    0.7111  \n",
       "AdaBoostRegressor                           0.7306                    0.7035  \n",
       "XGBRegressor                                0.7296                    0.7066  \n",
       "ExtraTreesRegressor                         0.7315                    0.7097  \n",
       "LinearRegression                            0.4637                    0.4508  \n",
       "KNeighborsRegressor                         0.7436                    0.7121  \n",
       "SVR                                         0.7345                    0.7105  \n",
       "MLPRegressor                                0.6869                    0.6496  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7f74e9b-3183-44d2-9a89-50f6f146b86a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:59:01.610034Z",
     "iopub.status.busy": "2025-07-13T05:59:01.609770Z",
     "iopub.status.idle": "2025-07-13T05:59:01.709711Z",
     "shell.execute_reply": "2025-07-13T05:59:01.709129Z",
     "shell.execute_reply.started": "2025-07-13T05:59:01.610016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-7.292462681315174, -7.5816599934724875, -6.9...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.02498166841009, -5.677531556147479, -5.73...</td>\n",
       "      <td>[-7.011098290154813, -5.677657866208772, -5.75...</td>\n",
       "      <td>[0.03599470284888139, 0.05166373952587775, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.41, -7.03, -7.22, -6.68, -6.28, -6.92, -5....</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.0, -5.59, -5.96, -5.92, -5.54, -6.8, -5.9...</td>\n",
       "      <td>[-6.922774392799999, -5.696, -5.81464565319999...</td>\n",
       "      <td>[0.15095325824120112, 0.13169662106523464, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-7.237957574910001, -7.663358800159997, -7.02...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.02289389292, -5.709211846339998, -5.78094...</td>\n",
       "      <td>[-7.000684719968001, -5.69114922889, -5.798257...</td>\n",
       "      <td>[0.02774833928049578, 0.021328592025846155, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-7.319278610307436, -7.551383576162681, -6.98...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.0464238051456505, -5.721889441915605, -5....</td>\n",
       "      <td>[-7.0037229190259875, -5.73188943775403, -5.76...</td>\n",
       "      <td>[0.04674952409970827, 0.044425233947629844, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-7.2, -7.498999999999999, -7.024264136171874,...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-6.992817969630868, -5.745020350880184, -5.7...</td>\n",
       "      <td>[-6.942262490403431, -5.691302683806768, -5.77...</td>\n",
       "      <td>[0.06162240980432033, 0.04679456505195146, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-7.336082, -7.9073353, -6.917879, -6.8506694,...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.1687274, -5.77472, -5.7993746, -5.907785,...</td>\n",
       "      <td>[-6.984561, -5.6831555, -5.81688, -5.854247, -...</td>\n",
       "      <td>[0.12944558, 0.052518845, 0.094338775, 0.08323...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-7.294226458880003, -7.6546999999999965, -6.9...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.0098213972600005, -5.720984778560002, -5....</td>\n",
       "      <td>[-6.971507747422, -5.681087192438001, -5.82335...</td>\n",
       "      <td>[0.02419666324639479, 0.027388123899037758, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.16117284066149, -7.175818078129848, -7.423...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-6.372213239724258, -8.533323731932793, -5.2...</td>\n",
       "      <td>[-7.450501750506096, -6.2072584716049475, -5.2...</td>\n",
       "      <td>[0.7529879090222406, 2.114482528387649, 0.6371...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-7.426666666666667, -7.343333333333334, -6.98...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.109999999999999, -5.650000000000001, -5.8...</td>\n",
       "      <td>[-7.090666666666668, -5.6673333333333344, -5.8...</td>\n",
       "      <td>[0.028782710859897104, 0.023701851779507684, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-7.138178023895527, -7.611015940881996, -6.91...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.031055314513305, -5.714109343336877, -5.8...</td>\n",
       "      <td>[-6.9892732549961405, -5.7255970911396705, -5....</td>\n",
       "      <td>[0.03461277241312399, 0.02153458392142625, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.691572168148516, -6.943485848954394, -6.82...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.1634139136706, -6.063710175887473, -5.663...</td>\n",
       "      <td>[-7.287145803835804, -6.251715077820889, -5.67...</td>\n",
       "      <td>[0.3239103060139881, 0.1730158758198925, 0.047...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-7.292462681315174, -7.5816599934724875, -6.9...   \n",
       "1   [-7.41, -7.03, -7.22, -6.68, -6.28, -6.92, -5....   \n",
       "2   [-7.237957574910001, -7.663358800159997, -7.02...   \n",
       "3   [-7.319278610307436, -7.551383576162681, -6.98...   \n",
       "4   [-7.2, -7.498999999999999, -7.024264136171874,...   \n",
       "5   [-7.336082, -7.9073353, -6.917879, -6.8506694,...   \n",
       "6   [-7.294226458880003, -7.6546999999999965, -6.9...   \n",
       "7   [-5.16117284066149, -7.175818078129848, -7.423...   \n",
       "8   [-7.426666666666667, -7.343333333333334, -6.98...   \n",
       "9   [-7.138178023895527, -7.611015940881996, -6.91...   \n",
       "10  [-6.691572168148516, -6.943485848954394, -6.82...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "1   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "2   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "3   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "4   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "5   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "6   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "7   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "8   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "9   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "10  0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.02498166841009, -5.677531556147479, -5.73...   \n",
       "1   [[-7.0, -5.59, -5.96, -5.92, -5.54, -6.8, -5.9...   \n",
       "2   [[-7.02289389292, -5.709211846339998, -5.78094...   \n",
       "3   [[-7.0464238051456505, -5.721889441915605, -5....   \n",
       "4   [[-6.992817969630868, -5.745020350880184, -5.7...   \n",
       "5   [[-7.1687274, -5.77472, -5.7993746, -5.907785,...   \n",
       "6   [[-7.0098213972600005, -5.720984778560002, -5....   \n",
       "7   [[-6.372213239724258, -8.533323731932793, -5.2...   \n",
       "8   [[-7.109999999999999, -5.650000000000001, -5.8...   \n",
       "9   [[-7.031055314513305, -5.714109343336877, -5.8...   \n",
       "10  [[-7.1634139136706, -6.063710175887473, -5.663...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.011098290154813, -5.677657866208772, -5.75...   \n",
       "1   [-6.922774392799999, -5.696, -5.81464565319999...   \n",
       "2   [-7.000684719968001, -5.69114922889, -5.798257...   \n",
       "3   [-7.0037229190259875, -5.73188943775403, -5.76...   \n",
       "4   [-6.942262490403431, -5.691302683806768, -5.77...   \n",
       "5   [-6.984561, -5.6831555, -5.81688, -5.854247, -...   \n",
       "6   [-6.971507747422, -5.681087192438001, -5.82335...   \n",
       "7   [-7.450501750506096, -6.2072584716049475, -5.2...   \n",
       "8   [-7.090666666666668, -5.6673333333333344, -5.8...   \n",
       "9   [-6.9892732549961405, -5.7255970911396705, -5....   \n",
       "10  [-7.287145803835804, -6.251715077820889, -5.67...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.03599470284888139, 0.05166373952587775, 0.0...  \n",
       "1   [0.15095325824120112, 0.13169662106523464, 0.1...  \n",
       "2   [0.02774833928049578, 0.021328592025846155, 0....  \n",
       "3   [0.04674952409970827, 0.044425233947629844, 0....  \n",
       "4   [0.06162240980432033, 0.04679456505195146, 0.0...  \n",
       "5   [0.12944558, 0.052518845, 0.094338775, 0.08323...  \n",
       "6   [0.02419666324639479, 0.027388123899037758, 0....  \n",
       "7   [0.7529879090222406, 2.114482528387649, 0.6371...  \n",
       "8   [0.028782710859897104, 0.023701851779507684, 0...  \n",
       "9   [0.03461277241312399, 0.02153458392142625, 0.0...  \n",
       "10  [0.3239103060139881, 0.1730158758198925, 0.047...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cfb84ae-acf6-445d-8a74-af6935760216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:59:01.710564Z",
     "iopub.status.busy": "2025-07-13T05:59:01.710354Z",
     "iopub.status.idle": "2025-07-13T05:59:01.821014Z",
     "shell.execute_reply": "2025-07-13T05:59:01.820522Z",
     "shell.execute_reply.started": "2025-07-13T05:59:01.710548Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('/kaggle/working/Results_ChemBERTa-zinc-base-v1_fine_tuned_embeddings_caco2.csv')\n",
    "prediction_df.to_csv('/kaggle/working/Prediction_data_ChemBERTa-zinc-base-v1_fine_tuned_embeddings_caco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7ceeb4d-9e50-4347-80b4-823def90a51c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:59:29.891231Z",
     "iopub.status.busy": "2025-07-13T05:59:29.890939Z",
     "iopub.status.idle": "2025-07-13T05:59:29.903965Z",
     "shell.execute_reply": "2025-07-13T05:59:29.903210Z",
     "shell.execute_reply.started": "2025-07-13T05:59:29.891214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.2404</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.3946</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.7090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.2366</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.3962</td>\n",
       "      <td>0.5297</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9516</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.3915</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.9486</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>0.7066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.7097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>2.2865</td>\n",
       "      <td>1.1810</td>\n",
       "      <td>1.5121</td>\n",
       "      <td>-2.7709</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>-0.6313</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.4508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.7121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.2753</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.7105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2748</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.4314</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.6496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.0578                0.1766   \n",
       "DecisionTreeRegressor                    0.1109                0.2501   \n",
       "RandomForestRegressor                    0.0560                0.1744   \n",
       "GradientBoostingRegressor                0.0572                0.1769   \n",
       "AdaBoostRegressor                        0.0615                0.1870   \n",
       "XGBRegressor                             0.0689                0.1920   \n",
       "ExtraTreesRegressor                      0.0585                0.1751   \n",
       "LinearRegression                         2.2865                1.1810   \n",
       "KNeighborsRegressor                      0.0732                0.1983   \n",
       "SVR                                      0.0544                0.1699   \n",
       "MLPRegressor                             0.2748                0.3981   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.2404               0.9047   \n",
       "DecisionTreeRegressor                     0.3330               0.8172   \n",
       "RandomForestRegressor                     0.2366               0.9077   \n",
       "GradientBoostingRegressor                 0.2393               0.9056   \n",
       "AdaBoostRegressor                         0.2480               0.8986   \n",
       "XGBRegressor                              0.2626               0.8863   \n",
       "ExtraTreesRegressor                       0.2420               0.9034   \n",
       "LinearRegression                          1.5121              -2.7709   \n",
       "KNeighborsRegressor                       0.2705               0.8793   \n",
       "SVR                                       0.2333               0.9103   \n",
       "MLPRegressor                              0.5242               0.5468   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.9512                0.9381   \n",
       "DecisionTreeRegressor                    0.9078                0.8869   \n",
       "RandomForestRegressor                    0.9528                0.9392   \n",
       "GradientBoostingRegressor                0.9516                0.9379   \n",
       "AdaBoostRegressor                        0.9486                0.9358   \n",
       "XGBRegressor                             0.9415                0.9273   \n",
       "ExtraTreesRegressor                      0.9505                0.9382   \n",
       "LinearRegression                         0.4015                0.3900   \n",
       "KNeighborsRegressor                      0.9381                0.9186   \n",
       "SVR                                      0.9541                0.9431   \n",
       "MLPRegressor                             0.8031                0.7882   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE  Test R2  \\\n",
       "LGBMRegressor               0.2790   0.3946    0.5282   0.5179   \n",
       "DecisionTreeRegressor       0.2828   0.4026    0.5318   0.5113   \n",
       "RandomForestRegressor       0.2806   0.3962    0.5297   0.5151   \n",
       "GradientBoostingRegressor   0.2768   0.3915    0.5261   0.5218   \n",
       "AdaBoostRegressor           0.2741   0.3948    0.5236   0.5263   \n",
       "XGBRegressor                0.2788   0.4008    0.5280   0.5183   \n",
       "ExtraTreesRegressor         0.2769   0.3972    0.5262   0.5216   \n",
       "LinearRegression            0.9441   0.7144    0.9716  -0.6313   \n",
       "KNeighborsRegressor         0.2687   0.3857    0.5183   0.5357   \n",
       "SVR                         0.2753   0.3952    0.5247   0.5242   \n",
       "MLPRegressor                0.3291   0.4499    0.5737   0.4314   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.7312                    0.7090  \n",
       "DecisionTreeRegressor                       0.7290                    0.7069  \n",
       "RandomForestRegressor                       0.7279                    0.7080  \n",
       "GradientBoostingRegressor                   0.7327                    0.7111  \n",
       "AdaBoostRegressor                           0.7306                    0.7035  \n",
       "XGBRegressor                                0.7296                    0.7066  \n",
       "ExtraTreesRegressor                         0.7315                    0.7097  \n",
       "LinearRegression                            0.4637                    0.4508  \n",
       "KNeighborsRegressor                         0.7436                    0.7121  \n",
       "SVR                                         0.7345                    0.7105  \n",
       "MLPRegressor                                0.6869                    0.6496  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b5f0120-d783-47c7-b402-c937e380ffbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T05:59:01.836847Z",
     "iopub.status.busy": "2025-07-13T05:59:01.836586Z",
     "iopub.status.idle": "2025-07-13T05:59:01.939488Z",
     "shell.execute_reply": "2025-07-13T05:59:01.938828Z",
     "shell.execute_reply.started": "2025-07-13T05:59:01.836824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-7.292462681315174, -7.5816599934724875, -6.9...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.02498166841009, -5.677531556147479, -5.73...</td>\n",
       "      <td>[-7.011098290154813, -5.677657866208772, -5.75...</td>\n",
       "      <td>[0.03599470284888139, 0.05166373952587775, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.41, -7.03, -7.22, -6.68, -6.28, -6.92, -5....</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.0, -5.59, -5.96, -5.92, -5.54, -6.8, -5.9...</td>\n",
       "      <td>[-6.922774392799999, -5.696, -5.81464565319999...</td>\n",
       "      <td>[0.15095325824120112, 0.13169662106523464, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-7.237957574910001, -7.663358800159997, -7.02...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.02289389292, -5.709211846339998, -5.78094...</td>\n",
       "      <td>[-7.000684719968001, -5.69114922889, -5.798257...</td>\n",
       "      <td>[0.02774833928049578, 0.021328592025846155, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-7.319278610307436, -7.551383576162681, -6.98...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.0464238051456505, -5.721889441915605, -5....</td>\n",
       "      <td>[-7.0037229190259875, -5.73188943775403, -5.76...</td>\n",
       "      <td>[0.04674952409970827, 0.044425233947629844, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-7.2, -7.498999999999999, -7.024264136171874,...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-6.992817969630868, -5.745020350880184, -5.7...</td>\n",
       "      <td>[-6.942262490403431, -5.691302683806768, -5.77...</td>\n",
       "      <td>[0.06162240980432033, 0.04679456505195146, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-7.336082, -7.9073353, -6.917879, -6.8506694,...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.1687274, -5.77472, -5.7993746, -5.907785,...</td>\n",
       "      <td>[-6.984561, -5.6831555, -5.81688, -5.854247, -...</td>\n",
       "      <td>[0.12944558, 0.052518845, 0.094338775, 0.08323...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-7.294226458880003, -7.6546999999999965, -6.9...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.0098213972600005, -5.720984778560002, -5....</td>\n",
       "      <td>[-6.971507747422, -5.681087192438001, -5.82335...</td>\n",
       "      <td>[0.02419666324639479, 0.027388123899037758, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-5.16117284066149, -7.175818078129848, -7.423...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-6.372213239724258, -8.533323731932793, -5.2...</td>\n",
       "      <td>[-7.450501750506096, -6.2072584716049475, -5.2...</td>\n",
       "      <td>[0.7529879090222406, 2.114482528387649, 0.6371...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-7.426666666666667, -7.343333333333334, -6.98...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.109999999999999, -5.650000000000001, -5.8...</td>\n",
       "      <td>[-7.090666666666668, -5.6673333333333344, -5.8...</td>\n",
       "      <td>[0.028782710859897104, 0.023701851779507684, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-7.138178023895527, -7.611015940881996, -6.91...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.031055314513305, -5.714109343336877, -5.8...</td>\n",
       "      <td>[-6.9892732549961405, -5.7255970911396705, -5....</td>\n",
       "      <td>[0.03461277241312399, 0.02153458392142625, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.691572168148516, -6.943485848954394, -6.82...</td>\n",
       "      <td>0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...</td>\n",
       "      <td>[[-7.1634139136706, -6.063710175887473, -5.663...</td>\n",
       "      <td>[-7.287145803835804, -6.251715077820889, -5.67...</td>\n",
       "      <td>[0.3239103060139881, 0.1730158758198925, 0.047...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-7.292462681315174, -7.5816599934724875, -6.9...   \n",
       "1   [-7.41, -7.03, -7.22, -6.68, -6.28, -6.92, -5....   \n",
       "2   [-7.237957574910001, -7.663358800159997, -7.02...   \n",
       "3   [-7.319278610307436, -7.551383576162681, -6.98...   \n",
       "4   [-7.2, -7.498999999999999, -7.024264136171874,...   \n",
       "5   [-7.336082, -7.9073353, -6.917879, -6.8506694,...   \n",
       "6   [-7.294226458880003, -7.6546999999999965, -6.9...   \n",
       "7   [-5.16117284066149, -7.175818078129848, -7.423...   \n",
       "8   [-7.426666666666667, -7.343333333333334, -6.98...   \n",
       "9   [-7.138178023895527, -7.611015940881996, -6.91...   \n",
       "10  [-6.691572168148516, -6.943485848954394, -6.82...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "1   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "2   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "3   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "4   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "5   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "6   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "7   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "8   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "9   0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "10  0     -7.19\n",
       "1     -6.21\n",
       "2     -7.24\n",
       "3     -5.8...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-7.02498166841009, -5.677531556147479, -5.73...   \n",
       "1   [[-7.0, -5.59, -5.96, -5.92, -5.54, -6.8, -5.9...   \n",
       "2   [[-7.02289389292, -5.709211846339998, -5.78094...   \n",
       "3   [[-7.0464238051456505, -5.721889441915605, -5....   \n",
       "4   [[-6.992817969630868, -5.745020350880184, -5.7...   \n",
       "5   [[-7.1687274, -5.77472, -5.7993746, -5.907785,...   \n",
       "6   [[-7.0098213972600005, -5.720984778560002, -5....   \n",
       "7   [[-6.372213239724258, -8.533323731932793, -5.2...   \n",
       "8   [[-7.109999999999999, -5.650000000000001, -5.8...   \n",
       "9   [[-7.031055314513305, -5.714109343336877, -5.8...   \n",
       "10  [[-7.1634139136706, -6.063710175887473, -5.663...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-7.011098290154813, -5.677657866208772, -5.75...   \n",
       "1   [-6.922774392799999, -5.696, -5.81464565319999...   \n",
       "2   [-7.000684719968001, -5.69114922889, -5.798257...   \n",
       "3   [-7.0037229190259875, -5.73188943775403, -5.76...   \n",
       "4   [-6.942262490403431, -5.691302683806768, -5.77...   \n",
       "5   [-6.984561, -5.6831555, -5.81688, -5.854247, -...   \n",
       "6   [-6.971507747422, -5.681087192438001, -5.82335...   \n",
       "7   [-7.450501750506096, -6.2072584716049475, -5.2...   \n",
       "8   [-7.090666666666668, -5.6673333333333344, -5.8...   \n",
       "9   [-6.9892732549961405, -5.7255970911396705, -5....   \n",
       "10  [-7.287145803835804, -6.251715077820889, -5.67...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.03599470284888139, 0.05166373952587775, 0.0...  \n",
       "1   [0.15095325824120112, 0.13169662106523464, 0.1...  \n",
       "2   [0.02774833928049578, 0.021328592025846155, 0....  \n",
       "3   [0.04674952409970827, 0.044425233947629844, 0....  \n",
       "4   [0.06162240980432033, 0.04679456505195146, 0.0...  \n",
       "5   [0.12944558, 0.052518845, 0.094338775, 0.08323...  \n",
       "6   [0.02419666324639479, 0.027388123899037758, 0....  \n",
       "7   [0.7529879090222406, 2.114482528387649, 0.6371...  \n",
       "8   [0.028782710859897104, 0.023701851779507684, 0...  \n",
       "9   [0.03461277241312399, 0.02153458392142625, 0.0...  \n",
       "10  [0.3239103060139881, 0.1730158758198925, 0.047...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "654733f6-3748-4de4-8bac-ef03c265386d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e50f035-e696-4eea-a9eb-c5a9fca1b09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7855952,
     "sourceId": 12453913,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
