{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954d6bd4-b5eb-49e7-8187-a217b9dcac74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:34:24.763165Z",
     "iopub.status.busy": "2025-07-11T12:34:24.762908Z",
     "iopub.status.idle": "2025-07-11T12:34:37.804129Z",
     "shell.execute_reply": "2025-07-11T12:34:37.803201Z",
     "shell.execute_reply.started": "2025-07-11T12:34:24.763146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.44.2\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.6.15)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.44.2) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.44.2) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.52.4\n",
      "    Uninstalling transformers-4.52.4:\n",
      "      Successfully uninstalled transformers-4.52.4\n",
      "Successfully installed tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.44.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd321882-ff9d-42d4-89ea-cf58885b8d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:34:37.806246Z",
     "iopub.status.busy": "2025-07-11T12:34:37.805738Z",
     "iopub.status.idle": "2025-07-11T12:34:41.433290Z",
     "shell.execute_reply": "2025-07-11T12:34:41.432301Z",
     "shell.execute_reply.started": "2025-07-11T12:34:37.806220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib==1.4.2\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: joblib\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.5.1\n",
      "    Uninstalling joblib-1.5.1:\n",
      "      Successfully uninstalled joblib-1.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d58b53-5425-427d-b900-fc0b6846ca64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:34:41.434711Z",
     "iopub.status.busy": "2025-07-11T12:34:41.434475Z",
     "iopub.status.idle": "2025-07-11T12:34:48.115785Z",
     "shell.execute_reply": "2025-07-11T12:34:48.115108Z",
     "shell.execute_reply.started": "2025-07-11T12:34:41.434688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.6.0\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.0) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.0) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.0) (3.6.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.6.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.6.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.6.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.6.0) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.6.0) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.6.0) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.6.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.6.0) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.6.0) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.6.0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.6.0) (2024.2.0)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.0 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be4620b-a715-4cbe-9c5a-6331cb1ecf15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:34:48.118185Z",
     "iopub.status.busy": "2025-07-11T12:34:48.117659Z",
     "iopub.status.idle": "2025-07-11T12:34:57.397314Z",
     "shell.execute_reply": "2025-07-11T12:34:57.396460Z",
     "shell.execute_reply.started": "2025-07-11T12:34:48.118161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Collecting scipy==1.13.1\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4) (2024.2.0)\n",
      "Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.0 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scipy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 pandas==2.2.3 scipy==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b285d19-55cb-4a81-bbc7-810ef8b7b37a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:34:57.398661Z",
     "iopub.status.busy": "2025-07-11T12:34:57.398372Z",
     "iopub.status.idle": "2025-07-11T12:35:01.488847Z",
     "shell.execute_reply": "2025-07-11T12:35:01.488013Z",
     "shell.execute_reply.started": "2025-07-11T12:34:57.398628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn==0.13.2\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting tqdm==4.66.5\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn==0.13.2) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn==0.13.2) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn==0.13.2) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (11.2.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.20->seaborn==0.13.2) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.20->seaborn==0.13.2) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.20->seaborn==0.13.2) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.20->seaborn==0.13.2) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.20->seaborn==0.13.2) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.20->seaborn==0.13.2) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.20->seaborn==0.13.2) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.20->seaborn==0.13.2) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.20->seaborn==0.13.2) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.20->seaborn==0.13.2) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.20->seaborn==0.13.2) (2024.2.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, seaborn\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.12.2\n",
      "    Uninstalling seaborn-0.12.2:\n",
      "      Successfully uninstalled seaborn-0.12.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "dataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\n",
      "dataproc-spark-connect 0.7.5 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed seaborn-0.13.2 tqdm-4.66.5\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn==0.13.2 tqdm==4.66.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a67708-1471-44d0-aae4-dabee689cac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ea0e60-9cfe-42de-b934-664587e8c25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:35:01.490145Z",
     "iopub.status.busy": "2025-07-11T12:35:01.489885Z",
     "iopub.status.idle": "2025-07-11T12:35:06.571211Z",
     "shell.execute_reply": "2025-07-11T12:35:06.570372Z",
     "shell.execute_reply.started": "2025-07-11T12:35:01.490117Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import AutoModel, AutoTokenizer,AutoModelForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('/kaggle/input/pampa-set/Train.csv')\n",
    "train_df = train_df[['ID', 'SMILES', 'Permeability']]\n",
    "test_df = pd.read_csv('/kaggle/input/pampa-set/Test.csv')\n",
    "test_df = test_df[['ID', 'SMILES', 'Permeability']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9092fdc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:35:06.572511Z",
     "iopub.status.busy": "2025-07-11T12:35:06.572125Z",
     "iopub.status.idle": "2025-07-11T12:35:06.581947Z",
     "shell.execute_reply": "2025-07-11T12:35:06.581141Z",
     "shell.execute_reply.started": "2025-07-11T12:35:06.572480Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1bd791-38e5-4a4e-900f-28bbbf691e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:35:06.584278Z",
     "iopub.status.busy": "2025-07-11T12:35:06.583994Z",
     "iopub.status.idle": "2025-07-11T12:35:10.823700Z",
     "shell.execute_reply": "2025-07-11T12:35:10.823035Z",
     "shell.execute_reply.started": "2025-07-11T12:35:06.584259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fba1c1632344d4a8c3cc3daede2624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e211b8f948d04271ab016191026eb54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_molformer.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ibm/MoLFormer-XL-both-10pct:\n",
      "- configuration_molformer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e92947e2ca54b9a874b93fe713e8279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_molformer.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ibm/MoLFormer-XL-both-10pct:\n",
      "- modeling_molformer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794b1b1a37704ce89004e8f1ee70b0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/187M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MolformerForSequenceClassification were not initialized from the model checkpoint at ibm/MoLFormer-XL-both-10pct and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.dense2.bias', 'classifier.dense2.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c22fd9808c44089f5a526ae3340480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e64ddfe2dce452490f0b0788480c967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_molformer_fast.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0392b82a04074514a8a13d0f4e9c5f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_molformer.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ibm/MoLFormer-XL-both-10pct:\n",
      "- tokenization_molformer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/ibm/MoLFormer-XL-both-10pct:\n",
      "- tokenization_molformer_fast.py\n",
      "- tokenization_molformer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4b9fd5c33d4ab2a31318c999b39092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce770d791da49898d9ddf8b0aef317e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6feb8ad1d5e04bdc9e09c60ae58d6b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"ibm/MoLFormer-XL-both-10pct\", deterministic_eval=True, trust_remote_code=True, num_labels=1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ibm/MoLFormer-XL-both-10pct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05ab00aa-cce1-4775-b3ed-e21d7d27420d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:35:10.825017Z",
     "iopub.status.busy": "2025-07-11T12:35:10.824371Z",
     "iopub.status.idle": "2025-07-11T12:35:10.830422Z",
     "shell.execute_reply": "2025-07-11T12:35:10.829776Z",
     "shell.execute_reply.started": "2025-07-11T12:35:10.824997Z"
    }
   },
   "outputs": [],
   "source": [
    "#Custom dataset class\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=325):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataframe = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.dataframe.iloc[idx]['SMILES']\n",
    "        permeability = self.dataframe.iloc[idx]['Permeability']\n",
    "        inputs = self.tokenizer(smiles, return_tensors='pt', padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
    "        \n",
    "        input_ids = inputs['input_ids'].squeeze(0)  # Shape: (sequence_length,)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)  # Shape: (sequence_length,)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(permeability, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e5e17b-ca6a-448b-baf2-a471eecae492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:47:35.409530Z",
     "iopub.status.busy": "2025-07-11T12:47:35.408717Z",
     "iopub.status.idle": "2025-07-11T12:47:35.418086Z",
     "shell.execute_reply": "2025-07-11T12:47:35.417310Z",
     "shell.execute_reply.started": "2025-07-11T12:47:35.409504Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cb4e4d1-cda6-42c4-b628-69bf690be558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SMILESDataset(train_df, tokenizer)\n",
    "test_dataset = SMILESDataset(test_df, tokenizer)\n",
    "batch_size = 16\n",
    "#Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba8955db-521c-4936-8961-0e1221f2565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9290db40-0a74-4930-9107-d7e60cec9358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:48:03.356657Z",
     "iopub.status.busy": "2025-07-11T12:48:03.356388Z",
     "iopub.status.idle": "2025-07-11T13:45:59.119533Z",
     "shell.execute_reply": "2025-07-11T13:45:59.118886Z",
     "shell.execute_reply.started": "2025-07-11T12:48:03.356637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 348/348 [02:53<00:00,  2.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.6446\n",
      "Entered Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.3943\n",
      "Entered Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 348/348 [02:53<00:00,  2.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.3551\n",
      "Entered Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.3132\n",
      "Entered Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 0.2929\n",
      "Entered Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.2663\n",
      "Entered Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.2573\n",
      "Entered Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.2327\n",
      "Entered Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.2208\n",
      "Entered Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.2238\n",
      "Entered Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.2098\n",
      "Entered Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train Loss: 0.2017\n",
      "Entered Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train Loss: 0.1881\n",
      "Entered Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Train Loss: 0.1804\n",
      "Entered Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train Loss: 0.1868\n",
      "Entered Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Train Loss: 0.1715\n",
      "Entered Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Train Loss: 0.1642\n",
      "Entered Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Train Loss: 0.1591\n",
      "Entered Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Train Loss: 0.1593\n",
      "Entered Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 348/348 [02:53<00:00,  2.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Train Loss: 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Entered Epoch {epoch + 1}\")\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{num_epochs}', unit='batch'):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move all batch tensors to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        labels = batch[\"labels\"].unsqueeze(1)  # still shape: (batch_size, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backprop and optimizer step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29c59014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:45:59.120893Z",
     "iopub.status.busy": "2025-07-11T13:45:59.120655Z",
     "iopub.status.idle": "2025-07-11T13:45:59.635286Z",
     "shell.execute_reply": "2025-07-11T13:45:59.634587Z",
     "shell.execute_reply.started": "2025-07-11T13:45:59.120877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to /kaggle/working/MoLFormer-XL-both-10pct_model_1_pampa\n"
     ]
    }
   ],
   "source": [
    "# Save the model after training\n",
    "model_name = 'MoLFormer-XL-both-10pct_model_1_pampa'\n",
    "model_save_path = f'/kaggle/working/{model_name}'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "model.save_pretrained(model_save_path, safe_serialization=False)\n",
    "\n",
    "print(f'Model and tokenizer saved to {model_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b170bb7d-5df7-4b82-955f-0a3e58fbd500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:51:08.476966Z",
     "iopub.status.busy": "2025-07-11T13:51:08.476675Z",
     "iopub.status.idle": "2025-07-11T13:51:25.021220Z",
     "shell.execute_reply": "2025-07-11T13:51:25.020614Z",
     "shell.execute_reply.started": "2025-07-11T13:51:08.476945Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 87/87 [00:16<00:00,  5.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2616\n",
      "(1392,)\n",
      "(1392,)\n",
      "Mean Squared Error: 0.2616\n",
      "Root Mean Squared Error: 0.5115\n",
      "Mean Absolute Error: 0.3906\n",
      "R^2 Score: 0.5866\n",
      "Pearson Correlation Coefficient: 0.8049\n",
      "Spearman Correlation Coefficient: 0.7803\n",
      "Hyperparameters:\n",
      "Learning Rate: 5e-05\n",
      "Batch Size: 16\n",
      "Epochs: 20\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# No gradient calculation during evaluation\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing', unit='batch'):\n",
    "      \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].unsqueeze(1).to(device).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Collect predictions and true labels (back to CPU for evaluation)\n",
    "        test_true_labels.extend(labels.cpu().numpy())\n",
    "        preds = outputs.logits.squeeze().cpu().numpy()  # Shape: (batch_size,)\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Final test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "test_true_labels = np.array(test_true_labels).flatten()\n",
    "predictions = np.array(predictions)\n",
    "print(test_true_labels.shape)\n",
    "print(predictions.shape)\n",
    "# Performance metrics\n",
    "mse = mean_squared_error(test_true_labels, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_true_labels, predictions)\n",
    "r2 = r2_score(test_true_labels, predictions)\n",
    "PCC,_ = pearsonr(test_true_labels, predictions)\n",
    "SCC,_ = spearmanr(test_true_labels, predictions)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "print(f'R^2 Score: {r2:.4f}')\n",
    "print(f'Pearson Correlation Coefficient: {PCC:.4f}')\n",
    "print(f'Spearman Correlation Coefficient: {SCC:.4f}')\n",
    "\n",
    "# Print hyperparameters\n",
    "print(\"Hyperparameters:\")\n",
    "print(f\"Learning Rate: {5e-5}\")\n",
    "print(f\"Batch Size: 16\")\n",
    "print(f\"Epochs: {num_epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a3c4f-358d-4c3c-a889-1a0f7e922e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3c1014b-07d3-47c1-ae82-36a0de05cb30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:55:56.035870Z",
     "iopub.status.busy": "2025-07-11T13:55:56.035591Z",
     "iopub.status.idle": "2025-07-11T13:55:56.559606Z",
     "shell.execute_reply": "2025-07-11T13:55:56.559056Z",
     "shell.execute_reply.started": "2025-07-11T13:55:56.035824Z"
    }
   },
   "outputs": [],
   "source": [
    "#MolFormer_XL Fine tuned Model_1 SMILES Embeddings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the model name and path\n",
    "model_name = 'MoLFormer-XL-both-10pct_model_1_pampa'\n",
    "model_save_path = f'/kaggle/working/{model_name}'\n",
    "\n",
    "if not os.path.exists(model_save_path):\n",
    "    raise FileNotFoundError(f\"The model directory {model_save_path} does not exist.\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_save_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_save_path, trust_remote_code=True).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3567b06a-a6e1-4d8b-9045-fbee8c512898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:55:59.423788Z",
     "iopub.status.busy": "2025-07-11T13:55:59.423212Z",
     "iopub.status.idle": "2025-07-11T13:55:59.456297Z",
     "shell.execute_reply": "2025-07-11T13:55:59.455536Z",
     "shell.execute_reply.started": "2025-07-11T13:55:59.423767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('/kaggle/input/pampa-set/Train.csv')\n",
    "train_df = train_df[['ID', 'SMILES', 'Permeability']]\n",
    "test_df = pd.read_csv('/kaggle/input/pampa-set/Test.csv')\n",
    "test_df = test_df[['ID', 'SMILES', 'Permeability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5da51286-aa61-4d50-acfb-f9a89c049327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:56:01.583557Z",
     "iopub.status.busy": "2025-07-11T13:56:01.582957Z",
     "iopub.status.idle": "2025-07-11T13:56:03.403522Z",
     "shell.execute_reply": "2025-07-11T13:56:03.402757Z",
     "shell.execute_reply.started": "2025-07-11T13:56:01.583534Z"
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_df['SMILES']), truncation=True, padding=True, max_length=325, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(list(test_df['SMILES']), truncation=True, padding=True, max_length=325, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce14b286-75fa-4744-b14d-d64051d95034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:56:31.043104Z",
     "iopub.status.busy": "2025-07-11T13:56:31.042477Z",
     "iopub.status.idle": "2025-07-11T13:56:31.048070Z",
     "shell.execute_reply": "2025-07-11T13:56:31.047376Z",
     "shell.execute_reply.started": "2025-07-11T13:56:31.043080Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "batch_size = 16 \n",
    "\n",
    "def generate_embeddings(encodings, batch_size):\n",
    "    embeddings = []\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(encodings['input_ids']), batch_size), desc=\"Processing batches\"):\n",
    "            batch = {key: val[i:i + batch_size].to(device) for key, val in encodings.items()}  \n",
    "            outputs = model(**batch)\n",
    "            embeddings.append(outputs.last_hidden_state)\n",
    "    return torch.cat(embeddings, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a6462f5-bf7c-4541-9c3f-480ba8a6930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 348/348 [00:47<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5568, 240, 768])\n",
      "torch.Size([5568, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = generate_embeddings(train_encodings, batch_size)\n",
    "print(train_embeddings.shape)\n",
    "train_embeddings = torch.mean(train_embeddings, dim=1)\n",
    "print(train_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4946aa76-c528-4187-92b1-86531d92c493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:59:38.198759Z",
     "iopub.status.busy": "2025-07-11T13:59:38.198486Z",
     "iopub.status.idle": "2025-07-11T13:59:38.239922Z",
     "shell.execute_reply": "2025-07-11T13:59:38.239388Z",
     "shell.execute_reply.started": "2025-07-11T13:59:38.198739Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create column names based on embedding size\n",
    "column_names = [f'x_fine_emb_MFXL{i}' for i in range(train_embeddings.shape[1])]\n",
    "\n",
    "# Convert GPU tensor to CPU and then to numpy before passing to pandas\n",
    "embeddings_df = pd.DataFrame(data=train_embeddings.cpu().numpy(), columns=column_names)\n",
    "\n",
    "# Concatenate original DataFrame with embedding DataFrame\n",
    "train_data = pd.concat([train_df, embeddings_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "120c3704-b8c6-4f63-823a-192c7df98112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:59:42.735632Z",
     "iopub.status.busy": "2025-07-11T13:59:42.735297Z",
     "iopub.status.idle": "2025-07-11T13:59:53.954748Z",
     "shell.execute_reply": "2025-07-11T13:59:53.954165Z",
     "shell.execute_reply.started": "2025-07-11T13:59:42.735606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 87/87 [00:11<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1392, 239, 768])\n",
      "torch.Size([1392, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = generate_embeddings(test_encodings, batch_size)\n",
    "print(test_embeddings.shape)\n",
    "test_embeddings = torch.mean(test_embeddings, dim=1)\n",
    "print(test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b1c98c1-e61a-4363-90ce-0a776782ba8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:00:07.741606Z",
     "iopub.status.busy": "2025-07-11T14:00:07.741335Z",
     "iopub.status.idle": "2025-07-11T14:00:07.751405Z",
     "shell.execute_reply": "2025-07-11T14:00:07.750702Z",
     "shell.execute_reply.started": "2025-07-11T14:00:07.741586Z"
    }
   },
   "outputs": [],
   "source": [
    "column_names = [f'x_fine_emb_MFXL{i}' for i in range(test_embeddings.shape[1])]\n",
    "embeddings_df = pd.DataFrame(data=test_embeddings.cpu().numpy(), columns=column_names)\n",
    "test_data = pd.concat([test_df, embeddings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e50f9b93-befe-4ede-a418-0550c3b8346b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:00:31.900685Z",
     "iopub.status.busy": "2025-07-11T14:00:31.900433Z",
     "iopub.status.idle": "2025-07-11T14:00:36.865208Z",
     "shell.execute_reply": "2025-07-11T14:00:36.864631Z",
     "shell.execute_reply.started": "2025-07-11T14:00:31.900669Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"/kaggle/working/Train_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings.csv\",index=False)\n",
    "test_data.to_csv(\"/kaggle/working/Test_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786620b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92ed4099-571b-4754-8c59-32dad30bb8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:01:46.398352Z",
     "iopub.status.busy": "2025-07-11T14:01:46.398083Z",
     "iopub.status.idle": "2025-07-11T14:01:50.397723Z",
     "shell.execute_reply": "2025-07-11T14:01:50.396988Z",
     "shell.execute_reply.started": "2025-07-11T14:01:46.398330Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aee84f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:02:06.697122Z",
     "iopub.status.busy": "2025-07-11T14:02:06.696501Z",
     "iopub.status.idle": "2025-07-11T14:02:07.546388Z",
     "shell.execute_reply": "2025-07-11T14:02:07.545467Z",
     "shell.execute_reply.started": "2025-07-11T14:02:06.697097Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/working/Train_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/working/Test_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeb8e51f-eca2-45b7-b7c2-5c185e9406ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:02:10.024637Z",
     "iopub.status.busy": "2025-07-11T14:02:10.024052Z",
     "iopub.status.idle": "2025-07-11T14:02:10.033665Z",
     "shell.execute_reply": "2025-07-11T14:02:10.032989Z",
     "shell.execute_reply.started": "2025-07-11T14:02:10.024614Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "152c2ac3-89bd-4d22-a778-6781d46adc13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:02:22.787636Z",
     "iopub.status.busy": "2025-07-11T14:02:22.786953Z",
     "iopub.status.idle": "2025-07-11T14:32:44.620517Z",
     "shell.execute_reply": "2025-07-11T14:32:44.619879Z",
     "shell.execute_reply.started": "2025-07-11T14:02:22.787598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 768)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 768)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6823136423499834\n",
      "0.6330207940952002\n",
      "0.6788672129572054\n",
      "0.6736476460325673\n",
      "0.6411048641681012\n",
      "0.6809373780792625\n",
      "0.6813575151591167\n",
      "0.6587013567039568\n",
      "0.6626508679427698\n",
      "0.6852988849048653\n",
      "0.6209563697522618\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3178</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.3629</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.4508</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.2643</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.6411</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.7815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.7639</td>\n",
       "      <td>0.8749</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.8112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.4491</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.8091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.8026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.4463</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>0.2399</td>\n",
       "      <td>0.3499</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.7788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1274                0.2616   \n",
       "DecisionTreeRegressor                    0.2865                0.3879   \n",
       "RandomForestRegressor                    0.1317                0.2657   \n",
       "GradientBoostingRegressor                0.1289                0.2643   \n",
       "AdaBoostRegressor                        0.1660                0.3198   \n",
       "XGBRegressor                             0.1471                0.2795   \n",
       "ExtraTreesRegressor                      0.1334                0.2658   \n",
       "LinearRegression                         0.1383                0.2771   \n",
       "KNeighborsRegressor                      0.1622                0.2946   \n",
       "SVR                                      0.1289                0.2586   \n",
       "MLPRegressor                             0.2010                0.3351   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.3569               0.7955   \n",
       "DecisionTreeRegressor                     0.5353               0.5400   \n",
       "RandomForestRegressor                     0.3629               0.7886   \n",
       "GradientBoostingRegressor                 0.3590               0.7930   \n",
       "AdaBoostRegressor                         0.4074               0.7335   \n",
       "XGBRegressor                              0.3835               0.7639   \n",
       "ExtraTreesRegressor                       0.3653               0.7857   \n",
       "LinearRegression                          0.3719               0.7780   \n",
       "KNeighborsRegressor                       0.4028               0.7395   \n",
       "SVR                                       0.3590               0.7930   \n",
       "MLPRegressor                              0.4483               0.6773   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8919                0.8724   \n",
       "DecisionTreeRegressor                    0.7749                0.7539   \n",
       "RandomForestRegressor                    0.8880                0.8688   \n",
       "GradientBoostingRegressor                0.8905                0.8703   \n",
       "AdaBoostRegressor                        0.8644                0.8358   \n",
       "XGBRegressor                             0.8749                0.8578   \n",
       "ExtraTreesRegressor                      0.8865                0.8685   \n",
       "LinearRegression                         0.8832                0.8650   \n",
       "KNeighborsRegressor                      0.8628                0.8367   \n",
       "SVR                                      0.8907                0.8743   \n",
       "MLPRegressor                             0.8322                0.8149   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2010   0.3178    0.4484  0.6823   \n",
       "DecisionTreeRegressor       0.2322   0.3415    0.4819  0.6330   \n",
       "RandomForestRegressor       0.2032   0.3188    0.4508  0.6789   \n",
       "GradientBoostingRegressor   0.2065   0.3241    0.4545  0.6736   \n",
       "AdaBoostRegressor           0.2271   0.3643    0.4766  0.6411   \n",
       "XGBRegressor                0.2019   0.3163    0.4493  0.6809   \n",
       "ExtraTreesRegressor         0.2016   0.3185    0.4491  0.6814   \n",
       "LinearRegression            0.2160   0.3268    0.4647  0.6587   \n",
       "KNeighborsRegressor         0.2135   0.3256    0.4620  0.6627   \n",
       "SVR                         0.1992   0.3121    0.4463  0.6853   \n",
       "MLPRegressor                0.2399   0.3499    0.4898  0.6210   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8262                    0.8099  \n",
       "DecisionTreeRegressor                       0.8000                    0.7874  \n",
       "RandomForestRegressor                       0.8240                    0.8071  \n",
       "GradientBoostingRegressor                   0.8211                    0.8017  \n",
       "AdaBoostRegressor                           0.8074                    0.7815  \n",
       "XGBRegressor                                0.8256                    0.8112  \n",
       "ExtraTreesRegressor                         0.8256                    0.8091  \n",
       "LinearRegression                            0.8136                    0.8000  \n",
       "KNeighborsRegressor                         0.8168                    0.8026  \n",
       "SVR                                         0.8283                    0.8156  \n",
       "MLPRegressor                                0.7926                    0.7788  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_data['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "X_test = test_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_test = test_data['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23e780f0-2276-47b0-ba5d-10ad01a541a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:32:44.622274Z",
     "iopub.status.busy": "2025-07-11T14:32:44.621752Z",
     "iopub.status.idle": "2025-07-11T14:32:44.633340Z",
     "shell.execute_reply": "2025-07-11T14:32:44.632704Z",
     "shell.execute_reply.started": "2025-07-11T14:32:44.622254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3178</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.3629</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.4508</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.2643</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.6411</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.7815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.7639</td>\n",
       "      <td>0.8749</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.8112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.4491</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.8091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.8026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.4463</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>0.2399</td>\n",
       "      <td>0.3499</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.7788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1274                0.2616   \n",
       "DecisionTreeRegressor                    0.2865                0.3879   \n",
       "RandomForestRegressor                    0.1317                0.2657   \n",
       "GradientBoostingRegressor                0.1289                0.2643   \n",
       "AdaBoostRegressor                        0.1660                0.3198   \n",
       "XGBRegressor                             0.1471                0.2795   \n",
       "ExtraTreesRegressor                      0.1334                0.2658   \n",
       "LinearRegression                         0.1383                0.2771   \n",
       "KNeighborsRegressor                      0.1622                0.2946   \n",
       "SVR                                      0.1289                0.2586   \n",
       "MLPRegressor                             0.2010                0.3351   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.3569               0.7955   \n",
       "DecisionTreeRegressor                     0.5353               0.5400   \n",
       "RandomForestRegressor                     0.3629               0.7886   \n",
       "GradientBoostingRegressor                 0.3590               0.7930   \n",
       "AdaBoostRegressor                         0.4074               0.7335   \n",
       "XGBRegressor                              0.3835               0.7639   \n",
       "ExtraTreesRegressor                       0.3653               0.7857   \n",
       "LinearRegression                          0.3719               0.7780   \n",
       "KNeighborsRegressor                       0.4028               0.7395   \n",
       "SVR                                       0.3590               0.7930   \n",
       "MLPRegressor                              0.4483               0.6773   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8919                0.8724   \n",
       "DecisionTreeRegressor                    0.7749                0.7539   \n",
       "RandomForestRegressor                    0.8880                0.8688   \n",
       "GradientBoostingRegressor                0.8905                0.8703   \n",
       "AdaBoostRegressor                        0.8644                0.8358   \n",
       "XGBRegressor                             0.8749                0.8578   \n",
       "ExtraTreesRegressor                      0.8865                0.8685   \n",
       "LinearRegression                         0.8832                0.8650   \n",
       "KNeighborsRegressor                      0.8628                0.8367   \n",
       "SVR                                      0.8907                0.8743   \n",
       "MLPRegressor                             0.8322                0.8149   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2010   0.3178    0.4484  0.6823   \n",
       "DecisionTreeRegressor       0.2322   0.3415    0.4819  0.6330   \n",
       "RandomForestRegressor       0.2032   0.3188    0.4508  0.6789   \n",
       "GradientBoostingRegressor   0.2065   0.3241    0.4545  0.6736   \n",
       "AdaBoostRegressor           0.2271   0.3643    0.4766  0.6411   \n",
       "XGBRegressor                0.2019   0.3163    0.4493  0.6809   \n",
       "ExtraTreesRegressor         0.2016   0.3185    0.4491  0.6814   \n",
       "LinearRegression            0.2160   0.3268    0.4647  0.6587   \n",
       "KNeighborsRegressor         0.2135   0.3256    0.4620  0.6627   \n",
       "SVR                         0.1992   0.3121    0.4463  0.6853   \n",
       "MLPRegressor                0.2399   0.3499    0.4898  0.6210   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8262                    0.8099  \n",
       "DecisionTreeRegressor                       0.8000                    0.7874  \n",
       "RandomForestRegressor                       0.8240                    0.8071  \n",
       "GradientBoostingRegressor                   0.8211                    0.8017  \n",
       "AdaBoostRegressor                           0.8074                    0.7815  \n",
       "XGBRegressor                                0.8256                    0.8112  \n",
       "ExtraTreesRegressor                         0.8256                    0.8091  \n",
       "LinearRegression                            0.8136                    0.8000  \n",
       "KNeighborsRegressor                         0.8168                    0.8026  \n",
       "SVR                                         0.8283                    0.8156  \n",
       "MLPRegressor                                0.7926                    0.7788  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70548cc9-30e7-43c9-b52c-dca917d0997e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:32:44.634319Z",
     "iopub.status.busy": "2025-07-11T14:32:44.634085Z",
     "iopub.status.idle": "2025-07-11T14:32:44.716198Z",
     "shell.execute_reply": "2025-07-11T14:32:44.715641Z",
     "shell.execute_reply.started": "2025-07-11T14:32:44.634300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-7.086583683584913, -6.815804250992958, -6.08...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.786902187760718, -6.61619648330882, -6.90...</td>\n",
       "      <td>[-6.8635711883907335, -6.602145199765539, -6.9...</td>\n",
       "      <td>[0.04622281290691233, 0.03860981393706258, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-6.51, -7.06, -5.72, -5.912688899, -5.05, -6....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -7.0, -6.31, -7.0, -5.49, -4.6, -6.85,...</td>\n",
       "      <td>[-6.9319999999999995, -6.732226014, -6.8495459...</td>\n",
       "      <td>[0.13599999999999995, 0.4617785557096743, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-7.041333211310001, -6.835555591965002, -5.94...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.908008623464999, -6.656546208579999, -6.9...</td>\n",
       "      <td>[-6.910041789408, -6.595817895558, -6.94424890...</td>\n",
       "      <td>[0.02203711599022947, 0.05227985263674236, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-7.01035820722417, -6.994280575001665, -6.008...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.923243933109582, -6.640486770903298, -6.9...</td>\n",
       "      <td>[-6.852781012277656, -6.651985741830822, -6.92...</td>\n",
       "      <td>[0.06382409848381805, 0.08264445960761631, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-6.754027529615008, -6.435270964203765, -5.95...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.475847222278211, -6.343212361304096, -6.5...</td>\n",
       "      <td>[-6.569448768320493, -6.346994998925384, -6.64...</td>\n",
       "      <td>[0.06310641597640962, 0.0425883097741094, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-7.159248, -6.749816, -6.179852, -6.16558, -4...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8943925, -6.863192, -6.8066826, -6.912811...</td>\n",
       "      <td>[-6.7879066, -6.5313463, -6.968013, -6.941123,...</td>\n",
       "      <td>[0.1608523, 0.21140534, 0.118369296, 0.0625279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.93379714519, -6.814765341580002, -6.368916...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.877597382784999, -6.595134529520001, -6.8...</td>\n",
       "      <td>[-6.874660321687, -6.595160118379999, -6.91421...</td>\n",
       "      <td>[0.023964459293484675, 0.04541375479493242, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-7.359347594781153, -7.423412449056961, -6.15...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.843919061837669, -7.181037690164304, -7.4...</td>\n",
       "      <td>[-6.9563218996613845, -7.158066911042337, -7.1...</td>\n",
       "      <td>[0.1677225252583808, 0.09940520709909355, 0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-6.963333333333334, -6.973333333333334, -6.12...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.38, -6.8, -6.963333333333334, -5.23...</td>\n",
       "      <td>[-6.994666666666667, -6.356, -6.84000000000000...</td>\n",
       "      <td>[0.006531972647421524, 0.04317406628984595, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.918340169532611, -7.076928358065048, -6.31...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.952095995554789, -6.682612137504316, -6.8...</td>\n",
       "      <td>[-6.9298493265727545, -6.6866611156754825, -6....</td>\n",
       "      <td>[0.01975997577154908, 0.0296676819013228, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.477409042308729, -7.099340326703263, -5.95...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.284669280805158, -7.118383662279891, -6.4...</td>\n",
       "      <td>[-6.375993597792849, -6.874811380781298, -5.98...</td>\n",
       "      <td>[0.11626594262004204, 0.26562128431539406, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-7.086583683584913, -6.815804250992958, -6.08...   \n",
       "1   [-6.51, -7.06, -5.72, -5.912688899, -5.05, -6....   \n",
       "2   [-7.041333211310001, -6.835555591965002, -5.94...   \n",
       "3   [-7.01035820722417, -6.994280575001665, -6.008...   \n",
       "4   [-6.754027529615008, -6.435270964203765, -5.95...   \n",
       "5   [-7.159248, -6.749816, -6.179852, -6.16558, -4...   \n",
       "6   [-6.93379714519, -6.814765341580002, -6.368916...   \n",
       "7   [-7.359347594781153, -7.423412449056961, -6.15...   \n",
       "8   [-6.963333333333334, -6.973333333333334, -6.12...   \n",
       "9   [-6.918340169532611, -7.076928358065048, -6.31...   \n",
       "10  [-6.477409042308729, -7.099340326703263, -5.95...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.786902187760718, -6.61619648330882, -6.90...   \n",
       "1   [[-7.0, -7.0, -6.31, -7.0, -5.49, -4.6, -6.85,...   \n",
       "2   [[-6.908008623464999, -6.656546208579999, -6.9...   \n",
       "3   [[-6.923243933109582, -6.640486770903298, -6.9...   \n",
       "4   [[-6.475847222278211, -6.343212361304096, -6.5...   \n",
       "5   [[-6.8943925, -6.863192, -6.8066826, -6.912811...   \n",
       "6   [[-6.877597382784999, -6.595134529520001, -6.8...   \n",
       "7   [[-6.843919061837669, -7.181037690164304, -7.4...   \n",
       "8   [[-7.0, -6.38, -6.8, -6.963333333333334, -5.23...   \n",
       "9   [[-6.952095995554789, -6.682612137504316, -6.8...   \n",
       "10  [[-6.284669280805158, -7.118383662279891, -6.4...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.8635711883907335, -6.602145199765539, -6.9...   \n",
       "1   [-6.9319999999999995, -6.732226014, -6.8495459...   \n",
       "2   [-6.910041789408, -6.595817895558, -6.94424890...   \n",
       "3   [-6.852781012277656, -6.651985741830822, -6.92...   \n",
       "4   [-6.569448768320493, -6.346994998925384, -6.64...   \n",
       "5   [-6.7879066, -6.5313463, -6.968013, -6.941123,...   \n",
       "6   [-6.874660321687, -6.595160118379999, -6.91421...   \n",
       "7   [-6.9563218996613845, -7.158066911042337, -7.1...   \n",
       "8   [-6.994666666666667, -6.356, -6.84000000000000...   \n",
       "9   [-6.9298493265727545, -6.6866611156754825, -6....   \n",
       "10  [-6.375993597792849, -6.874811380781298, -5.98...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.04622281290691233, 0.03860981393706258, 0.0...  \n",
       "1   [0.13599999999999995, 0.4617785557096743, 0.27...  \n",
       "2   [0.02203711599022947, 0.05227985263674236, 0.0...  \n",
       "3   [0.06382409848381805, 0.08264445960761631, 0.0...  \n",
       "4   [0.06310641597640962, 0.0425883097741094, 0.11...  \n",
       "5   [0.1608523, 0.21140534, 0.118369296, 0.0625279...  \n",
       "6   [0.023964459293484675, 0.04541375479493242, 0....  \n",
       "7   [0.1677225252583808, 0.09940520709909355, 0.15...  \n",
       "8   [0.006531972647421524, 0.04317406628984595, 0....  \n",
       "9   [0.01975997577154908, 0.0296676819013228, 0.03...  \n",
       "10  [0.11626594262004204, 0.26562128431539406, 0.2...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0e20820-200e-44a2-a375-5f1b4986a587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:32:44.717369Z",
     "iopub.status.busy": "2025-07-11T14:32:44.717147Z",
     "iopub.status.idle": "2025-07-11T14:32:44.802856Z",
     "shell.execute_reply": "2025-07-11T14:32:44.802132Z",
     "shell.execute_reply.started": "2025-07-11T14:32:44.717352Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('/kaggle/working/Results_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings.csv')\n",
    "prediction_df.to_csv('/kaggle/working/Prediction_data_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e6925e9-f01c-43fe-bb1f-f1150e01d157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:46:53.892158Z",
     "iopub.status.busy": "2025-07-11T14:46:53.891882Z",
     "iopub.status.idle": "2025-07-11T14:46:53.905046Z",
     "shell.execute_reply": "2025-07-11T14:46:53.904177Z",
     "shell.execute_reply.started": "2025-07-11T14:46:53.892137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3178</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.3629</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.4508</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.2643</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.6411</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.7815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.7639</td>\n",
       "      <td>0.8749</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.8112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.4491</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.8091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.8026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.4463</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>0.2399</td>\n",
       "      <td>0.3499</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.7788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1274                0.2616   \n",
       "DecisionTreeRegressor                    0.2865                0.3879   \n",
       "RandomForestRegressor                    0.1317                0.2657   \n",
       "GradientBoostingRegressor                0.1289                0.2643   \n",
       "AdaBoostRegressor                        0.1660                0.3198   \n",
       "XGBRegressor                             0.1471                0.2795   \n",
       "ExtraTreesRegressor                      0.1334                0.2658   \n",
       "LinearRegression                         0.1383                0.2771   \n",
       "KNeighborsRegressor                      0.1622                0.2946   \n",
       "SVR                                      0.1289                0.2586   \n",
       "MLPRegressor                             0.2010                0.3351   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.3569               0.7955   \n",
       "DecisionTreeRegressor                     0.5353               0.5400   \n",
       "RandomForestRegressor                     0.3629               0.7886   \n",
       "GradientBoostingRegressor                 0.3590               0.7930   \n",
       "AdaBoostRegressor                         0.4074               0.7335   \n",
       "XGBRegressor                              0.3835               0.7639   \n",
       "ExtraTreesRegressor                       0.3653               0.7857   \n",
       "LinearRegression                          0.3719               0.7780   \n",
       "KNeighborsRegressor                       0.4028               0.7395   \n",
       "SVR                                       0.3590               0.7930   \n",
       "MLPRegressor                              0.4483               0.6773   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8919                0.8724   \n",
       "DecisionTreeRegressor                    0.7749                0.7539   \n",
       "RandomForestRegressor                    0.8880                0.8688   \n",
       "GradientBoostingRegressor                0.8905                0.8703   \n",
       "AdaBoostRegressor                        0.8644                0.8358   \n",
       "XGBRegressor                             0.8749                0.8578   \n",
       "ExtraTreesRegressor                      0.8865                0.8685   \n",
       "LinearRegression                         0.8832                0.8650   \n",
       "KNeighborsRegressor                      0.8628                0.8367   \n",
       "SVR                                      0.8907                0.8743   \n",
       "MLPRegressor                             0.8322                0.8149   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2010   0.3178    0.4484  0.6823   \n",
       "DecisionTreeRegressor       0.2322   0.3415    0.4819  0.6330   \n",
       "RandomForestRegressor       0.2032   0.3188    0.4508  0.6789   \n",
       "GradientBoostingRegressor   0.2065   0.3241    0.4545  0.6736   \n",
       "AdaBoostRegressor           0.2271   0.3643    0.4766  0.6411   \n",
       "XGBRegressor                0.2019   0.3163    0.4493  0.6809   \n",
       "ExtraTreesRegressor         0.2016   0.3185    0.4491  0.6814   \n",
       "LinearRegression            0.2160   0.3268    0.4647  0.6587   \n",
       "KNeighborsRegressor         0.2135   0.3256    0.4620  0.6627   \n",
       "SVR                         0.1992   0.3121    0.4463  0.6853   \n",
       "MLPRegressor                0.2399   0.3499    0.4898  0.6210   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8262                    0.8099  \n",
       "DecisionTreeRegressor                       0.8000                    0.7874  \n",
       "RandomForestRegressor                       0.8240                    0.8071  \n",
       "GradientBoostingRegressor                   0.8211                    0.8017  \n",
       "AdaBoostRegressor                           0.8074                    0.7815  \n",
       "XGBRegressor                                0.8256                    0.8112  \n",
       "ExtraTreesRegressor                         0.8256                    0.8091  \n",
       "LinearRegression                            0.8136                    0.8000  \n",
       "KNeighborsRegressor                         0.8168                    0.8026  \n",
       "SVR                                         0.8283                    0.8156  \n",
       "MLPRegressor                                0.7926                    0.7788  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc4fc0ad-61d4-4662-91aa-543114899f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T14:46:58.111152Z",
     "iopub.status.busy": "2025-07-11T14:46:58.110858Z",
     "iopub.status.idle": "2025-07-11T14:46:58.197957Z",
     "shell.execute_reply": "2025-07-11T14:46:58.197377Z",
     "shell.execute_reply.started": "2025-07-11T14:46:58.111129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-7.086583683584913, -6.815804250992958, -6.08...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.786902187760718, -6.61619648330882, -6.90...</td>\n",
       "      <td>[-6.8635711883907335, -6.602145199765539, -6.9...</td>\n",
       "      <td>[0.04622281290691233, 0.03860981393706258, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-6.51, -7.06, -5.72, -5.912688899, -5.05, -6....</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -7.0, -6.31, -7.0, -5.49, -4.6, -6.85,...</td>\n",
       "      <td>[-6.9319999999999995, -6.732226014, -6.8495459...</td>\n",
       "      <td>[0.13599999999999995, 0.4617785557096743, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-7.041333211310001, -6.835555591965002, -5.94...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.908008623464999, -6.656546208579999, -6.9...</td>\n",
       "      <td>[-6.910041789408, -6.595817895558, -6.94424890...</td>\n",
       "      <td>[0.02203711599022947, 0.05227985263674236, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-7.01035820722417, -6.994280575001665, -6.008...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.923243933109582, -6.640486770903298, -6.9...</td>\n",
       "      <td>[-6.852781012277656, -6.651985741830822, -6.92...</td>\n",
       "      <td>[0.06382409848381805, 0.08264445960761631, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-6.754027529615008, -6.435270964203765, -5.95...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.475847222278211, -6.343212361304096, -6.5...</td>\n",
       "      <td>[-6.569448768320493, -6.346994998925384, -6.64...</td>\n",
       "      <td>[0.06310641597640962, 0.0425883097741094, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-7.159248, -6.749816, -6.179852, -6.16558, -4...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.8943925, -6.863192, -6.8066826, -6.912811...</td>\n",
       "      <td>[-6.7879066, -6.5313463, -6.968013, -6.941123,...</td>\n",
       "      <td>[0.1608523, 0.21140534, 0.118369296, 0.0625279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.93379714519, -6.814765341580002, -6.368916...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.877597382784999, -6.595134529520001, -6.8...</td>\n",
       "      <td>[-6.874660321687, -6.595160118379999, -6.91421...</td>\n",
       "      <td>[0.023964459293484675, 0.04541375479493242, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-7.359347594781153, -7.423412449056961, -6.15...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.843919061837669, -7.181037690164304, -7.4...</td>\n",
       "      <td>[-6.9563218996613845, -7.158066911042337, -7.1...</td>\n",
       "      <td>[0.1677225252583808, 0.09940520709909355, 0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-6.963333333333334, -6.973333333333334, -6.12...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-7.0, -6.38, -6.8, -6.963333333333334, -5.23...</td>\n",
       "      <td>[-6.994666666666667, -6.356, -6.84000000000000...</td>\n",
       "      <td>[0.006531972647421524, 0.04317406628984595, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.918340169532611, -7.076928358065048, -6.31...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.952095995554789, -6.682612137504316, -6.8...</td>\n",
       "      <td>[-6.9298493265727545, -6.6866611156754825, -6....</td>\n",
       "      <td>[0.01975997577154908, 0.0296676819013228, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.477409042308729, -7.099340326703263, -5.95...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.284669280805158, -7.118383662279891, -6.4...</td>\n",
       "      <td>[-6.375993597792849, -6.874811380781298, -5.98...</td>\n",
       "      <td>[0.11626594262004204, 0.26562128431539406, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-7.086583683584913, -6.815804250992958, -6.08...   \n",
       "1   [-6.51, -7.06, -5.72, -5.912688899, -5.05, -6....   \n",
       "2   [-7.041333211310001, -6.835555591965002, -5.94...   \n",
       "3   [-7.01035820722417, -6.994280575001665, -6.008...   \n",
       "4   [-6.754027529615008, -6.435270964203765, -5.95...   \n",
       "5   [-7.159248, -6.749816, -6.179852, -6.16558, -4...   \n",
       "6   [-6.93379714519, -6.814765341580002, -6.368916...   \n",
       "7   [-7.359347594781153, -7.423412449056961, -6.15...   \n",
       "8   [-6.963333333333334, -6.973333333333334, -6.12...   \n",
       "9   [-6.918340169532611, -7.076928358065048, -6.31...   \n",
       "10  [-6.477409042308729, -7.099340326703263, -5.95...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.786902187760718, -6.61619648330882, -6.90...   \n",
       "1   [[-7.0, -7.0, -6.31, -7.0, -5.49, -4.6, -6.85,...   \n",
       "2   [[-6.908008623464999, -6.656546208579999, -6.9...   \n",
       "3   [[-6.923243933109582, -6.640486770903298, -6.9...   \n",
       "4   [[-6.475847222278211, -6.343212361304096, -6.5...   \n",
       "5   [[-6.8943925, -6.863192, -6.8066826, -6.912811...   \n",
       "6   [[-6.877597382784999, -6.595134529520001, -6.8...   \n",
       "7   [[-6.843919061837669, -7.181037690164304, -7.4...   \n",
       "8   [[-7.0, -6.38, -6.8, -6.963333333333334, -5.23...   \n",
       "9   [[-6.952095995554789, -6.682612137504316, -6.8...   \n",
       "10  [[-6.284669280805158, -7.118383662279891, -6.4...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.8635711883907335, -6.602145199765539, -6.9...   \n",
       "1   [-6.9319999999999995, -6.732226014, -6.8495459...   \n",
       "2   [-6.910041789408, -6.595817895558, -6.94424890...   \n",
       "3   [-6.852781012277656, -6.651985741830822, -6.92...   \n",
       "4   [-6.569448768320493, -6.346994998925384, -6.64...   \n",
       "5   [-6.7879066, -6.5313463, -6.968013, -6.941123,...   \n",
       "6   [-6.874660321687, -6.595160118379999, -6.91421...   \n",
       "7   [-6.9563218996613845, -7.158066911042337, -7.1...   \n",
       "8   [-6.994666666666667, -6.356, -6.84000000000000...   \n",
       "9   [-6.9298493265727545, -6.6866611156754825, -6....   \n",
       "10  [-6.375993597792849, -6.874811380781298, -5.98...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.04622281290691233, 0.03860981393706258, 0.0...  \n",
       "1   [0.13599999999999995, 0.4617785557096743, 0.27...  \n",
       "2   [0.02203711599022947, 0.05227985263674236, 0.0...  \n",
       "3   [0.06382409848381805, 0.08264445960761631, 0.0...  \n",
       "4   [0.06310641597640962, 0.0425883097741094, 0.11...  \n",
       "5   [0.1608523, 0.21140534, 0.118369296, 0.0625279...  \n",
       "6   [0.023964459293484675, 0.04541375479493242, 0....  \n",
       "7   [0.1677225252583808, 0.09940520709909355, 0.15...  \n",
       "8   [0.006531972647421524, 0.04317406628984595, 0....  \n",
       "9   [0.01975997577154908, 0.0296676819013228, 0.03...  \n",
       "10  [0.11626594262004204, 0.26562128431539406, 0.2...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297f462-92c4-4e5e-af59-4592bc7b0bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7639ba42-865e-40d5-98da-95608349997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            y_pred_fold = np.clip(y_pred_fold, -10, -3.9)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1469a2fe-a786-4847-9d88-10cbb1fd1a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 768)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 768)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6594109412842075\n",
      "0.610630589972784\n",
      "0.656469053639413\n",
      "0.649650937580281\n",
      "0.6116745485349053\n",
      "0.6608957033986504\n",
      "0.6637857562930325\n",
      "0.6354723001996591\n",
      "0.6427874416969913\n",
      "0.6578998911432188\n",
      "0.5452053040200068\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train MSE (5 fold cv)</th>\n",
       "      <th>Train MAE (5 fold cv)</th>\n",
       "      <th>Train RMSE (5 fold cv)</th>\n",
       "      <th>Train R2 (5 fold cv)</th>\n",
       "      <th>Train PCC (5 fold cv)</th>\n",
       "      <th>Train SCC (5 fold cv)</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Pearson Correlation</th>\n",
       "      <th>Test Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.3752</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.4643</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.7949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>0.5482</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.7293</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.3591</td>\n",
       "      <td>0.4964</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.7597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.3795</td>\n",
       "      <td>0.7687</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.3315</td>\n",
       "      <td>0.4663</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>0.7948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.2796</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.3359</td>\n",
       "      <td>0.4709</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.7891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.3332</td>\n",
       "      <td>0.4247</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.2949</td>\n",
       "      <td>0.3998</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.8381</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.6609</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.7957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.7963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.2979</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.3436</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.3057</td>\n",
       "      <td>0.4176</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>0.8513</td>\n",
       "      <td>0.8223</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.7880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.3798</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.2497</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.5991</td>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0.7388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Train MSE (5 fold cv) Train MAE (5 fold cv)  \\\n",
       "LGBMRegressor                            0.1408                0.2760   \n",
       "DecisionTreeRegressor                    0.3005                0.3977   \n",
       "RandomForestRegressor                    0.1441                0.2791   \n",
       "GradientBoostingRegressor                0.1438                0.2796   \n",
       "AdaBoostRegressor                        0.1804                0.3332   \n",
       "XGBRegressor                             0.1599                0.2949   \n",
       "ExtraTreesRegressor                      0.1407                0.2759   \n",
       "LinearRegression                         0.1595                0.2979   \n",
       "KNeighborsRegressor                      0.1744                0.3057   \n",
       "SVR                                      0.1443                0.2761   \n",
       "MLPRegressor                             0.2497                0.3673   \n",
       "\n",
       "                          Train RMSE (5 fold cv) Train R2 (5 fold cv)  \\\n",
       "LGBMRegressor                             0.3752               0.7740   \n",
       "DecisionTreeRegressor                     0.5482               0.5175   \n",
       "RandomForestRegressor                     0.3795               0.7687   \n",
       "GradientBoostingRegressor                 0.3792               0.7691   \n",
       "AdaBoostRegressor                         0.4247               0.7104   \n",
       "XGBRegressor                              0.3998               0.7433   \n",
       "ExtraTreesRegressor                       0.3751               0.7741   \n",
       "LinearRegression                          0.3994               0.7439   \n",
       "KNeighborsRegressor                       0.4176               0.7199   \n",
       "SVR                                       0.3798               0.7684   \n",
       "MLPRegressor                              0.4997               0.5991   \n",
       "\n",
       "                          Train PCC (5 fold cv) Train SCC (5 fold cv)  \\\n",
       "LGBMRegressor                            0.8798                0.8549   \n",
       "DecisionTreeRegressor                    0.7596                0.7293   \n",
       "RandomForestRegressor                    0.8768                0.8530   \n",
       "GradientBoostingRegressor                0.8770                0.8517   \n",
       "AdaBoostRegressor                        0.8529                0.8164   \n",
       "XGBRegressor                             0.8635                0.8381   \n",
       "ExtraTreesRegressor                      0.8799                0.8554   \n",
       "LinearRegression                         0.8638                0.8407   \n",
       "KNeighborsRegressor                      0.8513                0.8223   \n",
       "SVR                                      0.8768                0.8539   \n",
       "MLPRegressor                             0.8118                0.7860   \n",
       "\n",
       "                          Test MSE Test MAE Test RMSE Test R2  \\\n",
       "LGBMRegressor               0.2155   0.3297    0.4643  0.6594   \n",
       "DecisionTreeRegressor       0.2464   0.3591    0.4964  0.6106   \n",
       "RandomForestRegressor       0.2174   0.3315    0.4663  0.6565   \n",
       "GradientBoostingRegressor   0.2217   0.3359    0.4709  0.6497   \n",
       "AdaBoostRegressor           0.2457   0.3773    0.4957  0.6117   \n",
       "XGBRegressor                0.2146   0.3257    0.4632  0.6609   \n",
       "ExtraTreesRegressor         0.2128   0.3272    0.4613  0.6638   \n",
       "LinearRegression            0.2307   0.3436    0.4803  0.6355   \n",
       "KNeighborsRegressor         0.2261   0.3337    0.4755  0.6428   \n",
       "SVR                         0.2165   0.3245    0.4653  0.6579   \n",
       "MLPRegressor                0.2878   0.3774    0.5365  0.5452   \n",
       "\n",
       "                          Test Pearson Correlation Test Spearman Correlation  \n",
       "LGBMRegressor                               0.8125                    0.7949  \n",
       "DecisionTreeRegressor                       0.7845                    0.7597  \n",
       "RandomForestRegressor                       0.8104                    0.7948  \n",
       "GradientBoostingRegressor                   0.8065                    0.7891  \n",
       "AdaBoostRegressor                           0.7894                    0.7619  \n",
       "XGBRegressor                                0.8136                    0.7957  \n",
       "ExtraTreesRegressor                         0.8150                    0.7963  \n",
       "LinearRegression                            0.7991                    0.7783  \n",
       "KNeighborsRegressor                         0.8052                    0.7880  \n",
       "SVR                                         0.8122                    0.7975  \n",
       "MLPRegressor                                0.7634                    0.7388  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_data['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "X_test = test_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_test = test_data['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "result_df, prediction_df = train_and_test_predict(models, X_train,y_train, X_test,  y_test)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e83640-106c-4811-8a0e-ec56ab01edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Y Train pred</th>\n",
       "      <th>Y Test actual</th>\n",
       "      <th>Test prediction folds</th>\n",
       "      <th>Test Predictions Mean</th>\n",
       "      <th>Test Predictions Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-6.909077396213976, -7.101259240107274, -6.33...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.646761997758443, -6.608498002030167, -6.8...</td>\n",
       "      <td>[-6.622763033792944, -6.656585882955784, -6.75...</td>\n",
       "      <td>[0.059518837031919854, 0.1119719133953916, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>[-7.0, -7.0, -6.22, -6.28, -4.68, -7.0, -6.21,...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.258509493, -6.24, -7.0, -7.0, -5.7, -6.87...</td>\n",
       "      <td>[-6.689701898600001, -6.484, -6.8508163008, -6...</td>\n",
       "      <td>[0.36013431197510004, 0.34742481200973535, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-6.7938633716349965, -6.97430426117, -6.22331...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.717490153910003, -6.712760668130001, -6.6...</td>\n",
       "      <td>[-6.626025296897001, -6.585755779228002, -6.63...</td>\n",
       "      <td>[0.0790222544163501, 0.08943658134169531, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>[-6.7243198362045815, -6.825998588946187, -6.0...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.640274047625274, -6.684196361443712, -6.7...</td>\n",
       "      <td>[-6.558216976910344, -6.634225596251376, -6.59...</td>\n",
       "      <td>[0.06019759923187576, 0.04619603396250953, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-6.3601653394901865, -6.507100462965622, -6.2...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.316111667428598, -6.441982282919446, -6.3...</td>\n",
       "      <td>[-6.371071113510344, -6.39484577546523, -6.347...</td>\n",
       "      <td>[0.09661370445591204, 0.07928440385636452, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-7.068997, -6.8560753, -6.4421377, -6.3696446...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.763857, -6.6924067, -6.953386, -6.789949,...</td>\n",
       "      <td>[-6.670822, -6.51983, -6.805169, -6.7844877, -...</td>\n",
       "      <td>[0.11041237, 0.18895552, 0.336173, 0.07561323,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>[-6.909716102445, -6.9859977469500025, -6.3266...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.645029993165001, -6.691985589590002, -6.7...</td>\n",
       "      <td>[-6.6628105390100005, -6.631058136546001, -6.7...</td>\n",
       "      <td>[0.04891292130037411, 0.05447640248727775, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[-7.548665983147586, -7.0273081994875355, -6.3...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.412551606069016, -6.758647068325146, -6.5...</td>\n",
       "      <td>[-6.317849575426787, -6.759392884347544, -6.33...</td>\n",
       "      <td>[0.16985516155283886, 0.12560976710489397, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>[-7.0, -7.0, -6.186666666666667, -5.8733333333...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.746666666666667, -6.746666666666667, -7.0...</td>\n",
       "      <td>[-6.797333333333334, -6.797333333333334, -7.0,...</td>\n",
       "      <td>[0.10133333333333318, 0.10133333333333318, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>[-6.97720696709948, -6.9838277014726815, -6.22...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.725858156162798, -6.607283766001682, -6.8...</td>\n",
       "      <td>[-6.639688945344266, -6.596293527100258, -6.77...</td>\n",
       "      <td>[0.05679081625449122, 0.019267847655598264, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>[-6.462799838853169, -7.417651797406833, -6.46...</td>\n",
       "      <td>0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...</td>\n",
       "      <td>[[-6.847189006998192, -6.437394113766778, -6.7...</td>\n",
       "      <td>[-6.871140764927882, -6.33951337905924, -6.709...</td>\n",
       "      <td>[0.35894241501999363, 0.17262075074179672, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "0               LGBMRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "2       RandomForestRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5                XGBRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7            LinearRegression   \n",
       "8         KNeighborsRegressor   \n",
       "9                         SVR   \n",
       "10               MLPRegressor   \n",
       "\n",
       "                                         Y Train pred  \\\n",
       "0   [-6.909077396213976, -7.101259240107274, -6.33...   \n",
       "1   [-7.0, -7.0, -6.22, -6.28, -4.68, -7.0, -6.21,...   \n",
       "2   [-6.7938633716349965, -6.97430426117, -6.22331...   \n",
       "3   [-6.7243198362045815, -6.825998588946187, -6.0...   \n",
       "4   [-6.3601653394901865, -6.507100462965622, -6.2...   \n",
       "5   [-7.068997, -6.8560753, -6.4421377, -6.3696446...   \n",
       "6   [-6.909716102445, -6.9859977469500025, -6.3266...   \n",
       "7   [-7.548665983147586, -7.0273081994875355, -6.3...   \n",
       "8   [-7.0, -7.0, -6.186666666666667, -5.8733333333...   \n",
       "9   [-6.97720696709948, -6.9838277014726815, -6.22...   \n",
       "10  [-6.462799838853169, -7.417651797406833, -6.46...   \n",
       "\n",
       "                                        Y Test actual  \\\n",
       "0   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "1   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "2   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "3   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "4   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "5   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "6   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "7   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "8   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "9   0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "10  0      -7.00\n",
       "1      -7.00\n",
       "2      -7.00\n",
       "3      ...   \n",
       "\n",
       "                                Test prediction folds  \\\n",
       "0   [[-6.646761997758443, -6.608498002030167, -6.8...   \n",
       "1   [[-6.258509493, -6.24, -7.0, -7.0, -5.7, -6.87...   \n",
       "2   [[-6.717490153910003, -6.712760668130001, -6.6...   \n",
       "3   [[-6.640274047625274, -6.684196361443712, -6.7...   \n",
       "4   [[-6.316111667428598, -6.441982282919446, -6.3...   \n",
       "5   [[-6.763857, -6.6924067, -6.953386, -6.789949,...   \n",
       "6   [[-6.645029993165001, -6.691985589590002, -6.7...   \n",
       "7   [[-6.412551606069016, -6.758647068325146, -6.5...   \n",
       "8   [[-6.746666666666667, -6.746666666666667, -7.0...   \n",
       "9   [[-6.725858156162798, -6.607283766001682, -6.8...   \n",
       "10  [[-6.847189006998192, -6.437394113766778, -6.7...   \n",
       "\n",
       "                                Test Predictions Mean  \\\n",
       "0   [-6.622763033792944, -6.656585882955784, -6.75...   \n",
       "1   [-6.689701898600001, -6.484, -6.8508163008, -6...   \n",
       "2   [-6.626025296897001, -6.585755779228002, -6.63...   \n",
       "3   [-6.558216976910344, -6.634225596251376, -6.59...   \n",
       "4   [-6.371071113510344, -6.39484577546523, -6.347...   \n",
       "5   [-6.670822, -6.51983, -6.805169, -6.7844877, -...   \n",
       "6   [-6.6628105390100005, -6.631058136546001, -6.7...   \n",
       "7   [-6.317849575426787, -6.759392884347544, -6.33...   \n",
       "8   [-6.797333333333334, -6.797333333333334, -7.0,...   \n",
       "9   [-6.639688945344266, -6.596293527100258, -6.77...   \n",
       "10  [-6.871140764927882, -6.33951337905924, -6.709...   \n",
       "\n",
       "                                 Test Predictions Std  \n",
       "0   [0.059518837031919854, 0.1119719133953916, 0.0...  \n",
       "1   [0.36013431197510004, 0.34742481200973535, 0.3...  \n",
       "2   [0.0790222544163501, 0.08943658134169531, 0.03...  \n",
       "3   [0.06019759923187576, 0.04619603396250953, 0.1...  \n",
       "4   [0.09661370445591204, 0.07928440385636452, 0.1...  \n",
       "5   [0.11041237, 0.18895552, 0.336173, 0.07561323,...  \n",
       "6   [0.04891292130037411, 0.05447640248727775, 0.0...  \n",
       "7   [0.16985516155283886, 0.12560976710489397, 0.2...  \n",
       "8   [0.10133333333333318, 0.10133333333333318, 0.0...  \n",
       "9   [0.05679081625449122, 0.019267847655598264, 0....  \n",
       "10  [0.35894241501999363, 0.17262075074179672, 0.0...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a6d4c-4c0f-4009-b6b2-29c35b8cb492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd3ae37-c269-40b9-985a-66762751bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "import joblib\n",
    "def train_and_test_predict_with_tuning(models, param_grids, X_train, y_train, X_test, y_test, save_dir):\n",
    "   \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        best_params = None\n",
    "\n",
    "        # hyperparameter tuning \n",
    "        if model_name in param_grids and param_grids[model_name]:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model, \n",
    "                param_grid=param_grids[model_name], \n",
    "                cv=kf,\n",
    "                scoring='neg_mean_squared_error', \n",
    "                n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            print(model_name)\n",
    "            print(\": best params\",best_params)\n",
    "        else:\n",
    "            default_params = model.get_params()\n",
    "            print(model_name, ': Default params', default_params)\n",
    "            best_params = {}\n",
    "            print(model_name, ':Used Default params')\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)  \n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, predictions_test_mean)\n",
    "        mae_test = mean_absolute_error(y_test, predictions_test_mean)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, predictions_test_mean)\n",
    "        print(r2_test)\n",
    "        pearson_test, _ = pearsonr(y_test, predictions_test_mean)\n",
    "        spearman_test, _ = spearmanr(y_test, predictions_test_mean)\n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Train pred': predictions_train,\n",
    "            'Y Test actual': y_test,\n",
    "            'Test Predictions folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "            'Best Parameters': best_params\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': f\"{mse_test:.4f}\",\n",
    "            'Test MAE': f\"{mae_test:.4f}\",\n",
    "            'Test RMSE': f\"{rmse_test:.4f}\",\n",
    "            'Test R2': f\"{r2_test:.4f}\",\n",
    "            'Test Pearson Correlation': f\"{pearson_test:.4f}\",\n",
    "            'Test Spearman Correlation': f\"{spearman_test:.4f}\",\n",
    "        }\n",
    "        # Save the model\n",
    "        model_path = os.path.join(save_dir, f\"{model_name}.joblib\")\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"Saved {model_name} model to {model_path}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d19babb-d4f4-48ee-900b-dbc9966b810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "        'ExtraTreesRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None,1,5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'LGBMRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'num_leaves': [31, 50, 100]\n",
    "        },\n",
    "        'DecisionTreeRegressor': {\n",
    "            'max_depth': [None, 10, 20, 50, 100],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'RandomForestRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [None, 1, 5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'GradientBoostingRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7, 10]\n",
    "        },\n",
    "        'AdaBoostRegressor': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'learning_rate': [0.001, 0.01, 0.1, 1.0]\n",
    "        },\n",
    "        'SVR': {\n",
    "            'C': [0.001, 0.1, 1, 10],\n",
    "            'epsilon': [0.1, 0.2, 0.5],\n",
    "            'gamma': [0.001, 0.1, 1, 10]\n",
    "        },\n",
    "        'KNeighborsRegressor': {\n",
    "            'n_neighbors': [3, 5, 10],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        },\n",
    "        'MLPRegressor': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'learning_rate': ['constant', 'adaptive'],\n",
    "            'max_iter': [100,200, 400]\n",
    "}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e28a7b-1a51-4d80-a435-255eb991dba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5568, 768)\n",
      "y_train shape:  (5568,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X_test shape:  (1392, 768)\n",
      "y_test shape:  (1392,)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "LGBMRegressor : Default params {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': 'regression', 'random_state': 101, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 5568, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.742906\n",
      "LGBMRegressor\n",
      ": best params {'learning_rate': 0.01, 'n_estimators': 400, 'num_leaves': 31}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.738310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.742699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.749235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.745049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4455, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -5.739237\n",
      "0.6573864709805025\n",
      "Saved LGBMRegressor model to embedding_results/Models_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_with_HPT/LGBMRegressor.joblib\n",
      "DecisionTreeRegressor : Default params {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 101, 'splitter': 'best'}\n",
      "DecisionTreeRegressor\n",
      ": best params {'max_depth': 10, 'min_samples_split': 10}\n",
      "0.627680663231102\n",
      "Saved DecisionTreeRegressor model to embedding_results/Models_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_with_HPT/DecisionTreeRegressor.joblib\n",
      "RandomForestRegressor : Default params {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_results/Models_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_with_HPT/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     32\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 33\u001b[0m result_df, prediction_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_test_predict_with_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m result_df\n",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m, in \u001b[0;36mtrain_and_test_predict_with_tuning\u001b[1;34m(models, param_grids, X_train, y_train, X_test, y_test, save_dir)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: Default params\u001b[39m\u001b[38;5;124m'\u001b[39m, default_params)\n\u001b[0;32m     22\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     23\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[0;32m     24\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grids[model_name], \n\u001b[0;32m     25\u001b[0m     cv\u001b[38;5;241m=\u001b[39mkf,\n\u001b[0;32m     26\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     27\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     30\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1018\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1019\u001b[0m     )\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1023\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1570\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1570\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:969\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    965\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    966\u001b[0m         )\n\u001b[0;32m    967\u001b[0m     )\n\u001b[1;32m--> 969\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = train_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_train = train_data['Permeability']\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "X_test = test_data.drop(['ID','SMILES','Permeability'],axis=1)\n",
    "y_test = test_data['Permeability']\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n",
    "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "models = [\n",
    "    lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',num_leaves=31,learning_rate=0.05,random_state=101),\n",
    "    DecisionTreeRegressor(random_state=101),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=101),\n",
    "    GradientBoostingRegressor(random_state=101),\n",
    "    AdaBoostRegressor(random_state=101),\n",
    "    xgb.XGBRegressor(random_state=101),\n",
    "    ExtraTreesRegressor(n_jobs=-1, n_estimators=100, random_state=101),\n",
    "    LinearRegression(), \n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(),  \n",
    "    MLPRegressor(random_state=101)\n",
    "]\n",
    "\n",
    "save_dir = 'embedding_results/Models_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_with_HPT/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "result_df, prediction_df = train_and_test_predict_with_tuning(models,param_grids, X_train,y_train, X_test,  y_test, save_dir)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a718389-c6a5-4397-b647-61b4fb885d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('embedding_results/Results_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_with_HPT.csv')\n",
    "prediction_df.to_csv('embedding_results/Prediction_data_MoLFormer-XL-both-10pct_model_1_fine_tuned_embeddings_with_HPT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6ef7c-65e3-4297-a75e-dd63025258a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c9435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771a9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dca642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42f880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8811b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa7075a-9c73-4150-a3cb-e2d57ba5a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_predict(models, X_train, y_train, X_test, y_test):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    results = {}\n",
    "    predictions = []  \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        predictions_train = []\n",
    "        actual_y_train = []\n",
    "\n",
    "        test_predictions_folds = []\n",
    "\n",
    "        mse_test_folds = []\n",
    "        mae_test_folds = []\n",
    "        rmse_test_folds = []\n",
    "        r2_test_folds = []\n",
    "        pearson_test_folds = []\n",
    "        spearman_test_folds = []\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_pred_fold = model.predict(X_val_fold)\n",
    "            predictions_train.extend(y_pred_fold)\n",
    "            actual_y_train.extend(y_val_fold)\n",
    "\n",
    "            predictions_test_fold = model.predict(X_test)\n",
    "            predictions_test_fold = np.clip(predictions_test_fold, -10, -3.9)\n",
    "            test_predictions_folds.append(predictions_test_fold)\n",
    "            \n",
    "\n",
    "            mse_test_folds.append(mean_squared_error(y_test, predictions_test_fold))\n",
    "            mae_test_folds.append(mean_absolute_error(y_test, predictions_test_fold))\n",
    "            rmse_test_folds.append(np.sqrt(mse_test_folds[-1]))\n",
    "            r2_test_folds.append(r2_score(y_test, predictions_test_fold))\n",
    "            pearson_test, _ = pearsonr(y_test, predictions_test_fold)\n",
    "            spearman_test, _ = spearmanr(y_test, predictions_test_fold)\n",
    "            pearson_test_folds.append(pearson_test)\n",
    "            spearman_test_folds.append(spearman_test)\n",
    "\n",
    "\n",
    "        mse_train = mean_squared_error(actual_y_train, predictions_train)\n",
    "        mae_train = mean_absolute_error(actual_y_train, predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = r2_score(actual_y_train, predictions_train)\n",
    "        pearson_train, _ = pearsonr(actual_y_train, predictions_train)\n",
    "        spearman_train, _ = spearmanr(actual_y_train, predictions_train)\n",
    "\n",
    "        # Helper function to format mean ± std string\n",
    "        def format_metric(metric_values):\n",
    "            mean_val = np.mean(metric_values)\n",
    "            std_val = np.std(metric_values)\n",
    "            return f\"{mean_val:.4f} ± {std_val:.4f}\"\n",
    "\n",
    "        mse_test_str = format_metric(mse_test_folds)\n",
    "        mae_test_str = format_metric(mae_test_folds)\n",
    "        rmse_test_str = format_metric(rmse_test_folds)\n",
    "        r2_test_str = format_metric(r2_test_folds)\n",
    "        pearson_test_str = format_metric(pearson_test_folds)\n",
    "        spearman_test_str = format_metric(spearman_test_folds)\n",
    "\n",
    "        predictions_test_mean = np.mean(test_predictions_folds, axis=0)\n",
    "        predictions_test_std = np.std(test_predictions_folds, axis=0)\n",
    "        \n",
    "\n",
    "        predictions.append({\n",
    "            'Model': model_name,\n",
    "            'Y Test': y_test,\n",
    "            'Test prediction folds': test_predictions_folds,\n",
    "            'Test Predictions Mean': predictions_test_mean,\n",
    "            'Test Predictions Std': predictions_test_std,\n",
    "\n",
    "        })\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Train MSE (5 fold cv)': f\"{mse_train:.4f}\",\n",
    "            'Train MAE (5 fold cv)': f\"{mae_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train RMSE (5 fold cv)': f\"{rmse_train:.4f}\",\n",
    "            'Train R2 (5 fold cv)': f\"{r2_train:.4f}\",\n",
    "            'Train PCC (5 fold cv)': f\"{pearson_train:.4f}\",\n",
    "            'Train SCC (5 fold cv)': f\"{spearman_train:.4f}\",\n",
    "            'Test MSE': mse_test_str,\n",
    "            'Test MAE': mae_test_str,\n",
    "            'Test RMSE': rmse_test_str,\n",
    "            'Test R2': r2_test_str,\n",
    "            'Test Pearson Correlation': pearson_test_str,\n",
    "            'Test Spearman Correlation': spearman_test_str,\n",
    "        }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return results_df, predictions_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7847446,
     "sourceId": 12440409,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
